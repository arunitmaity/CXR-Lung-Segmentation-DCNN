{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_lungSeg_model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLRgLqimY5kt",
        "outputId": "5c944de2-1c34-434c-df65-490413852a7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Sep 26 09:01:10 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.66       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qBWPp3nbFQe",
        "outputId": "5b7f67b3-9fcb-46a0-ab20-1e3729b26f0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avtchxMFbJ41",
        "outputId": "9b43eea6-2271-4965-952f-8cd180a853ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!unzip '/content/gdrive/My Drive/Colab Notebooks/tbh+clahe.zip' -d '/content'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/gdrive/My Drive/Colab Notebooks/tbh+clahe.zip\n",
            "   creating: /content/tbh+clahe/\n",
            "   creating: /content/tbh+clahe/test/\n",
            "   creating: /content/tbh+clahe/test/cxrs/\n",
            "  inflating: /content/tbh+clahe/test/cxrs/MCUCXR_0048_0.png  \n",
            "  inflating: /content/tbh+clahe/test/cxrs/MCUCXR_0005_0.png  \n",
            "  inflating: /content/tbh+clahe/test/cxrs/MCUCXR_0013_0.png  \n",
            "  inflating: /content/tbh+clahe/test/cxrs/MCUCXR_0061_0.png  \n",
            "  inflating: /content/tbh+clahe/test/cxrs/MCUCXR_0338_1.png  \n",
            "  inflating: /content/tbh+clahe/test/cxrs/MCUCXR_0070_0.png  \n",
            "  inflating: /content/tbh+clahe/test/cxrs/MCUCXR_0083_0.png  \n",
            "  inflating: /content/tbh+clahe/test/cxrs/MCUCXR_0047_0.png  \n",
            "  inflating: /content/tbh+clahe/test/cxrs/MCUCXR_0080_0.png  \n",
            "  inflating: /content/tbh+clahe/test/cxrs/MCUCXR_0266_1.png  \n",
            "  inflating: /content/tbh+clahe/test/cxrs/MCUCXR_0024_0.png  \n",
            "  inflating: /content/tbh+clahe/test/cxrs/MCUCXR_0101_0.png  \n",
            "  inflating: /content/tbh+clahe/test/cxrs/MCUCXR_0071_0.png  \n",
            "  inflating: /content/tbh+clahe/test/cxrs/MCUCXR_0077_0.png  \n",
            "  inflating: /content/tbh+clahe/test/cxrs/JPCNN040.png  \n",
            "  inflating: /content/tbh+clahe/test/cxrs/JPCLN065.png  \n",
            "  inflating: /content/tbh+clahe/test/cxrs/JPCNN082.png  \n",
            "  inflating: /content/tbh+clahe/test/cxrs/JPCLN143.png  \n",
            "  inflating: /content/tbh+clahe/test/cxrs/JPCLN107.png  \n",
            "  inflating: /content/tbh+clahe/test/cxrs/JPCLN054.png  \n",
            "  inflating: /content/tbh+clahe/test/cxrs/JPCLN138.png  \n",
            "  inflating: /content/tbh+clahe/test/cxrs/JPCLN122.png  \n",
            "  inflating: /content/tbh+clahe/test/cxrs/JPCLN060.png  \n",
            "  inflating: /content/tbh+clahe/test/cxrs/JPCNN078.png  \n",
            "  inflating: /content/tbh+clahe/test/cxrs/JPCNN058.png  \n",
            "  inflating: /content/tbh+clahe/test/cxrs/JPCNN074.png  \n",
            "  inflating: /content/tbh+clahe/test/cxrs/JPCLN051.png  \n",
            "  inflating: /content/tbh+clahe/test/cxrs/JPCNN071.png  \n",
            "  inflating: /content/tbh+clahe/test/cxrs/JPCLN092.png  \n",
            "  inflating: /content/tbh+clahe/test/cxrs/JPCLN146.png  \n",
            "  inflating: /content/tbh+clahe/test/cxrs/JPCLN135.png  \n",
            "  inflating: /content/tbh+clahe/test/cxrs/JPCLN015.png  \n",
            "  inflating: /content/tbh+clahe/test/cxrs/JPCNN090.png  \n",
            "  inflating: /content/tbh+clahe/test/cxrs/JPCLN071.png  \n",
            "  inflating: /content/tbh+clahe/test/cxrs/JPCLN001.png  \n",
            "  inflating: /content/tbh+clahe/test/cxrs/JPCLN059.png  \n",
            "  inflating: /content/tbh+clahe/test/cxrs/JPCNN054.png  \n",
            "  inflating: /content/tbh+clahe/test/cxrs/JPCNN046.png  \n",
            "  inflating: /content/tbh+clahe/test/cxrs/JPCNN004.png  \n",
            "   creating: /content/tbh+clahe/test/masks/\n",
            "  inflating: /content/tbh+clahe/test/masks/MCUCXR_0048_0.png  \n",
            "  inflating: /content/tbh+clahe/test/masks/MCUCXR_0005_0.png  \n",
            "  inflating: /content/tbh+clahe/test/masks/MCUCXR_0013_0.png  \n",
            "  inflating: /content/tbh+clahe/test/masks/MCUCXR_0061_0.png  \n",
            "  inflating: /content/tbh+clahe/test/masks/MCUCXR_0338_1.png  \n",
            "  inflating: /content/tbh+clahe/test/masks/MCUCXR_0070_0.png  \n",
            "  inflating: /content/tbh+clahe/test/masks/MCUCXR_0083_0.png  \n",
            "  inflating: /content/tbh+clahe/test/masks/MCUCXR_0047_0.png  \n",
            "  inflating: /content/tbh+clahe/test/masks/MCUCXR_0080_0.png  \n",
            "  inflating: /content/tbh+clahe/test/masks/MCUCXR_0266_1.png  \n",
            "  inflating: /content/tbh+clahe/test/masks/MCUCXR_0024_0.png  \n",
            "  inflating: /content/tbh+clahe/test/masks/MCUCXR_0101_0.png  \n",
            "  inflating: /content/tbh+clahe/test/masks/MCUCXR_0071_0.png  \n",
            "  inflating: /content/tbh+clahe/test/masks/MCUCXR_0077_0.png  \n",
            "  inflating: /content/tbh+clahe/test/masks/JPCNN040.png  \n",
            "  inflating: /content/tbh+clahe/test/masks/JPCLN065.png  \n",
            "  inflating: /content/tbh+clahe/test/masks/JPCNN082.png  \n",
            "  inflating: /content/tbh+clahe/test/masks/JPCLN143.png  \n",
            "  inflating: /content/tbh+clahe/test/masks/JPCLN107.png  \n",
            "  inflating: /content/tbh+clahe/test/masks/JPCLN054.png  \n",
            "  inflating: /content/tbh+clahe/test/masks/JPCLN138.png  \n",
            "  inflating: /content/tbh+clahe/test/masks/JPCLN122.png  \n",
            "  inflating: /content/tbh+clahe/test/masks/JPCLN060.png  \n",
            "  inflating: /content/tbh+clahe/test/masks/JPCNN078.png  \n",
            "  inflating: /content/tbh+clahe/test/masks/JPCNN058.png  \n",
            "  inflating: /content/tbh+clahe/test/masks/JPCNN074.png  \n",
            "  inflating: /content/tbh+clahe/test/masks/JPCLN051.png  \n",
            "  inflating: /content/tbh+clahe/test/masks/JPCNN071.png  \n",
            "  inflating: /content/tbh+clahe/test/masks/JPCLN092.png  \n",
            "  inflating: /content/tbh+clahe/test/masks/JPCLN146.png  \n",
            "  inflating: /content/tbh+clahe/test/masks/JPCLN135.png  \n",
            "  inflating: /content/tbh+clahe/test/masks/JPCLN015.png  \n",
            "  inflating: /content/tbh+clahe/test/masks/JPCNN090.png  \n",
            "  inflating: /content/tbh+clahe/test/masks/JPCLN071.png  \n",
            "  inflating: /content/tbh+clahe/test/masks/JPCLN001.png  \n",
            "  inflating: /content/tbh+clahe/test/masks/JPCLN059.png  \n",
            "  inflating: /content/tbh+clahe/test/masks/JPCNN054.png  \n",
            "  inflating: /content/tbh+clahe/test/masks/JPCNN046.png  \n",
            "  inflating: /content/tbh+clahe/test/masks/JPCNN004.png  \n",
            "   creating: /content/tbh+clahe/train/\n",
            "   creating: /content/tbh+clahe/train/cxrs/\n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0096_0.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0092_0.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0057_0.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0150_1.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0282_1.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0062_0.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0213_1.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0056_0.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0063_0.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0023_0.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0331_1.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0049_0.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0040_0.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0031_0.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0043_0.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0309_1.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0166_1.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0393_1.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0027_0.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0275_1.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0091_0.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0081_0.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0030_0.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0058_0.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0387_1.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0243_1.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0041_0.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0008_0.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0354_1.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0046_0.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0011_0.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0044_0.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0367_1.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0006_0.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0375_1.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0015_0.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0264_1.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0086_0.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0079_0.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0228_1.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0311_1.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0099_0.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0064_0.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0042_0.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0075_0.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0055_0.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0085_0.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0255_1.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0052_0.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0029_0.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0002_0.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0020_0.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0113_1.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0094_0.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0054_0.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0021_0.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0253_1.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0038_0.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0301_1.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0104_1.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0059_0.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0095_0.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0102_0.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0142_1.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0060_0.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0090_0.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0144_1.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0203_1.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0035_0.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0218_1.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0019_0.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0390_1.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0022_0.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0196_1.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0289_1.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0069_0.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0141_1.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0082_0.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0372_1.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0399_1.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0294_1.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0350_1.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0117_1.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0103_0.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0097_0.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0313_1.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0162_1.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0001_0.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0182_1.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0334_1.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0254_1.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0053_0.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0140_1.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0223_1.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0087_0.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0074_0.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0352_1.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0316_1.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0188_1.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0100_0.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0004_0.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0362_1.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0348_1.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0089_0.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0026_0.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0068_0.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0016_0.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0251_1.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0003_0.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/MCUCXR_0108_1.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN011.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN070.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN066.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN092.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN053.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN089.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN038.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN007.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN083.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN062.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN076.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN032.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN060.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN133.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN081.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN009.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN136.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN099.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN087.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN058.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN017.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN027.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN057.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN119.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN052.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN044.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN021.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN024.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN018.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN001.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN021.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN013.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN042.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN148.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN140.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN064.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN037.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN077.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN010.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN079.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN153.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN085.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN006.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN036.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN068.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN075.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN013.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN047.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN072.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN141.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN149.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN117.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN093.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN036.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN002.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN130.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN088.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN132.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN081.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN150.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN091.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN082.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN025.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN151.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN055.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN024.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN059.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN084.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN102.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN025.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN033.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN129.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN038.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN022.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN048.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN091.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN061.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN128.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN030.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN056.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN019.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN109.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN086.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN061.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN104.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN101.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN056.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN048.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN008.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN078.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN125.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN035.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN022.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN152.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN020.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN030.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN039.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN089.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN083.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN016.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN114.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN142.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN002.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN144.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN137.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN076.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN026.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN020.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN026.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN098.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN097.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN043.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN034.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN100.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN053.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN043.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN096.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN063.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN086.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN069.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN028.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN041.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN105.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN031.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN062.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN018.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN064.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN080.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN007.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN029.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN131.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN093.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN075.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN040.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN014.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN050.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN023.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN044.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN113.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN116.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN005.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN134.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN067.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN126.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN023.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN032.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN015.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN127.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN049.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN051.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN073.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN055.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN045.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN118.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN046.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN124.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN079.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN087.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN012.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN033.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN123.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN003.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN066.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN014.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN031.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN065.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN067.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN003.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN041.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN004.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN017.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN072.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN028.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN037.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN090.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN145.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN027.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN080.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN108.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN095.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN103.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN049.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN111.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN073.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN016.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN010.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN011.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN154.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN034.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN147.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN039.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCNN070.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN094.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN085.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN008.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN012.png  \n",
            "  inflating: /content/tbh+clahe/train/cxrs/JPCLN112.png  \n",
            "   creating: /content/tbh+clahe/train/masks/\n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0096_0.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0092_0.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0057_0.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0150_1.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0282_1.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0062_0.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0213_1.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0056_0.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0063_0.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0023_0.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0331_1.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0049_0.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0040_0.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0031_0.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0043_0.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0309_1.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0166_1.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0393_1.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0027_0.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0275_1.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0091_0.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0081_0.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0030_0.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0058_0.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0387_1.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0243_1.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0041_0.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0008_0.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0354_1.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0046_0.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0011_0.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0044_0.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0367_1.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0006_0.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0375_1.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0015_0.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0264_1.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0086_0.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0079_0.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0228_1.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0311_1.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0099_0.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0064_0.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0042_0.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0075_0.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0055_0.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0085_0.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0255_1.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0052_0.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0029_0.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0002_0.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0020_0.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0113_1.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0094_0.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0054_0.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0021_0.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0253_1.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0038_0.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0301_1.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0104_1.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0059_0.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0095_0.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0102_0.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0142_1.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0060_0.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0090_0.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0144_1.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0203_1.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0035_0.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0218_1.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0019_0.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0390_1.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0022_0.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0196_1.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0289_1.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0069_0.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0141_1.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0082_0.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0372_1.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0399_1.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0294_1.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0350_1.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0117_1.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0103_0.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0097_0.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0313_1.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0162_1.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0001_0.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0182_1.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0334_1.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0254_1.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0053_0.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0140_1.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0223_1.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0087_0.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0074_0.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0352_1.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0316_1.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0188_1.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0100_0.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0004_0.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0362_1.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0348_1.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0089_0.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0026_0.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0068_0.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0016_0.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0251_1.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0003_0.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/MCUCXR_0108_1.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN011.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN070.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN066.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN092.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN053.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN089.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN038.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN007.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN083.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN062.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN076.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN032.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN060.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN133.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN081.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN009.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN136.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN099.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN087.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN058.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN017.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN027.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN057.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN119.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN052.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN044.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN021.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN024.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN018.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN001.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN021.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN013.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN042.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN148.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN140.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN064.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN037.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN077.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN010.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN079.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN153.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN085.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN006.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN036.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN068.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN075.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN013.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN047.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN072.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN141.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN149.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN117.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN093.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN036.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN002.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN130.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN088.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN132.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN081.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN150.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN091.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN082.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN025.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN151.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN055.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN024.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN059.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN084.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN102.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN025.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN033.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN129.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN038.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN022.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN048.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN091.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN061.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN128.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN030.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN056.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN019.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN109.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN086.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN061.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN104.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN101.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN056.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN048.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN008.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN078.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN125.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN035.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN022.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN152.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN020.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN030.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN039.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN089.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN083.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN016.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN114.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN142.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN002.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN144.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN137.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN076.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN026.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN020.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN026.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN098.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN097.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN043.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN034.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN100.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN053.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN043.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN096.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN063.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN086.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN069.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN028.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN041.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN105.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN031.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN062.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN018.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN064.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN080.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN007.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN029.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN131.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN093.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN075.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN040.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN014.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN050.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN023.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN044.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN113.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN116.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN005.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN134.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN067.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN126.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN023.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN032.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN015.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN127.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN049.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN051.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN073.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN055.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN045.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN118.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN046.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN124.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN079.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN087.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN012.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN033.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN123.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN003.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN066.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN014.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN031.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN065.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN067.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN003.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN041.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN004.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN017.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN072.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN028.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN037.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN090.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN145.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN027.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN080.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN108.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN095.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN103.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN049.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN111.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN073.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN016.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN010.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN011.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN154.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN034.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN147.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN039.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCNN070.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN094.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN085.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN008.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN012.png  \n",
            "  inflating: /content/tbh+clahe/train/masks/JPCLN112.png  \n",
            "   creating: /content/tbh+clahe/validation/\n",
            "   creating: /content/tbh+clahe/validation/cxrs/\n",
            "  inflating: /content/tbh+clahe/validation/cxrs/MCUCXR_0369_1.png  \n",
            "  inflating: /content/tbh+clahe/validation/cxrs/MCUCXR_0072_0.png  \n",
            "  inflating: /content/tbh+clahe/validation/cxrs/MCUCXR_0084_0.png  \n",
            "  inflating: /content/tbh+clahe/validation/cxrs/MCUCXR_0195_1.png  \n",
            "  inflating: /content/tbh+clahe/validation/cxrs/MCUCXR_0126_1.png  \n",
            "  inflating: /content/tbh+clahe/validation/cxrs/MCUCXR_0383_1.png  \n",
            "  inflating: /content/tbh+clahe/validation/cxrs/MCUCXR_0028_0.png  \n",
            "  inflating: /content/tbh+clahe/validation/cxrs/MCUCXR_0170_1.png  \n",
            "  inflating: /content/tbh+clahe/validation/cxrs/MCUCXR_0045_0.png  \n",
            "  inflating: /content/tbh+clahe/validation/cxrs/MCUCXR_0258_1.png  \n",
            "  inflating: /content/tbh+clahe/validation/cxrs/MCUCXR_0017_0.png  \n",
            "  inflating: /content/tbh+clahe/validation/cxrs/MCUCXR_0173_1.png  \n",
            "  inflating: /content/tbh+clahe/validation/cxrs/MCUCXR_0194_1.png  \n",
            "  inflating: /content/tbh+clahe/validation/cxrs/MCUCXR_0051_0.png  \n",
            "  inflating: /content/tbh+clahe/validation/cxrs/JPCNN077.png  \n",
            "  inflating: /content/tbh+clahe/validation/cxrs/JPCLN121.png  \n",
            "  inflating: /content/tbh+clahe/validation/cxrs/JPCLN110.png  \n",
            "  inflating: /content/tbh+clahe/validation/cxrs/JPCLN074.png  \n",
            "  inflating: /content/tbh+clahe/validation/cxrs/JPCLN052.png  \n",
            "  inflating: /content/tbh+clahe/validation/cxrs/JPCLN139.png  \n",
            "  inflating: /content/tbh+clahe/validation/cxrs/JPCNN005.png  \n",
            "  inflating: /content/tbh+clahe/validation/cxrs/JPCNN029.png  \n",
            "  inflating: /content/tbh+clahe/validation/cxrs/JPCNN045.png  \n",
            "  inflating: /content/tbh+clahe/validation/cxrs/JPCLN006.png  \n",
            "  inflating: /content/tbh+clahe/validation/cxrs/JPCNN050.png  \n",
            "  inflating: /content/tbh+clahe/validation/cxrs/JPCLN019.png  \n",
            "  inflating: /content/tbh+clahe/validation/cxrs/JPCLN120.png  \n",
            "  inflating: /content/tbh+clahe/validation/cxrs/JPCLN063.png  \n",
            "  inflating: /content/tbh+clahe/validation/cxrs/JPCNN042.png  \n",
            "  inflating: /content/tbh+clahe/validation/cxrs/JPCLN106.png  \n",
            "  inflating: /content/tbh+clahe/validation/cxrs/JPCNN084.png  \n",
            "  inflating: /content/tbh+clahe/validation/cxrs/JPCNN088.png  \n",
            "  inflating: /content/tbh+clahe/validation/cxrs/JPCLN069.png  \n",
            "  inflating: /content/tbh+clahe/validation/cxrs/JPCNN047.png  \n",
            "  inflating: /content/tbh+clahe/validation/cxrs/JPCNN068.png  \n",
            "  inflating: /content/tbh+clahe/validation/cxrs/JPCLN057.png  \n",
            "  inflating: /content/tbh+clahe/validation/cxrs/JPCLN035.png  \n",
            "  inflating: /content/tbh+clahe/validation/cxrs/JPCNN009.png  \n",
            "  inflating: /content/tbh+clahe/validation/cxrs/JPCLN115.png  \n",
            "   creating: /content/tbh+clahe/validation/masks/\n",
            "  inflating: /content/tbh+clahe/validation/masks/MCUCXR_0369_1.png  \n",
            "  inflating: /content/tbh+clahe/validation/masks/MCUCXR_0072_0.png  \n",
            "  inflating: /content/tbh+clahe/validation/masks/MCUCXR_0084_0.png  \n",
            "  inflating: /content/tbh+clahe/validation/masks/MCUCXR_0195_1.png  \n",
            "  inflating: /content/tbh+clahe/validation/masks/MCUCXR_0126_1.png  \n",
            "  inflating: /content/tbh+clahe/validation/masks/MCUCXR_0383_1.png  \n",
            "  inflating: /content/tbh+clahe/validation/masks/MCUCXR_0028_0.png  \n",
            "  inflating: /content/tbh+clahe/validation/masks/MCUCXR_0170_1.png  \n",
            "  inflating: /content/tbh+clahe/validation/masks/MCUCXR_0045_0.png  \n",
            "  inflating: /content/tbh+clahe/validation/masks/MCUCXR_0258_1.png  \n",
            "  inflating: /content/tbh+clahe/validation/masks/MCUCXR_0017_0.png  \n",
            "  inflating: /content/tbh+clahe/validation/masks/MCUCXR_0173_1.png  \n",
            "  inflating: /content/tbh+clahe/validation/masks/MCUCXR_0194_1.png  \n",
            "  inflating: /content/tbh+clahe/validation/masks/MCUCXR_0051_0.png  \n",
            "  inflating: /content/tbh+clahe/validation/masks/JPCNN077.png  \n",
            "  inflating: /content/tbh+clahe/validation/masks/JPCLN121.png  \n",
            "  inflating: /content/tbh+clahe/validation/masks/JPCLN110.png  \n",
            "  inflating: /content/tbh+clahe/validation/masks/JPCLN074.png  \n",
            "  inflating: /content/tbh+clahe/validation/masks/JPCLN052.png  \n",
            "  inflating: /content/tbh+clahe/validation/masks/JPCLN139.png  \n",
            "  inflating: /content/tbh+clahe/validation/masks/JPCNN005.png  \n",
            "  inflating: /content/tbh+clahe/validation/masks/JPCNN029.png  \n",
            "  inflating: /content/tbh+clahe/validation/masks/JPCNN045.png  \n",
            "  inflating: /content/tbh+clahe/validation/masks/JPCLN006.png  \n",
            "  inflating: /content/tbh+clahe/validation/masks/JPCNN050.png  \n",
            "  inflating: /content/tbh+clahe/validation/masks/JPCLN019.png  \n",
            "  inflating: /content/tbh+clahe/validation/masks/JPCLN120.png  \n",
            "  inflating: /content/tbh+clahe/validation/masks/JPCLN063.png  \n",
            "  inflating: /content/tbh+clahe/validation/masks/JPCNN042.png  \n",
            "  inflating: /content/tbh+clahe/validation/masks/JPCLN106.png  \n",
            "  inflating: /content/tbh+clahe/validation/masks/JPCNN084.png  \n",
            "  inflating: /content/tbh+clahe/validation/masks/JPCNN088.png  \n",
            "  inflating: /content/tbh+clahe/validation/masks/JPCLN069.png  \n",
            "  inflating: /content/tbh+clahe/validation/masks/JPCNN047.png  \n",
            "  inflating: /content/tbh+clahe/validation/masks/JPCNN068.png  \n",
            "  inflating: /content/tbh+clahe/validation/masks/JPCLN057.png  \n",
            "  inflating: /content/tbh+clahe/validation/masks/JPCLN035.png  \n",
            "  inflating: /content/tbh+clahe/validation/masks/JPCNN009.png  \n",
            "  inflating: /content/tbh+clahe/validation/masks/JPCLN115.png  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDUhM5ESbw28",
        "outputId": "83c370d8-df60-4660-a35a-3c1afdefbab2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "!pip install efficientnet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting efficientnet\n",
            "  Downloading https://files.pythonhosted.org/packages/53/97/84f88e581d6ac86dcf1ab347c497c4c568c38784e3a2bd659b96912ab793/efficientnet-1.1.1-py3-none-any.whl\n",
            "Collecting keras-applications<=1.0.8,>=1.0.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\r\u001b[K     |██████▌                         | 10kB 30.6MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 20kB 11.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 30kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 40kB 6.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 4.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from efficientnet) (0.16.2)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.18.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (2.10.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (2.5)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (2.4.1)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (7.0.0)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (3.2.2)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (1.1.1)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.15.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image->efficientnet) (4.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (0.10.0)\n",
            "Installing collected packages: keras-applications, efficientnet\n",
            "Successfully installed efficientnet-1.1.1 keras-applications-1.0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-F2YngSbzhk"
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kT5gUHVwcKoy",
        "outputId": "ee41db23-86a2-4c6a-a3ce-7bbb02599806",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from glob import glob\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, LeakyReLU, Add\n",
        "from efficientnet.tfkeras import EfficientNetB4\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import MaxPooling2D, Dropout, Conv2DTranspose, concatenate\n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "from tensorflow.keras.callbacks import *\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Nadam\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set Global Variables and Directories\n",
        "BATCH_SIZE = 5\n",
        "EPOCHS = 250\n",
        "segmentation_train_path = '/content/tbh+clahe/train/'\n",
        "segmentation_validation_path = '/content/tbh+clahe/validation/'\n",
        "segmentation_test_path = '/content/tbh+clahe/test/'\n",
        "segmentation_train_image_path = '/content/tbh+clahe/train/cxrs/'\n",
        "segmentation_validation_image_path = '/content/tbh+clahe/validation/cxrs/'\n",
        "segmentation_test_image_path = '/content/tbh+clahe/test/cxrs/'\n",
        "train_files = glob(os.path.join(segmentation_train_image_path, \"*.png\"))\n",
        "val_files = glob(os.path.join(segmentation_validation_image_path, \"*.png\"))\n",
        "test_files = glob(os.path.join(segmentation_test_image_path, \"*.png\"))\n",
        "\n",
        "\n",
        "# Define Keras Image Data Generators for training and validation sets\n",
        "def train_generator(batch_size, train_path, image_folder, mask_folder, aug_dict,\n",
        "                    image_color_mode=\"rgb\",\n",
        "                    mask_color_mode=\"grayscale\",\n",
        "                    target_size=(512, 512),\n",
        "                    seed=420):\n",
        "    image_datagen = ImageDataGenerator(**aug_dict)\n",
        "    mask_datagen = ImageDataGenerator(**aug_dict)\n",
        "    seed = np.random.randint(seed)\n",
        "    image_generator = image_datagen.flow_from_directory(\n",
        "        train_path,\n",
        "        classes=[image_folder],\n",
        "        class_mode=None,\n",
        "        color_mode=image_color_mode,\n",
        "        target_size=target_size,\n",
        "        batch_size=batch_size,\n",
        "        seed=seed,\n",
        "        shuffle=True)\n",
        "\n",
        "    mask_generator = mask_datagen.flow_from_directory(\n",
        "        train_path,\n",
        "        classes=[mask_folder],\n",
        "        class_mode=None,\n",
        "        color_mode=mask_color_mode,\n",
        "        target_size=target_size,\n",
        "        batch_size=batch_size,\n",
        "        seed=seed,\n",
        "        shuffle=True)\n",
        "\n",
        "    for (img, mask) in zip(image_generator, mask_generator):\n",
        "        img, mask = normalise(img, mask)\n",
        "        yield img, mask\n",
        "\n",
        "\n",
        "def val_generator(batch_size, train_path, image_folder, mask_folder,\n",
        "                  image_color_mode=\"rgb\",\n",
        "                  mask_color_mode=\"grayscale\",\n",
        "                  target_size=(512, 512)):\n",
        "    image_datagen = ImageDataGenerator()\n",
        "    mask_datagen = ImageDataGenerator()\n",
        "    image_generator = image_datagen.flow_from_directory(\n",
        "        train_path,\n",
        "        classes=[image_folder],\n",
        "        class_mode=None,\n",
        "        color_mode=image_color_mode,\n",
        "        target_size=target_size,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False)\n",
        "\n",
        "    mask_generator = mask_datagen.flow_from_directory(\n",
        "        train_path,\n",
        "        classes=[mask_folder],\n",
        "        class_mode=None,\n",
        "        color_mode=mask_color_mode,\n",
        "        target_size=target_size,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False)\n",
        "\n",
        "    for (img, mask) in zip(image_generator, mask_generator):\n",
        "        img, mask = normalise(img, mask)\n",
        "        yield img, mask\n",
        "\n",
        "\n",
        "# Helper Function for normalizing data\n",
        "def normalise(img, mask):\n",
        "    img = img / 255.0\n",
        "    mask = mask / 255.0\n",
        "    mask[mask > 0.5] = 1.0\n",
        "    mask[mask <= 0.5] = 0.0\n",
        "    return img, mask\n",
        "\n",
        "\n",
        "# Define Loss Functions\n",
        "smooth = 1e-6\n",
        "\n",
        "\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "\n",
        "\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    return 1 - dice_coef(y_true, y_pred)\n",
        "\n",
        "\n",
        "def jacard_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + smooth)\n",
        "\n",
        "\n",
        "def generalised_dice_loss_2d(Y_gt, Y_pred):\n",
        "    w = tf.reduce_sum(Y_gt)\n",
        "    w = 1 / (w ** 2 + smooth)\n",
        "\n",
        "    numerator = Y_gt * Y_pred\n",
        "    numerator = w * tf.reduce_sum(numerator)\n",
        "    numerator = tf.reduce_sum(numerator)\n",
        "\n",
        "    denominator = Y_pred + Y_gt\n",
        "    denominator = w * tf.reduce_sum(denominator)\n",
        "    denominator = tf.reduce_sum(denominator)\n",
        "\n",
        "    gen_dice_coef = 2 * numerator / (denominator + smooth)\n",
        "    loss = tf.reduce_mean(1 - gen_dice_coef)\n",
        "    return loss\n",
        "\n",
        "\n",
        "def pgdl(y_true, y_pred):\n",
        "    k = 2.5\n",
        "    gd = generalised_dice_loss_2d(y_true, y_pred)\n",
        "    loss = gd / (1 + k * (1 - gd))\n",
        "    return loss\n",
        "\n",
        "\n",
        "loss_weight = 0.9\n",
        "\n",
        "\n",
        "def loss(y_true, y_pred):\n",
        "    return loss_weight * pgdl(y_true, y_pred) + (1 - loss_weight) * binary_crossentropy(y_true, y_pred)\n",
        "\n",
        "\n",
        "# Define Cyclic LR Schedule Keras Callback\n",
        "class CyclicLR(Callback):\n",
        "    def __init__(self, base_lr=0.001, max_lr=0.006, step_size=2000., mode='triangular',\n",
        "                 gamma=1., scale_fn=None, scale_mode='cycle'):\n",
        "        super(CyclicLR, self).__init__()\n",
        "        self.base_lr = base_lr\n",
        "        self.max_lr = max_lr\n",
        "        self.step_size = step_size\n",
        "        self.mode = mode\n",
        "        self.gamma = gamma\n",
        "        if scale_fn == None:\n",
        "            if self.mode == 'triangular':\n",
        "                self.scale_fn = lambda x: 1.\n",
        "                self.scale_mode = 'cycle'\n",
        "            elif self.mode == 'triangular2':\n",
        "                self.scale_fn = lambda x: 1 / (2. ** (x - 1))\n",
        "                self.scale_mode = 'cycle'\n",
        "            elif self.mode == 'exp_range':\n",
        "                self.scale_fn = lambda x: gamma ** (x)\n",
        "                self.scale_mode = 'iterations'\n",
        "        else:\n",
        "            self.scale_fn = scale_fn\n",
        "            self.scale_mode = scale_mode\n",
        "        self.clr_iterations = 0.\n",
        "        self.trn_iterations = 0.\n",
        "        self.history = {}\n",
        "\n",
        "        self._reset()\n",
        "\n",
        "    def _reset(self, new_base_lr=None, new_max_lr=None,\n",
        "               new_step_size=None):\n",
        "        \"\"\"Resets cycle iterations.\n",
        "        Optional boundary/step size adjustment.\n",
        "        \"\"\"\n",
        "        if new_base_lr != None:\n",
        "            self.base_lr = new_base_lr\n",
        "        if new_max_lr != None:\n",
        "            self.max_lr = new_max_lr\n",
        "        if new_step_size != None:\n",
        "            self.step_size = new_step_size\n",
        "        self.clr_iterations = 0.\n",
        "\n",
        "    def clr(self):\n",
        "        cycle = np.floor(1 + self.clr_iterations / (2 * self.step_size))\n",
        "        x = np.abs(self.clr_iterations / self.step_size - 2 * cycle + 1)\n",
        "        if self.scale_mode == 'cycle':\n",
        "            return self.base_lr + (self.max_lr - self.base_lr) * np.maximum(0, (1 - x)) * self.scale_fn(cycle)\n",
        "        else:\n",
        "            return self.base_lr + (self.max_lr - self.base_lr) * np.maximum(0, (1 - x)) * self.scale_fn(\n",
        "                self.clr_iterations)\n",
        "\n",
        "    def on_train_begin(self, logs={}):\n",
        "        logs = logs or {}\n",
        "\n",
        "        if self.clr_iterations == 0:\n",
        "            K.set_value(self.model.optimizer.lr, self.base_lr)\n",
        "        else:\n",
        "            K.set_value(self.model.optimizer.lr, self.clr())\n",
        "\n",
        "    def on_batch_end(self, epoch, logs=None):\n",
        "\n",
        "        logs = logs or {}\n",
        "        self.trn_iterations += 1\n",
        "        self.clr_iterations += 1\n",
        "\n",
        "        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))\n",
        "        self.history.setdefault('iterations', []).append(self.trn_iterations)\n",
        "\n",
        "        for k, v in logs.items():\n",
        "            self.history.setdefault(k, []).append(v)\n",
        "\n",
        "        K.set_value(self.model.optimizer.lr, self.clr())\n",
        "\n",
        "\n",
        "# Define helper blocks for DCNN\n",
        "def convolution_block(x, filters, size, strides=(1, 1), padding='same', activation=True):\n",
        "    x = Conv2D(filters, size, strides=strides, padding=padding)(x)\n",
        "    if activation:\n",
        "        x = LeakyReLU(alpha=0.1)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def residual_block(blockInput, num_filters=16):\n",
        "    x = LeakyReLU(alpha=0.1)(blockInput)\n",
        "    x = BatchNormalization()(x)\n",
        "    blockInput = BatchNormalization()(blockInput)\n",
        "    x = convolution_block(x, num_filters, (3, 3))\n",
        "    x = convolution_block(x, num_filters, (3, 3), activation=False)\n",
        "    x = Add()([x, blockInput])\n",
        "    return x\n",
        "\n",
        "\n",
        "# Define U-Net++ with Efficient Net B4 as backbone/encoder architecture:\n",
        "def UNetplusplus_efficientnet(input_shape=(None, None, 3), dropout_rate=0.1):\n",
        "    backbone = EfficientNetB4(weights='imagenet',\n",
        "                              include_top=False,\n",
        "                              input_shape=input_shape)\n",
        "    input = backbone.input\n",
        "\n",
        "    # Encoder\n",
        "    x_0_0 = backbone.layers[28].output\n",
        "    x_1_0 = backbone.layers[86].output\n",
        "    x_2_0 = backbone.layers[144].output\n",
        "    x_3_0 = backbone.layers[320].output\n",
        "    x_3_0 = LeakyReLU(alpha=0.1)(x_3_0)\n",
        "\n",
        "    # Middle\n",
        "    start_neurons = 8\n",
        "    x_4_0 = MaxPooling2D((2, 2))(x_3_0)\n",
        "    x_4_0 = Dropout(dropout_rate)(x_4_0)\n",
        "    x_4_0 = Conv2D(start_neurons * 32, (3, 3), activation=None, padding=\"same\", name='conv_middle')(x_4_0)\n",
        "    x_4_0 = residual_block(x_4_0, start_neurons * 32)\n",
        "    x_4_0 = residual_block(x_4_0, start_neurons * 32)\n",
        "    x_4_0 = LeakyReLU(alpha=0.1)(x_4_0)\n",
        "\n",
        "    # Decoder\n",
        "    x_3_1 = Conv2DTranspose(start_neurons * 16, (3, 3), strides=(2, 2), padding=\"same\")(x_4_0)\n",
        "    x_3_1 = concatenate([x_3_1, x_3_0])\n",
        "    x_3_1 = Dropout(dropout_rate)(x_3_1)\n",
        "    x_3_1 = Conv2D(start_neurons * 16, (3, 3), activation=None, padding=\"same\")(x_3_1)\n",
        "    x_3_1 = residual_block(x_3_1, start_neurons * 16)\n",
        "    x_3_1 = residual_block(x_3_1, start_neurons * 16)\n",
        "    x_3_1 = LeakyReLU(alpha=0.1)(x_3_1)\n",
        "\n",
        "    x_2_1 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(x_3_0)\n",
        "    x_2_1 = concatenate([x_2_1, x_2_0])\n",
        "    x_2_1 = Dropout(dropout_rate)(x_2_1)\n",
        "    x_2_1 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(x_2_1)\n",
        "    x_2_1 = residual_block(x_2_1, start_neurons * 8)\n",
        "    x_2_1 = residual_block(x_2_1, start_neurons * 8)\n",
        "    x_2_1 = LeakyReLU(alpha=0.1)(x_2_1)\n",
        "\n",
        "    x_2_2 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(x_3_1)\n",
        "    x_2_2 = concatenate([x_2_2, x_2_1, x_2_0])\n",
        "    x_2_2 = Dropout(dropout_rate)(x_2_2)\n",
        "    x_2_2 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(x_2_2)\n",
        "    x_2_2 = residual_block(x_2_2, start_neurons * 8)\n",
        "    x_2_2 = residual_block(x_2_2, start_neurons * 8)\n",
        "    x_2_2 = LeakyReLU(alpha=0.1)(x_2_2)\n",
        "\n",
        "    x_1_1 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(x_2_0)\n",
        "    x_1_1 = concatenate([x_1_1, x_1_0])\n",
        "    x_1_1 = Dropout(dropout_rate)(x_1_1)\n",
        "    x_1_1 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(x_1_1)\n",
        "    x_1_1 = residual_block(x_1_1, start_neurons * 4)\n",
        "    x_1_1 = residual_block(x_1_1, start_neurons * 4)\n",
        "    x_1_1 = LeakyReLU(alpha=0.1)(x_1_1)\n",
        "\n",
        "    x_1_2 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(x_2_1)\n",
        "    x_1_2 = concatenate([x_1_2, x_1_1, x_1_0])\n",
        "    x_1_2 = Dropout(dropout_rate)(x_1_2)\n",
        "    x_1_2 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(x_1_2)\n",
        "    x_1_2 = residual_block(x_1_2, start_neurons * 4)\n",
        "    x_1_2 = residual_block(x_1_2, start_neurons * 4)\n",
        "    x_1_2 = LeakyReLU(alpha=0.1)(x_1_2)\n",
        "\n",
        "    x_1_3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(x_2_2)\n",
        "    x_1_3 = concatenate([x_1_3, x_1_2, x_1_1, x_1_0])\n",
        "    x_1_3 = Dropout(dropout_rate)(x_1_3)\n",
        "    x_1_3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(x_1_3)\n",
        "    x_1_3 = residual_block(x_1_3, start_neurons * 4)\n",
        "    x_1_3 = residual_block(x_1_3, start_neurons * 4)\n",
        "    x_1_3 = LeakyReLU(alpha=0.1)(x_1_3)\n",
        "\n",
        "    x_0_1 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(x_1_0)\n",
        "    x_0_1 = concatenate([x_0_1, x_0_0])\n",
        "    x_0_1 = Dropout(dropout_rate)(x_0_1)\n",
        "    x_0_1 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(x_0_1)\n",
        "    x_0_1 = residual_block(x_0_1, start_neurons * 2)\n",
        "    x_0_1 = residual_block(x_0_1, start_neurons * 2)\n",
        "    x_0_1 = LeakyReLU(alpha=0.1)(x_0_1)\n",
        "\n",
        "    x_0_2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(x_1_1)\n",
        "    x_0_2 = concatenate([x_0_2, x_0_1, x_0_0])\n",
        "    x_0_2 = Dropout(dropout_rate)(x_0_2)\n",
        "    x_0_2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(x_0_2)\n",
        "    x_0_2 = residual_block(x_0_2, start_neurons * 2)\n",
        "    x_0_2 = residual_block(x_0_2, start_neurons * 2)\n",
        "    x_0_2 = LeakyReLU(alpha=0.1)(x_0_2)\n",
        "\n",
        "    x_0_3 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(x_1_2)\n",
        "    x_0_3 = concatenate([x_0_3, x_0_2, x_0_1, x_0_0])\n",
        "    x_0_3 = Dropout(dropout_rate)(x_0_3)\n",
        "    x_0_3 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(x_0_3)\n",
        "    x_0_3 = residual_block(x_0_3, start_neurons * 2)\n",
        "    x_0_3 = residual_block(x_0_3, start_neurons * 2)\n",
        "    x_0_3 = LeakyReLU(alpha=0.1)(x_0_3)\n",
        "\n",
        "    x_0_4 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(x_1_3)\n",
        "    x_0_4 = concatenate([x_0_4, x_0_3, x_0_2, x_0_1, x_0_0])\n",
        "    x_0_4 = Dropout(dropout_rate)(x_0_4)\n",
        "    x_0_4 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(x_0_4)\n",
        "    x_0_4 = residual_block(x_0_4, start_neurons * 2)\n",
        "    x_0_4 = residual_block(x_0_4, start_neurons * 2)\n",
        "    x_0_4 = LeakyReLU(alpha=0.1)(x_0_4)\n",
        "    \n",
        "    x_0_4 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(x_0_4)\n",
        "    x_0_4 = Dropout(dropout_rate)(x_0_4)\n",
        "    x_0_4 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(x_0_4)\n",
        "    x_0_4 = residual_block(x_0_4, start_neurons * 1)\n",
        "    x_0_4 = residual_block(x_0_4, start_neurons * 1)\n",
        "    x_0_4 = LeakyReLU(alpha=0.1)(x_0_4)\n",
        "    x_0_4 = Dropout(dropout_rate / 2)(x_0_4)\n",
        "\n",
        "    output_layer = Conv2D(1, (1, 1), padding=\"same\", activation=\"sigmoid\")(x_0_4)\n",
        "\n",
        "    model = Model(input, output_layer)\n",
        "    return model\n",
        "\n",
        "\n",
        "# Initiate Model Compilation\n",
        "img_size = 512\n",
        "model = UNetplusplus_efficientnet(input_shape=(img_size, img_size, 3), dropout_rate=0.5)\n",
        "model.summary()\n",
        "model.compile(optimizer=Nadam(), loss=loss,\n",
        "              metrics=[binary_crossentropy, dice_coef, jacard_coef, 'binary_accuracy'])\n",
        "\n",
        "# Define all remaining keras callbacks\n",
        "model_checkpoint = ModelCheckpoint('net_lung_seg.hdf5',\n",
        "                                   monitor='val_dice_coef',\n",
        "                                   verbose=1,\n",
        "                                   save_best_only=True,\n",
        "                                   mode='max')\n",
        "\n",
        "log_dir = \"logs/history_plotter/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "clr = CyclicLR(base_lr=5e-4, max_lr=1e-3, step_size=10 * len(train_files) / BATCH_SIZE, mode='triangular')\n",
        "\n",
        "callbacks = [model_checkpoint,\n",
        "             clr,\n",
        "             tensorboard_callback]\n",
        "\n",
        "train_generator_args = dict(rotation_range=0.5,\n",
        "                            width_shift_range=0.025,\n",
        "                            height_shift_range=0.025,\n",
        "                            shear_range=0.025,\n",
        "                            zoom_range=0.025,\n",
        "                            horizontal_flip=True,\n",
        "                            fill_mode='nearest',\n",
        "                            cval=0)\n",
        "# Initialize Generators\n",
        "train_gen = train_generator(BATCH_SIZE,\n",
        "                            segmentation_train_path,\n",
        "                            'cxrs',\n",
        "                            'masks',\n",
        "                            train_generator_args,\n",
        "                            target_size=(512, 512))\n",
        "\n",
        "val_gen = val_generator(BATCH_SIZE,\n",
        "                        segmentation_validation_path,\n",
        "                        'cxrs',\n",
        "                        'masks',\n",
        "                        target_size=(512, 512))\n",
        "# Train Model\n",
        "history = model.fit_generator(train_gen,\n",
        "                              steps_per_epoch=len(train_files) / BATCH_SIZE,\n",
        "                              epochs=EPOCHS,\n",
        "                              callbacks=callbacks,\n",
        "                              validation_data=val_gen,\n",
        "                              validation_steps=len(val_files) / BATCH_SIZE)\n",
        "\n",
        "h = clr.history"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/Callidior/keras-applications/releases/download/efficientnet/efficientnet-b4_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5\n",
            "71892992/71892840 [==============================] - 2s 0us/step\n",
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 512, 512, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "stem_conv (Conv2D)              (None, 256, 256, 48) 1296        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "stem_bn (BatchNormalization)    (None, 256, 256, 48) 192         stem_conv[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "stem_activation (Activation)    (None, 256, 256, 48) 0           stem_bn[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block1a_dwconv (DepthwiseConv2D (None, 256, 256, 48) 432         stem_activation[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block1a_bn (BatchNormalization) (None, 256, 256, 48) 192         block1a_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block1a_activation (Activation) (None, 256, 256, 48) 0           block1a_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block1a_se_squeeze (GlobalAvera (None, 48)           0           block1a_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block1a_se_reshape (Reshape)    (None, 1, 1, 48)     0           block1a_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block1a_se_reduce (Conv2D)      (None, 1, 1, 12)     588         block1a_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block1a_se_expand (Conv2D)      (None, 1, 1, 48)     624         block1a_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block1a_se_excite (Multiply)    (None, 256, 256, 48) 0           block1a_activation[0][0]         \n",
            "                                                                 block1a_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block1a_project_conv (Conv2D)   (None, 256, 256, 24) 1152        block1a_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block1a_project_bn (BatchNormal (None, 256, 256, 24) 96          block1a_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block1b_dwconv (DepthwiseConv2D (None, 256, 256, 24) 216         block1a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block1b_bn (BatchNormalization) (None, 256, 256, 24) 96          block1b_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block1b_activation (Activation) (None, 256, 256, 24) 0           block1b_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block1b_se_squeeze (GlobalAvera (None, 24)           0           block1b_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block1b_se_reshape (Reshape)    (None, 1, 1, 24)     0           block1b_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block1b_se_reduce (Conv2D)      (None, 1, 1, 6)      150         block1b_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block1b_se_expand (Conv2D)      (None, 1, 1, 24)     168         block1b_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block1b_se_excite (Multiply)    (None, 256, 256, 24) 0           block1b_activation[0][0]         \n",
            "                                                                 block1b_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block1b_project_conv (Conv2D)   (None, 256, 256, 24) 576         block1b_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block1b_project_bn (BatchNormal (None, 256, 256, 24) 96          block1b_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block1b_drop (FixedDropout)     (None, 256, 256, 24) 0           block1b_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block1b_add (Add)               (None, 256, 256, 24) 0           block1b_drop[0][0]               \n",
            "                                                                 block1a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2a_expand_conv (Conv2D)    (None, 256, 256, 144 3456        block1b_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block2a_expand_bn (BatchNormali (None, 256, 256, 144 576         block2a_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block2a_expand_activation (Acti (None, 256, 256, 144 0           block2a_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2a_dwconv (DepthwiseConv2D (None, 128, 128, 144 1296        block2a_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block2a_bn (BatchNormalization) (None, 128, 128, 144 576         block2a_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block2a_activation (Activation) (None, 128, 128, 144 0           block2a_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block2a_se_squeeze (GlobalAvera (None, 144)          0           block2a_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2a_se_reshape (Reshape)    (None, 1, 1, 144)    0           block2a_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2a_se_reduce (Conv2D)      (None, 1, 1, 6)      870         block2a_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2a_se_expand (Conv2D)      (None, 1, 1, 144)    1008        block2a_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2a_se_excite (Multiply)    (None, 128, 128, 144 0           block2a_activation[0][0]         \n",
            "                                                                 block2a_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2a_project_conv (Conv2D)   (None, 128, 128, 32) 4608        block2a_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2a_project_bn (BatchNormal (None, 128, 128, 32) 128         block2a_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block2b_expand_conv (Conv2D)    (None, 128, 128, 192 6144        block2a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2b_expand_bn (BatchNormali (None, 128, 128, 192 768         block2b_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block2b_expand_activation (Acti (None, 128, 128, 192 0           block2b_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2b_dwconv (DepthwiseConv2D (None, 128, 128, 192 1728        block2b_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block2b_bn (BatchNormalization) (None, 128, 128, 192 768         block2b_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block2b_activation (Activation) (None, 128, 128, 192 0           block2b_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block2b_se_squeeze (GlobalAvera (None, 192)          0           block2b_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2b_se_reshape (Reshape)    (None, 1, 1, 192)    0           block2b_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2b_se_reduce (Conv2D)      (None, 1, 1, 8)      1544        block2b_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2b_se_expand (Conv2D)      (None, 1, 1, 192)    1728        block2b_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2b_se_excite (Multiply)    (None, 128, 128, 192 0           block2b_activation[0][0]         \n",
            "                                                                 block2b_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2b_project_conv (Conv2D)   (None, 128, 128, 32) 6144        block2b_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2b_project_bn (BatchNormal (None, 128, 128, 32) 128         block2b_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block2b_drop (FixedDropout)     (None, 128, 128, 32) 0           block2b_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2b_add (Add)               (None, 128, 128, 32) 0           block2b_drop[0][0]               \n",
            "                                                                 block2a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2c_expand_conv (Conv2D)    (None, 128, 128, 192 6144        block2b_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block2c_expand_bn (BatchNormali (None, 128, 128, 192 768         block2c_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block2c_expand_activation (Acti (None, 128, 128, 192 0           block2c_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2c_dwconv (DepthwiseConv2D (None, 128, 128, 192 1728        block2c_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block2c_bn (BatchNormalization) (None, 128, 128, 192 768         block2c_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block2c_activation (Activation) (None, 128, 128, 192 0           block2c_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block2c_se_squeeze (GlobalAvera (None, 192)          0           block2c_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2c_se_reshape (Reshape)    (None, 1, 1, 192)    0           block2c_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2c_se_reduce (Conv2D)      (None, 1, 1, 8)      1544        block2c_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2c_se_expand (Conv2D)      (None, 1, 1, 192)    1728        block2c_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2c_se_excite (Multiply)    (None, 128, 128, 192 0           block2c_activation[0][0]         \n",
            "                                                                 block2c_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2c_project_conv (Conv2D)   (None, 128, 128, 32) 6144        block2c_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2c_project_bn (BatchNormal (None, 128, 128, 32) 128         block2c_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block2c_drop (FixedDropout)     (None, 128, 128, 32) 0           block2c_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2c_add (Add)               (None, 128, 128, 32) 0           block2c_drop[0][0]               \n",
            "                                                                 block2b_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block2d_expand_conv (Conv2D)    (None, 128, 128, 192 6144        block2c_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block2d_expand_bn (BatchNormali (None, 128, 128, 192 768         block2d_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block2d_expand_activation (Acti (None, 128, 128, 192 0           block2d_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2d_dwconv (DepthwiseConv2D (None, 128, 128, 192 1728        block2d_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block2d_bn (BatchNormalization) (None, 128, 128, 192 768         block2d_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block2d_activation (Activation) (None, 128, 128, 192 0           block2d_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block2d_se_squeeze (GlobalAvera (None, 192)          0           block2d_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2d_se_reshape (Reshape)    (None, 1, 1, 192)    0           block2d_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2d_se_reduce (Conv2D)      (None, 1, 1, 8)      1544        block2d_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2d_se_expand (Conv2D)      (None, 1, 1, 192)    1728        block2d_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2d_se_excite (Multiply)    (None, 128, 128, 192 0           block2d_activation[0][0]         \n",
            "                                                                 block2d_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2d_project_conv (Conv2D)   (None, 128, 128, 32) 6144        block2d_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2d_project_bn (BatchNormal (None, 128, 128, 32) 128         block2d_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block2d_drop (FixedDropout)     (None, 128, 128, 32) 0           block2d_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2d_add (Add)               (None, 128, 128, 32) 0           block2d_drop[0][0]               \n",
            "                                                                 block2c_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block3a_expand_conv (Conv2D)    (None, 128, 128, 192 6144        block2d_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block3a_expand_bn (BatchNormali (None, 128, 128, 192 768         block3a_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3a_expand_activation (Acti (None, 128, 128, 192 0           block3a_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3a_dwconv (DepthwiseConv2D (None, 64, 64, 192)  4800        block3a_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block3a_bn (BatchNormalization) (None, 64, 64, 192)  768         block3a_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block3a_activation (Activation) (None, 64, 64, 192)  0           block3a_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block3a_se_squeeze (GlobalAvera (None, 192)          0           block3a_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3a_se_reshape (Reshape)    (None, 1, 1, 192)    0           block3a_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3a_se_reduce (Conv2D)      (None, 1, 1, 8)      1544        block3a_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3a_se_expand (Conv2D)      (None, 1, 1, 192)    1728        block3a_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3a_se_excite (Multiply)    (None, 64, 64, 192)  0           block3a_activation[0][0]         \n",
            "                                                                 block3a_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3a_project_conv (Conv2D)   (None, 64, 64, 56)   10752       block3a_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3a_project_bn (BatchNormal (None, 64, 64, 56)   224         block3a_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block3b_expand_conv (Conv2D)    (None, 64, 64, 336)  18816       block3a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3b_expand_bn (BatchNormali (None, 64, 64, 336)  1344        block3b_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3b_expand_activation (Acti (None, 64, 64, 336)  0           block3b_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3b_dwconv (DepthwiseConv2D (None, 64, 64, 336)  8400        block3b_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block3b_bn (BatchNormalization) (None, 64, 64, 336)  1344        block3b_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block3b_activation (Activation) (None, 64, 64, 336)  0           block3b_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block3b_se_squeeze (GlobalAvera (None, 336)          0           block3b_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3b_se_reshape (Reshape)    (None, 1, 1, 336)    0           block3b_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3b_se_reduce (Conv2D)      (None, 1, 1, 14)     4718        block3b_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3b_se_expand (Conv2D)      (None, 1, 1, 336)    5040        block3b_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3b_se_excite (Multiply)    (None, 64, 64, 336)  0           block3b_activation[0][0]         \n",
            "                                                                 block3b_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3b_project_conv (Conv2D)   (None, 64, 64, 56)   18816       block3b_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3b_project_bn (BatchNormal (None, 64, 64, 56)   224         block3b_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block3b_drop (FixedDropout)     (None, 64, 64, 56)   0           block3b_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3b_add (Add)               (None, 64, 64, 56)   0           block3b_drop[0][0]               \n",
            "                                                                 block3a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3c_expand_conv (Conv2D)    (None, 64, 64, 336)  18816       block3b_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block3c_expand_bn (BatchNormali (None, 64, 64, 336)  1344        block3c_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3c_expand_activation (Acti (None, 64, 64, 336)  0           block3c_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3c_dwconv (DepthwiseConv2D (None, 64, 64, 336)  8400        block3c_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block3c_bn (BatchNormalization) (None, 64, 64, 336)  1344        block3c_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block3c_activation (Activation) (None, 64, 64, 336)  0           block3c_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block3c_se_squeeze (GlobalAvera (None, 336)          0           block3c_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3c_se_reshape (Reshape)    (None, 1, 1, 336)    0           block3c_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3c_se_reduce (Conv2D)      (None, 1, 1, 14)     4718        block3c_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3c_se_expand (Conv2D)      (None, 1, 1, 336)    5040        block3c_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3c_se_excite (Multiply)    (None, 64, 64, 336)  0           block3c_activation[0][0]         \n",
            "                                                                 block3c_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3c_project_conv (Conv2D)   (None, 64, 64, 56)   18816       block3c_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3c_project_bn (BatchNormal (None, 64, 64, 56)   224         block3c_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block3c_drop (FixedDropout)     (None, 64, 64, 56)   0           block3c_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3c_add (Add)               (None, 64, 64, 56)   0           block3c_drop[0][0]               \n",
            "                                                                 block3b_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block3d_expand_conv (Conv2D)    (None, 64, 64, 336)  18816       block3c_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block3d_expand_bn (BatchNormali (None, 64, 64, 336)  1344        block3d_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3d_expand_activation (Acti (None, 64, 64, 336)  0           block3d_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3d_dwconv (DepthwiseConv2D (None, 64, 64, 336)  8400        block3d_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block3d_bn (BatchNormalization) (None, 64, 64, 336)  1344        block3d_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block3d_activation (Activation) (None, 64, 64, 336)  0           block3d_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block3d_se_squeeze (GlobalAvera (None, 336)          0           block3d_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3d_se_reshape (Reshape)    (None, 1, 1, 336)    0           block3d_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3d_se_reduce (Conv2D)      (None, 1, 1, 14)     4718        block3d_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3d_se_expand (Conv2D)      (None, 1, 1, 336)    5040        block3d_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3d_se_excite (Multiply)    (None, 64, 64, 336)  0           block3d_activation[0][0]         \n",
            "                                                                 block3d_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3d_project_conv (Conv2D)   (None, 64, 64, 56)   18816       block3d_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3d_project_bn (BatchNormal (None, 64, 64, 56)   224         block3d_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block3d_drop (FixedDropout)     (None, 64, 64, 56)   0           block3d_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3d_add (Add)               (None, 64, 64, 56)   0           block3d_drop[0][0]               \n",
            "                                                                 block3c_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4a_expand_conv (Conv2D)    (None, 64, 64, 336)  18816       block3d_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4a_expand_bn (BatchNormali (None, 64, 64, 336)  1344        block4a_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4a_expand_activation (Acti (None, 64, 64, 336)  0           block4a_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4a_dwconv (DepthwiseConv2D (None, 32, 32, 336)  3024        block4a_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block4a_bn (BatchNormalization) (None, 32, 32, 336)  1344        block4a_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block4a_activation (Activation) (None, 32, 32, 336)  0           block4a_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block4a_se_squeeze (GlobalAvera (None, 336)          0           block4a_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4a_se_reshape (Reshape)    (None, 1, 1, 336)    0           block4a_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4a_se_reduce (Conv2D)      (None, 1, 1, 14)     4718        block4a_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4a_se_expand (Conv2D)      (None, 1, 1, 336)    5040        block4a_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4a_se_excite (Multiply)    (None, 32, 32, 336)  0           block4a_activation[0][0]         \n",
            "                                                                 block4a_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4a_project_conv (Conv2D)   (None, 32, 32, 112)  37632       block4a_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4a_project_bn (BatchNormal (None, 32, 32, 112)  448         block4a_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block4b_expand_conv (Conv2D)    (None, 32, 32, 672)  75264       block4a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4b_expand_bn (BatchNormali (None, 32, 32, 672)  2688        block4b_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4b_expand_activation (Acti (None, 32, 32, 672)  0           block4b_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4b_dwconv (DepthwiseConv2D (None, 32, 32, 672)  6048        block4b_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block4b_bn (BatchNormalization) (None, 32, 32, 672)  2688        block4b_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block4b_activation (Activation) (None, 32, 32, 672)  0           block4b_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block4b_se_squeeze (GlobalAvera (None, 672)          0           block4b_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4b_se_reshape (Reshape)    (None, 1, 1, 672)    0           block4b_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4b_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block4b_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4b_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block4b_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4b_se_excite (Multiply)    (None, 32, 32, 672)  0           block4b_activation[0][0]         \n",
            "                                                                 block4b_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4b_project_conv (Conv2D)   (None, 32, 32, 112)  75264       block4b_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4b_project_bn (BatchNormal (None, 32, 32, 112)  448         block4b_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block4b_drop (FixedDropout)     (None, 32, 32, 112)  0           block4b_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4b_add (Add)               (None, 32, 32, 112)  0           block4b_drop[0][0]               \n",
            "                                                                 block4a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4c_expand_conv (Conv2D)    (None, 32, 32, 672)  75264       block4b_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4c_expand_bn (BatchNormali (None, 32, 32, 672)  2688        block4c_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4c_expand_activation (Acti (None, 32, 32, 672)  0           block4c_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4c_dwconv (DepthwiseConv2D (None, 32, 32, 672)  6048        block4c_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block4c_bn (BatchNormalization) (None, 32, 32, 672)  2688        block4c_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block4c_activation (Activation) (None, 32, 32, 672)  0           block4c_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block4c_se_squeeze (GlobalAvera (None, 672)          0           block4c_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4c_se_reshape (Reshape)    (None, 1, 1, 672)    0           block4c_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4c_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block4c_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4c_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block4c_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4c_se_excite (Multiply)    (None, 32, 32, 672)  0           block4c_activation[0][0]         \n",
            "                                                                 block4c_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4c_project_conv (Conv2D)   (None, 32, 32, 112)  75264       block4c_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4c_project_bn (BatchNormal (None, 32, 32, 112)  448         block4c_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block4c_drop (FixedDropout)     (None, 32, 32, 112)  0           block4c_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4c_add (Add)               (None, 32, 32, 112)  0           block4c_drop[0][0]               \n",
            "                                                                 block4b_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4d_expand_conv (Conv2D)    (None, 32, 32, 672)  75264       block4c_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4d_expand_bn (BatchNormali (None, 32, 32, 672)  2688        block4d_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4d_expand_activation (Acti (None, 32, 32, 672)  0           block4d_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4d_dwconv (DepthwiseConv2D (None, 32, 32, 672)  6048        block4d_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block4d_bn (BatchNormalization) (None, 32, 32, 672)  2688        block4d_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block4d_activation (Activation) (None, 32, 32, 672)  0           block4d_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block4d_se_squeeze (GlobalAvera (None, 672)          0           block4d_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4d_se_reshape (Reshape)    (None, 1, 1, 672)    0           block4d_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4d_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block4d_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4d_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block4d_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4d_se_excite (Multiply)    (None, 32, 32, 672)  0           block4d_activation[0][0]         \n",
            "                                                                 block4d_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4d_project_conv (Conv2D)   (None, 32, 32, 112)  75264       block4d_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4d_project_bn (BatchNormal (None, 32, 32, 112)  448         block4d_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block4d_drop (FixedDropout)     (None, 32, 32, 112)  0           block4d_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4d_add (Add)               (None, 32, 32, 112)  0           block4d_drop[0][0]               \n",
            "                                                                 block4c_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4e_expand_conv (Conv2D)    (None, 32, 32, 672)  75264       block4d_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4e_expand_bn (BatchNormali (None, 32, 32, 672)  2688        block4e_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4e_expand_activation (Acti (None, 32, 32, 672)  0           block4e_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4e_dwconv (DepthwiseConv2D (None, 32, 32, 672)  6048        block4e_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block4e_bn (BatchNormalization) (None, 32, 32, 672)  2688        block4e_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block4e_activation (Activation) (None, 32, 32, 672)  0           block4e_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block4e_se_squeeze (GlobalAvera (None, 672)          0           block4e_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4e_se_reshape (Reshape)    (None, 1, 1, 672)    0           block4e_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4e_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block4e_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4e_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block4e_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4e_se_excite (Multiply)    (None, 32, 32, 672)  0           block4e_activation[0][0]         \n",
            "                                                                 block4e_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4e_project_conv (Conv2D)   (None, 32, 32, 112)  75264       block4e_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4e_project_bn (BatchNormal (None, 32, 32, 112)  448         block4e_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block4e_drop (FixedDropout)     (None, 32, 32, 112)  0           block4e_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4e_add (Add)               (None, 32, 32, 112)  0           block4e_drop[0][0]               \n",
            "                                                                 block4d_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4f_expand_conv (Conv2D)    (None, 32, 32, 672)  75264       block4e_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4f_expand_bn (BatchNormali (None, 32, 32, 672)  2688        block4f_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4f_expand_activation (Acti (None, 32, 32, 672)  0           block4f_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4f_dwconv (DepthwiseConv2D (None, 32, 32, 672)  6048        block4f_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block4f_bn (BatchNormalization) (None, 32, 32, 672)  2688        block4f_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block4f_activation (Activation) (None, 32, 32, 672)  0           block4f_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block4f_se_squeeze (GlobalAvera (None, 672)          0           block4f_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4f_se_reshape (Reshape)    (None, 1, 1, 672)    0           block4f_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4f_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block4f_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4f_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block4f_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4f_se_excite (Multiply)    (None, 32, 32, 672)  0           block4f_activation[0][0]         \n",
            "                                                                 block4f_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4f_project_conv (Conv2D)   (None, 32, 32, 112)  75264       block4f_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4f_project_bn (BatchNormal (None, 32, 32, 112)  448         block4f_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block4f_drop (FixedDropout)     (None, 32, 32, 112)  0           block4f_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4f_add (Add)               (None, 32, 32, 112)  0           block4f_drop[0][0]               \n",
            "                                                                 block4e_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5a_expand_conv (Conv2D)    (None, 32, 32, 672)  75264       block4f_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5a_expand_bn (BatchNormali (None, 32, 32, 672)  2688        block5a_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5a_expand_activation (Acti (None, 32, 32, 672)  0           block5a_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5a_dwconv (DepthwiseConv2D (None, 32, 32, 672)  16800       block5a_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block5a_bn (BatchNormalization) (None, 32, 32, 672)  2688        block5a_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block5a_activation (Activation) (None, 32, 32, 672)  0           block5a_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block5a_se_squeeze (GlobalAvera (None, 672)          0           block5a_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5a_se_reshape (Reshape)    (None, 1, 1, 672)    0           block5a_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5a_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block5a_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5a_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block5a_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5a_se_excite (Multiply)    (None, 32, 32, 672)  0           block5a_activation[0][0]         \n",
            "                                                                 block5a_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5a_project_conv (Conv2D)   (None, 32, 32, 160)  107520      block5a_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5a_project_bn (BatchNormal (None, 32, 32, 160)  640         block5a_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block5b_expand_conv (Conv2D)    (None, 32, 32, 960)  153600      block5a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5b_expand_bn (BatchNormali (None, 32, 32, 960)  3840        block5b_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5b_expand_activation (Acti (None, 32, 32, 960)  0           block5b_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5b_dwconv (DepthwiseConv2D (None, 32, 32, 960)  24000       block5b_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block5b_bn (BatchNormalization) (None, 32, 32, 960)  3840        block5b_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block5b_activation (Activation) (None, 32, 32, 960)  0           block5b_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block5b_se_squeeze (GlobalAvera (None, 960)          0           block5b_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5b_se_reshape (Reshape)    (None, 1, 1, 960)    0           block5b_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5b_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block5b_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5b_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block5b_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5b_se_excite (Multiply)    (None, 32, 32, 960)  0           block5b_activation[0][0]         \n",
            "                                                                 block5b_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5b_project_conv (Conv2D)   (None, 32, 32, 160)  153600      block5b_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5b_project_bn (BatchNormal (None, 32, 32, 160)  640         block5b_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block5b_drop (FixedDropout)     (None, 32, 32, 160)  0           block5b_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5b_add (Add)               (None, 32, 32, 160)  0           block5b_drop[0][0]               \n",
            "                                                                 block5a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5c_expand_conv (Conv2D)    (None, 32, 32, 960)  153600      block5b_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5c_expand_bn (BatchNormali (None, 32, 32, 960)  3840        block5c_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5c_expand_activation (Acti (None, 32, 32, 960)  0           block5c_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5c_dwconv (DepthwiseConv2D (None, 32, 32, 960)  24000       block5c_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block5c_bn (BatchNormalization) (None, 32, 32, 960)  3840        block5c_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block5c_activation (Activation) (None, 32, 32, 960)  0           block5c_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block5c_se_squeeze (GlobalAvera (None, 960)          0           block5c_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5c_se_reshape (Reshape)    (None, 1, 1, 960)    0           block5c_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5c_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block5c_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5c_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block5c_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5c_se_excite (Multiply)    (None, 32, 32, 960)  0           block5c_activation[0][0]         \n",
            "                                                                 block5c_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5c_project_conv (Conv2D)   (None, 32, 32, 160)  153600      block5c_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5c_project_bn (BatchNormal (None, 32, 32, 160)  640         block5c_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block5c_drop (FixedDropout)     (None, 32, 32, 160)  0           block5c_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5c_add (Add)               (None, 32, 32, 160)  0           block5c_drop[0][0]               \n",
            "                                                                 block5b_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5d_expand_conv (Conv2D)    (None, 32, 32, 960)  153600      block5c_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5d_expand_bn (BatchNormali (None, 32, 32, 960)  3840        block5d_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5d_expand_activation (Acti (None, 32, 32, 960)  0           block5d_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5d_dwconv (DepthwiseConv2D (None, 32, 32, 960)  24000       block5d_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block5d_bn (BatchNormalization) (None, 32, 32, 960)  3840        block5d_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block5d_activation (Activation) (None, 32, 32, 960)  0           block5d_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block5d_se_squeeze (GlobalAvera (None, 960)          0           block5d_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5d_se_reshape (Reshape)    (None, 1, 1, 960)    0           block5d_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5d_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block5d_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5d_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block5d_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5d_se_excite (Multiply)    (None, 32, 32, 960)  0           block5d_activation[0][0]         \n",
            "                                                                 block5d_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5d_project_conv (Conv2D)   (None, 32, 32, 160)  153600      block5d_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5d_project_bn (BatchNormal (None, 32, 32, 160)  640         block5d_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block5d_drop (FixedDropout)     (None, 32, 32, 160)  0           block5d_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5d_add (Add)               (None, 32, 32, 160)  0           block5d_drop[0][0]               \n",
            "                                                                 block5c_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5e_expand_conv (Conv2D)    (None, 32, 32, 960)  153600      block5d_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5e_expand_bn (BatchNormali (None, 32, 32, 960)  3840        block5e_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5e_expand_activation (Acti (None, 32, 32, 960)  0           block5e_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5e_dwconv (DepthwiseConv2D (None, 32, 32, 960)  24000       block5e_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block5e_bn (BatchNormalization) (None, 32, 32, 960)  3840        block5e_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block5e_activation (Activation) (None, 32, 32, 960)  0           block5e_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block5e_se_squeeze (GlobalAvera (None, 960)          0           block5e_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5e_se_reshape (Reshape)    (None, 1, 1, 960)    0           block5e_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5e_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block5e_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5e_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block5e_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5e_se_excite (Multiply)    (None, 32, 32, 960)  0           block5e_activation[0][0]         \n",
            "                                                                 block5e_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5e_project_conv (Conv2D)   (None, 32, 32, 160)  153600      block5e_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5e_project_bn (BatchNormal (None, 32, 32, 160)  640         block5e_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block5e_drop (FixedDropout)     (None, 32, 32, 160)  0           block5e_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5e_add (Add)               (None, 32, 32, 160)  0           block5e_drop[0][0]               \n",
            "                                                                 block5d_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5f_expand_conv (Conv2D)    (None, 32, 32, 960)  153600      block5e_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5f_expand_bn (BatchNormali (None, 32, 32, 960)  3840        block5f_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5f_expand_activation (Acti (None, 32, 32, 960)  0           block5f_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5f_dwconv (DepthwiseConv2D (None, 32, 32, 960)  24000       block5f_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block5f_bn (BatchNormalization) (None, 32, 32, 960)  3840        block5f_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block5f_activation (Activation) (None, 32, 32, 960)  0           block5f_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block5f_se_squeeze (GlobalAvera (None, 960)          0           block5f_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5f_se_reshape (Reshape)    (None, 1, 1, 960)    0           block5f_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5f_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block5f_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5f_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block5f_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5f_se_excite (Multiply)    (None, 32, 32, 960)  0           block5f_activation[0][0]         \n",
            "                                                                 block5f_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5f_project_conv (Conv2D)   (None, 32, 32, 160)  153600      block5f_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5f_project_bn (BatchNormal (None, 32, 32, 160)  640         block5f_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block5f_drop (FixedDropout)     (None, 32, 32, 160)  0           block5f_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5f_add (Add)               (None, 32, 32, 160)  0           block5f_drop[0][0]               \n",
            "                                                                 block5e_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block6a_expand_conv (Conv2D)    (None, 32, 32, 960)  153600      block5f_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block6a_expand_bn (BatchNormali (None, 32, 32, 960)  3840        block6a_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6a_expand_activation (Acti (None, 32, 32, 960)  0           block6a_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)         (None, 32, 32, 960)  0           block6a_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 16, 16, 960)  0           leaky_re_lu[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 16, 16, 960)  0           max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv_middle (Conv2D)            (None, 16, 16, 256)  2212096     dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)       (None, 16, 16, 256)  0           conv_middle[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 16, 16, 256)  1024        leaky_re_lu_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 16, 16, 256)  590080      batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)       (None, 16, 16, 256)  0           conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 16, 16, 256)  1024        leaky_re_lu_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 16, 16, 256)  590080      batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 16, 16, 256)  1024        conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 16, 16, 256)  1024        conv_middle[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 16, 16, 256)  0           batch_normalization_3[0][0]      \n",
            "                                                                 batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)       (None, 16, 16, 256)  0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 16, 16, 256)  1024        leaky_re_lu_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 16, 16, 256)  590080      batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)       (None, 16, 16, 256)  0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 256)  1024        leaky_re_lu_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 16, 16, 256)  590080      batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 256)  1024        conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 256)  1024        add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 16, 16, 256)  0           batch_normalization_7[0][0]      \n",
            "                                                                 batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)       (None, 16, 16, 256)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose (Conv2DTranspo (None, 32, 32, 128)  295040      leaky_re_lu_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 32, 32, 1088) 0           conv2d_transpose[0][0]           \n",
            "                                                                 leaky_re_lu[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTrans (None, 64, 64, 64)   553024      leaky_re_lu[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 32, 32, 1088) 0           concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 64, 64, 400)  0           conv2d_transpose_1[0][0]         \n",
            "                                                                 block4a_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_3 (Conv2DTrans (None, 128, 128, 32) 96800       block4a_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 128)  1253504     dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 64, 64, 400)  0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 128, 128, 224 0           conv2d_transpose_3[0][0]         \n",
            "                                                                 block3a_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_6 (Conv2DTrans (None, 256, 256, 16) 27664       block3a_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)       (None, 32, 32, 128)  0           conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 64, 64, 64)   230464      dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 128, 128, 224 0           concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 256, 256, 160 0           conv2d_transpose_6[0][0]         \n",
            "                                                                 block2a_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 32, 32, 128)  512         leaky_re_lu_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_11 (LeakyReLU)      (None, 64, 64, 64)   0           conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 128, 128, 32) 64544       dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 256, 256, 160 0           concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 128)  147584      batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 64, 64, 64)   256         leaky_re_lu_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_21 (LeakyReLU)      (None, 128, 128, 32) 0           conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 256, 256, 16) 23056       dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)       (None, 32, 32, 128)  0           conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 64, 64, 64)   36928       batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 128, 128, 32) 128         leaky_re_lu_21[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_36 (LeakyReLU)      (None, 256, 256, 16) 0           conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 32, 32, 128)  512         leaky_re_lu_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_12 (LeakyReLU)      (None, 64, 64, 64)   0           conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 128, 128, 32) 9248        batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 256, 256, 16) 64          leaky_re_lu_36[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 128)  147584      batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 64, 64, 64)   256         leaky_re_lu_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_22 (LeakyReLU)      (None, 128, 128, 32) 0           conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 256, 256, 16) 2320        batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 32, 32, 128)  512         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 32, 32, 128)  512         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 64, 64, 64)   36928       batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 128, 128, 32) 128         leaky_re_lu_22[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_37 (LeakyReLU)      (None, 256, 256, 16) 0           conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 32, 32, 128)  0           batch_normalization_11[0][0]     \n",
            "                                                                 batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 64, 64, 64)   256         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 64, 64, 64)   256         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 128, 128, 32) 9248        batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 256, 256, 16) 64          leaky_re_lu_37[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)       (None, 32, 32, 128)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 64, 64, 64)   0           batch_normalization_19[0][0]     \n",
            "                                                                 batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 128, 128, 32) 128         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 128, 128, 32) 128         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 256, 256, 16) 2320        batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 32, 32, 128)  512         leaky_re_lu_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_13 (LeakyReLU)      (None, 64, 64, 64)   0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 128, 128, 32) 0           batch_normalization_35[0][0]     \n",
            "                                                                 batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 256, 256, 16) 64          conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 256, 256, 16) 64          conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 128)  147584      batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 64, 64, 64)   256         leaky_re_lu_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_23 (LeakyReLU)      (None, 128, 128, 32) 0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 256, 256, 16) 0           batch_normalization_59[0][0]     \n",
            "                                                                 batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_9 (LeakyReLU)       (None, 32, 32, 128)  0           conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 64, 64, 64)   36928       batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 128, 128, 32) 128         leaky_re_lu_23[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_38 (LeakyReLU)      (None, 256, 256, 16) 0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 32, 32, 128)  512         leaky_re_lu_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_14 (LeakyReLU)      (None, 64, 64, 64)   0           conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 128, 128, 32) 9248        batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 256, 256, 16) 64          leaky_re_lu_38[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 32, 32, 128)  147584      batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 64, 64, 64)   256         leaky_re_lu_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_24 (LeakyReLU)      (None, 128, 128, 32) 0           conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 256, 256, 16) 2320        batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 32, 32, 128)  512         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 32, 32, 128)  512         add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 64, 64, 64)   36928       batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 128, 128, 32) 128         leaky_re_lu_24[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_39 (LeakyReLU)      (None, 256, 256, 16) 0           conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 32, 32, 128)  0           batch_normalization_15[0][0]     \n",
            "                                                                 batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 64, 64, 64)   256         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 64, 64, 64)   256         add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 128, 128, 32) 9248        batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 256, 256, 16) 64          leaky_re_lu_39[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_10 (LeakyReLU)      (None, 32, 32, 128)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 64, 64, 64)   0           batch_normalization_23[0][0]     \n",
            "                                                                 batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 128, 128, 32) 128         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 128, 128, 32) 128         add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 256, 256, 16) 2320        batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTrans (None, 64, 64, 64)   73792       leaky_re_lu_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_15 (LeakyReLU)      (None, 64, 64, 64)   0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 128, 128, 32) 0           batch_normalization_39[0][0]     \n",
            "                                                                 batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 256, 256, 16) 64          conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 256, 256, 16) 64          add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 64, 64, 464)  0           conv2d_transpose_2[0][0]         \n",
            "                                                                 leaky_re_lu_15[0][0]             \n",
            "                                                                 block4a_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_4 (Conv2DTrans (None, 128, 128, 32) 18464       leaky_re_lu_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_25 (LeakyReLU)      (None, 128, 128, 32) 0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 256, 256, 16) 0           batch_normalization_63[0][0]     \n",
            "                                                                 batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 64, 64, 464)  0           concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 128, 128, 256 0           conv2d_transpose_4[0][0]         \n",
            "                                                                 leaky_re_lu_25[0][0]             \n",
            "                                                                 block3a_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_7 (Conv2DTrans (None, 256, 256, 16) 4624        leaky_re_lu_25[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_40 (LeakyReLU)      (None, 256, 256, 16) 0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 64, 64, 64)   267328      dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 128, 128, 256 0           concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 256, 256, 176 0           conv2d_transpose_7[0][0]         \n",
            "                                                                 leaky_re_lu_40[0][0]             \n",
            "                                                                 block2a_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_16 (LeakyReLU)      (None, 64, 64, 64)   0           conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 128, 128, 32) 73760       dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 256, 256, 176 0           concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 64, 64, 64)   256         leaky_re_lu_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_26 (LeakyReLU)      (None, 128, 128, 32) 0           conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 256, 256, 16) 25360       dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 64, 64, 64)   36928       batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 128, 128, 32) 128         leaky_re_lu_26[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_41 (LeakyReLU)      (None, 256, 256, 16) 0           conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_17 (LeakyReLU)      (None, 64, 64, 64)   0           conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 128, 128, 32) 9248        batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 256, 256, 16) 64          leaky_re_lu_41[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 64, 64, 64)   256         leaky_re_lu_17[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_27 (LeakyReLU)      (None, 128, 128, 32) 0           conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 256, 256, 16) 2320        batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 64, 64, 64)   36928       batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 128, 128, 32) 128         leaky_re_lu_27[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_42 (LeakyReLU)      (None, 256, 256, 16) 0           conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 64, 64, 64)   256         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 64, 64, 64)   256         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 128, 128, 32) 9248        batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 256, 256, 16) 64          leaky_re_lu_42[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 64, 64, 64)   0           batch_normalization_27[0][0]     \n",
            "                                                                 batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 128, 128, 32) 128         conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 128, 128, 32) 128         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 256, 256, 16) 2320        batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_18 (LeakyReLU)      (None, 64, 64, 64)   0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 128, 128, 32) 0           batch_normalization_43[0][0]     \n",
            "                                                                 batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 256, 256, 16) 64          conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 256, 256, 16) 64          conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 64, 64, 64)   256         leaky_re_lu_18[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_28 (LeakyReLU)      (None, 128, 128, 32) 0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 256, 256, 16) 0           batch_normalization_67[0][0]     \n",
            "                                                                 batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 64, 64, 64)   36928       batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 128, 128, 32) 128         leaky_re_lu_28[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_43 (LeakyReLU)      (None, 256, 256, 16) 0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_19 (LeakyReLU)      (None, 64, 64, 64)   0           conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 128, 128, 32) 9248        batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 256, 256, 16) 64          leaky_re_lu_43[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 64, 64, 64)   256         leaky_re_lu_19[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_29 (LeakyReLU)      (None, 128, 128, 32) 0           conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 256, 256, 16) 2320        batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 64, 64, 64)   36928       batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 128, 128, 32) 128         leaky_re_lu_29[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_44 (LeakyReLU)      (None, 256, 256, 16) 0           conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 64, 64, 64)   256         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 64, 64, 64)   256         add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 128, 128, 32) 9248        batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 256, 256, 16) 64          leaky_re_lu_44[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 64, 64, 64)   0           batch_normalization_31[0][0]     \n",
            "                                                                 batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 128, 128, 32) 128         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 128, 128, 32) 128         add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 256, 256, 16) 2320        batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_20 (LeakyReLU)      (None, 64, 64, 64)   0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 128, 128, 32) 0           batch_normalization_47[0][0]     \n",
            "                                                                 batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 256, 256, 16) 64          conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 256, 256, 16) 64          add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_5 (Conv2DTrans (None, 128, 128, 32) 18464       leaky_re_lu_20[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_30 (LeakyReLU)      (None, 128, 128, 32) 0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 256, 256, 16) 0           batch_normalization_71[0][0]     \n",
            "                                                                 batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 128, 128, 288 0           conv2d_transpose_5[0][0]         \n",
            "                                                                 leaky_re_lu_30[0][0]             \n",
            "                                                                 leaky_re_lu_25[0][0]             \n",
            "                                                                 block3a_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_8 (Conv2DTrans (None, 256, 256, 16) 4624        leaky_re_lu_30[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_45 (LeakyReLU)      (None, 256, 256, 16) 0           add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 128, 128, 288 0           concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 256, 256, 192 0           conv2d_transpose_8[0][0]         \n",
            "                                                                 leaky_re_lu_45[0][0]             \n",
            "                                                                 leaky_re_lu_40[0][0]             \n",
            "                                                                 block2a_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 128, 128, 32) 82976       dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 256, 256, 192 0           concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_31 (LeakyReLU)      (None, 128, 128, 32) 0           conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 256, 256, 16) 27664       dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 128, 128, 32) 128         leaky_re_lu_31[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_46 (LeakyReLU)      (None, 256, 256, 16) 0           conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 128, 128, 32) 9248        batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 256, 256, 16) 64          leaky_re_lu_46[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_32 (LeakyReLU)      (None, 128, 128, 32) 0           conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 256, 256, 16) 2320        batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 128, 128, 32) 128         leaky_re_lu_32[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_47 (LeakyReLU)      (None, 256, 256, 16) 0           conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 128, 128, 32) 9248        batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 256, 256, 16) 64          leaky_re_lu_47[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 128, 128, 32) 128         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 128, 128, 32) 128         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 256, 256, 16) 2320        batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 128, 128, 32) 0           batch_normalization_51[0][0]     \n",
            "                                                                 batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 256, 256, 16) 64          conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 256, 256, 16) 64          conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_33 (LeakyReLU)      (None, 128, 128, 32) 0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 256, 256, 16) 0           batch_normalization_75[0][0]     \n",
            "                                                                 batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 128, 128, 32) 128         leaky_re_lu_33[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_48 (LeakyReLU)      (None, 256, 256, 16) 0           add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 128, 128, 32) 9248        batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 256, 256, 16) 64          leaky_re_lu_48[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_34 (LeakyReLU)      (None, 128, 128, 32) 0           conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 256, 256, 16) 2320        batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 128, 128, 32) 128         leaky_re_lu_34[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_49 (LeakyReLU)      (None, 256, 256, 16) 0           conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 128, 128, 32) 9248        batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 256, 256, 16) 64          leaky_re_lu_49[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 128, 128, 32) 128         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 128, 128, 32) 128         add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 256, 256, 16) 2320        batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 128, 128, 32) 0           batch_normalization_55[0][0]     \n",
            "                                                                 batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 256, 256, 16) 64          conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 256, 256, 16) 64          add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_35 (LeakyReLU)      (None, 128, 128, 32) 0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, 256, 256, 16) 0           batch_normalization_79[0][0]     \n",
            "                                                                 batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_9 (Conv2DTrans (None, 256, 256, 16) 4624        leaky_re_lu_35[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_50 (LeakyReLU)      (None, 256, 256, 16) 0           add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 256, 256, 208 0           conv2d_transpose_9[0][0]         \n",
            "                                                                 leaky_re_lu_50[0][0]             \n",
            "                                                                 leaky_re_lu_45[0][0]             \n",
            "                                                                 leaky_re_lu_40[0][0]             \n",
            "                                                                 block2a_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 256, 256, 208 0           concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 256, 256, 16) 29968       dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_51 (LeakyReLU)      (None, 256, 256, 16) 0           conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 256, 256, 16) 64          leaky_re_lu_51[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 256, 256, 16) 2320        batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_52 (LeakyReLU)      (None, 256, 256, 16) 0           conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 256, 256, 16) 64          leaky_re_lu_52[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 256, 256, 16) 2320        batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 256, 256, 16) 64          conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 256, 256, 16) 64          conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, 256, 256, 16) 0           batch_normalization_83[0][0]     \n",
            "                                                                 batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_53 (LeakyReLU)      (None, 256, 256, 16) 0           add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 256, 256, 16) 64          leaky_re_lu_53[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 256, 256, 16) 2320        batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_54 (LeakyReLU)      (None, 256, 256, 16) 0           conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 256, 256, 16) 64          leaky_re_lu_54[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 256, 256, 16) 2320        batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 256, 256, 16) 64          conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 256, 256, 16) 64          add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "add_21 (Add)                    (None, 256, 256, 16) 0           batch_normalization_87[0][0]     \n",
            "                                                                 batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_55 (LeakyReLU)      (None, 256, 256, 16) 0           add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_10 (Conv2DTran (None, 512, 512, 16) 2320        leaky_re_lu_55[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 512, 512, 16) 0           conv2d_transpose_10[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 512, 512, 8)  1160        dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_56 (LeakyReLU)      (None, 512, 512, 8)  0           conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 512, 512, 8)  32          leaky_re_lu_56[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 512, 512, 8)  584         batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_57 (LeakyReLU)      (None, 512, 512, 8)  0           conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 512, 512, 8)  32          leaky_re_lu_57[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 512, 512, 8)  584         batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 512, 512, 8)  32          conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 512, 512, 8)  32          conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_22 (Add)                    (None, 512, 512, 8)  0           batch_normalization_91[0][0]     \n",
            "                                                                 batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_58 (LeakyReLU)      (None, 512, 512, 8)  0           add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 512, 512, 8)  32          leaky_re_lu_58[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 512, 512, 8)  584         batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_59 (LeakyReLU)      (None, 512, 512, 8)  0           conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, 512, 512, 8)  32          leaky_re_lu_59[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 512, 512, 8)  584         batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_95 (BatchNo (None, 512, 512, 8)  32          conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 512, 512, 8)  32          add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "add_23 (Add)                    (None, 512, 512, 8)  0           batch_normalization_95[0][0]     \n",
            "                                                                 batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_60 (LeakyReLU)      (None, 512, 512, 8)  0           add_23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 512, 512, 8)  0           leaky_re_lu_60[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 512, 512, 1)  9           dropout_12[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 12,651,681\n",
            "Trainable params: 12,590,225\n",
            "Non-trainable params: 61,456\n",
            "__________________________________________________________________________________________________\n",
            "WARNING:tensorflow:From <ipython-input-9-49d7613e5953>:416: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Found 307 images belonging to 1 classes.\n",
            "Found 307 images belonging to 1 classes.\n",
            "Epoch 1/250\n",
            " 1/61 [..............................] - ETA: 0s - loss: 0.4102 - binary_crossentropy: 1.1086 - dice_coef: 0.4051 - jacard_coef: 0.2540 - binary_accuracy: 0.3994WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
            "Instructions for updating:\n",
            "use `tf.profiler.experimental.stop` instead.\n",
            " 2/61 [..............................] - ETA: 1:11 - loss: 0.4069 - binary_crossentropy: 1.0947 - dice_coef: 0.4075 - jacard_coef: 0.2559 - binary_accuracy: 0.4028WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.7317s vs `on_train_batch_end` time: 1.6797s). Check your callbacks.\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.2042 - binary_crossentropy: 0.4296 - dice_coef: 0.6564 - jacard_coef: 0.4979 - binary_accuracy: 0.8689Found 39 images belonging to 1 classes.\n",
            "Found 39 images belonging to 1 classes.\n",
            "\n",
            "Epoch 00001: val_dice_coef improved from -inf to 0.67796, saving model to net_lung_seg.hdf5\n",
            "62/61 [==============================] - 62s 997ms/step - loss: 0.2042 - binary_crossentropy: 0.4296 - dice_coef: 0.6564 - jacard_coef: 0.4979 - binary_accuracy: 0.8689 - val_loss: 1.3369 - val_binary_crossentropy: 11.9354 - val_dice_coef: 0.6780 - val_jacard_coef: 0.5142 - val_binary_accuracy: 0.8671\n",
            "Epoch 2/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.1232 - binary_crossentropy: 0.1929 - dice_coef: 0.7928 - jacard_coef: 0.6579 - binary_accuracy: 0.9827\n",
            "Epoch 00002: val_dice_coef improved from 0.67796 to 0.75140, saving model to net_lung_seg.hdf5\n",
            "62/61 [==============================] - 55s 884ms/step - loss: 0.1232 - binary_crossentropy: 0.1929 - dice_coef: 0.7928 - jacard_coef: 0.6579 - binary_accuracy: 0.9827 - val_loss: 0.3121 - val_binary_crossentropy: 1.9563 - val_dice_coef: 0.7514 - val_jacard_coef: 0.6027 - val_binary_accuracy: 0.8958\n",
            "Epoch 3/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.1061 - binary_crossentropy: 0.1490 - dice_coef: 0.8331 - jacard_coef: 0.7150 - binary_accuracy: 0.9849\n",
            "Epoch 00003: val_dice_coef improved from 0.75140 to 0.83029, saving model to net_lung_seg.hdf5\n",
            "62/61 [==============================] - 55s 885ms/step - loss: 0.1061 - binary_crossentropy: 0.1490 - dice_coef: 0.8331 - jacard_coef: 0.7150 - binary_accuracy: 0.9849 - val_loss: 0.1428 - val_binary_crossentropy: 0.5150 - val_dice_coef: 0.8303 - val_jacard_coef: 0.7105 - val_binary_accuracy: 0.9491\n",
            "Epoch 4/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0985 - binary_crossentropy: 0.1334 - dice_coef: 0.8549 - jacard_coef: 0.7482 - binary_accuracy: 0.9813\n",
            "Epoch 00004: val_dice_coef did not improve from 0.83029\n",
            "62/61 [==============================] - 53s 856ms/step - loss: 0.0985 - binary_crossentropy: 0.1334 - dice_coef: 0.8549 - jacard_coef: 0.7482 - binary_accuracy: 0.9813 - val_loss: 0.3083 - val_binary_crossentropy: 1.9719 - val_dice_coef: 0.7679 - val_jacard_coef: 0.6243 - val_binary_accuracy: 0.8699\n",
            "Epoch 5/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0866 - binary_crossentropy: 0.1044 - dice_coef: 0.8853 - jacard_coef: 0.7950 - binary_accuracy: 0.9858\n",
            "Epoch 00005: val_dice_coef improved from 0.83029 to 0.84791, saving model to net_lung_seg.hdf5\n",
            "62/61 [==============================] - 55s 885ms/step - loss: 0.0866 - binary_crossentropy: 0.1044 - dice_coef: 0.8853 - jacard_coef: 0.7950 - binary_accuracy: 0.9858 - val_loss: 0.1397 - val_binary_crossentropy: 0.5410 - val_dice_coef: 0.8479 - val_jacard_coef: 0.7372 - val_binary_accuracy: 0.9355\n",
            "Epoch 6/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0787 - binary_crossentropy: 0.0826 - dice_coef: 0.9049 - jacard_coef: 0.8269 - binary_accuracy: 0.9877\n",
            "Epoch 00006: val_dice_coef improved from 0.84791 to 0.88239, saving model to net_lung_seg.hdf5\n",
            "62/61 [==============================] - 55s 885ms/step - loss: 0.0787 - binary_crossentropy: 0.0826 - dice_coef: 0.9049 - jacard_coef: 0.8269 - binary_accuracy: 0.9877 - val_loss: 0.1011 - val_binary_crossentropy: 0.2488 - val_dice_coef: 0.8824 - val_jacard_coef: 0.7900 - val_binary_accuracy: 0.9580\n",
            "Epoch 7/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0734 - binary_crossentropy: 0.0717 - dice_coef: 0.9211 - jacard_coef: 0.8540 - binary_accuracy: 0.9881\n",
            "Epoch 00007: val_dice_coef improved from 0.88239 to 0.92474, saving model to net_lung_seg.hdf5\n",
            "62/61 [==============================] - 55s 884ms/step - loss: 0.0734 - binary_crossentropy: 0.0717 - dice_coef: 0.9211 - jacard_coef: 0.8540 - binary_accuracy: 0.9881 - val_loss: 0.0754 - val_binary_crossentropy: 0.1077 - val_dice_coef: 0.9247 - val_jacard_coef: 0.8604 - val_binary_accuracy: 0.9792\n",
            "Epoch 8/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0704 - binary_crossentropy: 0.0664 - dice_coef: 0.9309 - jacard_coef: 0.8711 - binary_accuracy: 0.9878\n",
            "Epoch 00008: val_dice_coef improved from 0.92474 to 0.93264, saving model to net_lung_seg.hdf5\n",
            "62/61 [==============================] - 55s 883ms/step - loss: 0.0704 - binary_crossentropy: 0.0664 - dice_coef: 0.9309 - jacard_coef: 0.8711 - binary_accuracy: 0.9878 - val_loss: 0.0759 - val_binary_crossentropy: 0.1328 - val_dice_coef: 0.9326 - val_jacard_coef: 0.8742 - val_binary_accuracy: 0.9773\n",
            "Epoch 9/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0677 - binary_crossentropy: 0.0618 - dice_coef: 0.9392 - jacard_coef: 0.8857 - binary_accuracy: 0.9881\n",
            "Epoch 00009: val_dice_coef did not improve from 0.93264\n",
            "62/61 [==============================] - 53s 852ms/step - loss: 0.0677 - binary_crossentropy: 0.0618 - dice_coef: 0.9392 - jacard_coef: 0.8857 - binary_accuracy: 0.9881 - val_loss: 0.0863 - val_binary_crossentropy: 0.1896 - val_dice_coef: 0.9142 - val_jacard_coef: 0.8427 - val_binary_accuracy: 0.9615\n",
            "Epoch 10/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0650 - binary_crossentropy: 0.0543 - dice_coef: 0.9469 - jacard_coef: 0.8992 - binary_accuracy: 0.9887\n",
            "Epoch 00010: val_dice_coef improved from 0.93264 to 0.95150, saving model to net_lung_seg.hdf5\n",
            "62/61 [==============================] - 55s 881ms/step - loss: 0.0650 - binary_crossentropy: 0.0543 - dice_coef: 0.9469 - jacard_coef: 0.8992 - binary_accuracy: 0.9887 - val_loss: 0.0674 - val_binary_crossentropy: 0.0963 - val_dice_coef: 0.9515 - val_jacard_coef: 0.9077 - val_binary_accuracy: 0.9822\n",
            "Epoch 11/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0635 - binary_crossentropy: 0.0508 - dice_coef: 0.9517 - jacard_coef: 0.9080 - binary_accuracy: 0.9888\n",
            "Epoch 00011: val_dice_coef improved from 0.95150 to 0.95818, saving model to net_lung_seg.hdf5\n",
            "62/61 [==============================] - 55s 881ms/step - loss: 0.0635 - binary_crossentropy: 0.0508 - dice_coef: 0.9517 - jacard_coef: 0.9080 - binary_accuracy: 0.9888 - val_loss: 0.0631 - val_binary_crossentropy: 0.0712 - val_dice_coef: 0.9582 - val_jacard_coef: 0.9199 - val_binary_accuracy: 0.9845\n",
            "Epoch 12/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0634 - binary_crossentropy: 0.0544 - dice_coef: 0.9541 - jacard_coef: 0.9125 - binary_accuracy: 0.9884\n",
            "Epoch 00012: val_dice_coef did not improve from 0.95818\n",
            "62/61 [==============================] - 53s 853ms/step - loss: 0.0634 - binary_crossentropy: 0.0544 - dice_coef: 0.9541 - jacard_coef: 0.9125 - binary_accuracy: 0.9884 - val_loss: 0.0655 - val_binary_crossentropy: 0.0948 - val_dice_coef: 0.9574 - val_jacard_coef: 0.9184 - val_binary_accuracy: 0.9822\n",
            "Epoch 13/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0635 - binary_crossentropy: 0.0584 - dice_coef: 0.9554 - jacard_coef: 0.9153 - binary_accuracy: 0.9879\n",
            "Epoch 00013: val_dice_coef improved from 0.95818 to 0.96861, saving model to net_lung_seg.hdf5\n",
            "62/61 [==============================] - 55s 880ms/step - loss: 0.0635 - binary_crossentropy: 0.0584 - dice_coef: 0.9554 - jacard_coef: 0.9153 - binary_accuracy: 0.9879 - val_loss: 0.0586 - val_binary_crossentropy: 0.0469 - val_dice_coef: 0.9686 - val_jacard_coef: 0.9392 - val_binary_accuracy: 0.9880\n",
            "Epoch 14/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0621 - binary_crossentropy: 0.0527 - dice_coef: 0.9588 - jacard_coef: 0.9213 - binary_accuracy: 0.9885\n",
            "Epoch 00014: val_dice_coef improved from 0.96861 to 0.97218, saving model to net_lung_seg.hdf5\n",
            "62/61 [==============================] - 55s 882ms/step - loss: 0.0621 - binary_crossentropy: 0.0527 - dice_coef: 0.9588 - jacard_coef: 0.9213 - binary_accuracy: 0.9885 - val_loss: 0.0569 - val_binary_crossentropy: 0.0403 - val_dice_coef: 0.9722 - val_jacard_coef: 0.9460 - val_binary_accuracy: 0.9892\n",
            "Epoch 15/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0603 - binary_crossentropy: 0.0452 - dice_coef: 0.9625 - jacard_coef: 0.9279 - binary_accuracy: 0.9896\n",
            "Epoch 00015: val_dice_coef improved from 0.97218 to 0.97256, saving model to net_lung_seg.hdf5\n",
            "62/61 [==============================] - 55s 885ms/step - loss: 0.0603 - binary_crossentropy: 0.0452 - dice_coef: 0.9625 - jacard_coef: 0.9279 - binary_accuracy: 0.9896 - val_loss: 0.0570 - val_binary_crossentropy: 0.0391 - val_dice_coef: 0.9726 - val_jacard_coef: 0.9466 - val_binary_accuracy: 0.9888\n",
            "Epoch 16/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0601 - binary_crossentropy: 0.0453 - dice_coef: 0.9633 - jacard_coef: 0.9295 - binary_accuracy: 0.9895\n",
            "Epoch 00016: val_dice_coef did not improve from 0.97256\n",
            "62/61 [==============================] - 53s 853ms/step - loss: 0.0601 - binary_crossentropy: 0.0453 - dice_coef: 0.9633 - jacard_coef: 0.9295 - binary_accuracy: 0.9895 - val_loss: 0.0611 - val_binary_crossentropy: 0.0707 - val_dice_coef: 0.9677 - val_jacard_coef: 0.9375 - val_binary_accuracy: 0.9852\n",
            "Epoch 17/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0585 - binary_crossentropy: 0.0383 - dice_coef: 0.9663 - jacard_coef: 0.9350 - binary_accuracy: 0.9906\n",
            "Epoch 00017: val_dice_coef did not improve from 0.97256\n",
            "62/61 [==============================] - 53s 851ms/step - loss: 0.0585 - binary_crossentropy: 0.0383 - dice_coef: 0.9663 - jacard_coef: 0.9350 - binary_accuracy: 0.9906 - val_loss: 0.0585 - val_binary_crossentropy: 0.0539 - val_dice_coef: 0.9712 - val_jacard_coef: 0.9441 - val_binary_accuracy: 0.9869\n",
            "Epoch 18/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0580 - binary_crossentropy: 0.0370 - dice_coef: 0.9675 - jacard_coef: 0.9370 - binary_accuracy: 0.9908\n",
            "Epoch 00018: val_dice_coef improved from 0.97256 to 0.97477, saving model to net_lung_seg.hdf5\n",
            "62/61 [==============================] - 55s 879ms/step - loss: 0.0580 - binary_crossentropy: 0.0370 - dice_coef: 0.9675 - jacard_coef: 0.9370 - binary_accuracy: 0.9908 - val_loss: 0.0567 - val_binary_crossentropy: 0.0408 - val_dice_coef: 0.9748 - val_jacard_coef: 0.9509 - val_binary_accuracy: 0.9887\n",
            "Epoch 19/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0591 - binary_crossentropy: 0.0447 - dice_coef: 0.9673 - jacard_coef: 0.9370 - binary_accuracy: 0.9898\n",
            "Epoch 00019: val_dice_coef improved from 0.97477 to 0.97575, saving model to net_lung_seg.hdf5\n",
            "62/61 [==============================] - 55s 880ms/step - loss: 0.0591 - binary_crossentropy: 0.0447 - dice_coef: 0.9673 - jacard_coef: 0.9370 - binary_accuracy: 0.9898 - val_loss: 0.0558 - val_binary_crossentropy: 0.0380 - val_dice_coef: 0.9758 - val_jacard_coef: 0.9527 - val_binary_accuracy: 0.9891\n",
            "Epoch 20/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0572 - binary_crossentropy: 0.0347 - dice_coef: 0.9700 - jacard_coef: 0.9418 - binary_accuracy: 0.9912\n",
            "Epoch 00020: val_dice_coef improved from 0.97575 to 0.97676, saving model to net_lung_seg.hdf5\n",
            "62/61 [==============================] - 55s 881ms/step - loss: 0.0572 - binary_crossentropy: 0.0347 - dice_coef: 0.9700 - jacard_coef: 0.9418 - binary_accuracy: 0.9912 - val_loss: 0.0555 - val_binary_crossentropy: 0.0377 - val_dice_coef: 0.9768 - val_jacard_coef: 0.9546 - val_binary_accuracy: 0.9895\n",
            "Epoch 21/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0581 - binary_crossentropy: 0.0422 - dice_coef: 0.9697 - jacard_coef: 0.9415 - binary_accuracy: 0.9905\n",
            "Epoch 00021: val_dice_coef did not improve from 0.97676\n",
            "62/61 [==============================] - 53s 852ms/step - loss: 0.0581 - binary_crossentropy: 0.0422 - dice_coef: 0.9697 - jacard_coef: 0.9415 - binary_accuracy: 0.9905 - val_loss: 0.0560 - val_binary_crossentropy: 0.0406 - val_dice_coef: 0.9760 - val_jacard_coef: 0.9532 - val_binary_accuracy: 0.9889\n",
            "Epoch 22/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0576 - binary_crossentropy: 0.0400 - dice_coef: 0.9705 - jacard_coef: 0.9429 - binary_accuracy: 0.9909\n",
            "Epoch 00022: val_dice_coef did not improve from 0.97676\n",
            "62/61 [==============================] - 53s 851ms/step - loss: 0.0576 - binary_crossentropy: 0.0400 - dice_coef: 0.9705 - jacard_coef: 0.9429 - binary_accuracy: 0.9909 - val_loss: 0.0559 - val_binary_crossentropy: 0.0420 - val_dice_coef: 0.9760 - val_jacard_coef: 0.9533 - val_binary_accuracy: 0.9887\n",
            "Epoch 23/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0569 - binary_crossentropy: 0.0360 - dice_coef: 0.9719 - jacard_coef: 0.9454 - binary_accuracy: 0.9911\n",
            "Epoch 00023: val_dice_coef improved from 0.97676 to 0.97776, saving model to net_lung_seg.hdf5\n",
            "62/61 [==============================] - 55s 888ms/step - loss: 0.0569 - binary_crossentropy: 0.0360 - dice_coef: 0.9719 - jacard_coef: 0.9454 - binary_accuracy: 0.9911 - val_loss: 0.0551 - val_binary_crossentropy: 0.0382 - val_dice_coef: 0.9778 - val_jacard_coef: 0.9565 - val_binary_accuracy: 0.9896\n",
            "Epoch 24/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0565 - binary_crossentropy: 0.0343 - dice_coef: 0.9728 - jacard_coef: 0.9471 - binary_accuracy: 0.9914\n",
            "Epoch 00024: val_dice_coef did not improve from 0.97776\n",
            "62/61 [==============================] - 53s 851ms/step - loss: 0.0565 - binary_crossentropy: 0.0343 - dice_coef: 0.9728 - jacard_coef: 0.9471 - binary_accuracy: 0.9914 - val_loss: 0.0568 - val_binary_crossentropy: 0.0477 - val_dice_coef: 0.9757 - val_jacard_coef: 0.9527 - val_binary_accuracy: 0.9882\n",
            "Epoch 25/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0562 - binary_crossentropy: 0.0329 - dice_coef: 0.9734 - jacard_coef: 0.9482 - binary_accuracy: 0.9914\n",
            "Epoch 00025: val_dice_coef did not improve from 0.97776\n",
            "62/61 [==============================] - 53s 854ms/step - loss: 0.0562 - binary_crossentropy: 0.0329 - dice_coef: 0.9734 - jacard_coef: 0.9482 - binary_accuracy: 0.9914 - val_loss: 0.0572 - val_binary_crossentropy: 0.0522 - val_dice_coef: 0.9748 - val_jacard_coef: 0.9510 - val_binary_accuracy: 0.9875\n",
            "Epoch 26/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0559 - binary_crossentropy: 0.0326 - dice_coef: 0.9745 - jacard_coef: 0.9503 - binary_accuracy: 0.9916\n",
            "Epoch 00026: val_dice_coef improved from 0.97776 to 0.97832, saving model to net_lung_seg.hdf5\n",
            "62/61 [==============================] - 55s 881ms/step - loss: 0.0559 - binary_crossentropy: 0.0326 - dice_coef: 0.9745 - jacard_coef: 0.9503 - binary_accuracy: 0.9916 - val_loss: 0.0555 - val_binary_crossentropy: 0.0423 - val_dice_coef: 0.9783 - val_jacard_coef: 0.9576 - val_binary_accuracy: 0.9892\n",
            "Epoch 27/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0555 - binary_crossentropy: 0.0306 - dice_coef: 0.9750 - jacard_coef: 0.9512 - binary_accuracy: 0.9917\n",
            "Epoch 00027: val_dice_coef did not improve from 0.97832\n",
            "62/61 [==============================] - 53s 853ms/step - loss: 0.0555 - binary_crossentropy: 0.0306 - dice_coef: 0.9750 - jacard_coef: 0.9512 - binary_accuracy: 0.9917 - val_loss: 0.0559 - val_binary_crossentropy: 0.0443 - val_dice_coef: 0.9774 - val_jacard_coef: 0.9559 - val_binary_accuracy: 0.9887\n",
            "Epoch 28/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0567 - binary_crossentropy: 0.0385 - dice_coef: 0.9737 - jacard_coef: 0.9491 - binary_accuracy: 0.9909\n",
            "Epoch 00028: val_dice_coef did not improve from 0.97832\n",
            "62/61 [==============================] - 53s 853ms/step - loss: 0.0567 - binary_crossentropy: 0.0385 - dice_coef: 0.9737 - jacard_coef: 0.9491 - binary_accuracy: 0.9909 - val_loss: 0.0566 - val_binary_crossentropy: 0.0473 - val_dice_coef: 0.9768 - val_jacard_coef: 0.9548 - val_binary_accuracy: 0.9883\n",
            "Epoch 29/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0561 - binary_crossentropy: 0.0358 - dice_coef: 0.9748 - jacard_coef: 0.9510 - binary_accuracy: 0.9910\n",
            "Epoch 00029: val_dice_coef did not improve from 0.97832\n",
            "62/61 [==============================] - 53s 850ms/step - loss: 0.0561 - binary_crossentropy: 0.0358 - dice_coef: 0.9748 - jacard_coef: 0.9510 - binary_accuracy: 0.9910 - val_loss: 0.0571 - val_binary_crossentropy: 0.0498 - val_dice_coef: 0.9759 - val_jacard_coef: 0.9531 - val_binary_accuracy: 0.9878\n",
            "Epoch 30/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0553 - binary_crossentropy: 0.0302 - dice_coef: 0.9756 - jacard_coef: 0.9525 - binary_accuracy: 0.9914\n",
            "Epoch 00030: val_dice_coef did not improve from 0.97832\n",
            "62/61 [==============================] - 53s 851ms/step - loss: 0.0553 - binary_crossentropy: 0.0302 - dice_coef: 0.9756 - jacard_coef: 0.9525 - binary_accuracy: 0.9914 - val_loss: 0.0591 - val_binary_crossentropy: 0.0650 - val_dice_coef: 0.9735 - val_jacard_coef: 0.9485 - val_binary_accuracy: 0.9864\n",
            "Epoch 31/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0562 - binary_crossentropy: 0.0360 - dice_coef: 0.9751 - jacard_coef: 0.9515 - binary_accuracy: 0.9908\n",
            "Epoch 00031: val_dice_coef did not improve from 0.97832\n",
            "62/61 [==============================] - 53s 853ms/step - loss: 0.0562 - binary_crossentropy: 0.0360 - dice_coef: 0.9751 - jacard_coef: 0.9515 - binary_accuracy: 0.9908 - val_loss: 0.0602 - val_binary_crossentropy: 0.0753 - val_dice_coef: 0.9727 - val_jacard_coef: 0.9470 - val_binary_accuracy: 0.9857\n",
            "Epoch 32/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0556 - binary_crossentropy: 0.0338 - dice_coef: 0.9764 - jacard_coef: 0.9540 - binary_accuracy: 0.9914\n",
            "Epoch 00032: val_dice_coef did not improve from 0.97832\n",
            "62/61 [==============================] - 53s 851ms/step - loss: 0.0556 - binary_crossentropy: 0.0338 - dice_coef: 0.9764 - jacard_coef: 0.9540 - binary_accuracy: 0.9914 - val_loss: 0.0566 - val_binary_crossentropy: 0.0502 - val_dice_coef: 0.9767 - val_jacard_coef: 0.9546 - val_binary_accuracy: 0.9880\n",
            "Epoch 33/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0542 - binary_crossentropy: 0.0265 - dice_coef: 0.9785 - jacard_coef: 0.9579 - binary_accuracy: 0.9923\n",
            "Epoch 00033: val_dice_coef did not improve from 0.97832\n",
            "62/61 [==============================] - 53s 853ms/step - loss: 0.0542 - binary_crossentropy: 0.0265 - dice_coef: 0.9785 - jacard_coef: 0.9579 - binary_accuracy: 0.9923 - val_loss: 0.0564 - val_binary_crossentropy: 0.0492 - val_dice_coef: 0.9775 - val_jacard_coef: 0.9560 - val_binary_accuracy: 0.9884\n",
            "Epoch 34/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0548 - binary_crossentropy: 0.0293 - dice_coef: 0.9780 - jacard_coef: 0.9571 - binary_accuracy: 0.9920\n",
            "Epoch 00034: val_dice_coef did not improve from 0.97832\n",
            "62/61 [==============================] - 53s 853ms/step - loss: 0.0548 - binary_crossentropy: 0.0293 - dice_coef: 0.9780 - jacard_coef: 0.9571 - binary_accuracy: 0.9920 - val_loss: 0.0563 - val_binary_crossentropy: 0.0499 - val_dice_coef: 0.9782 - val_jacard_coef: 0.9574 - val_binary_accuracy: 0.9886\n",
            "Epoch 35/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0543 - binary_crossentropy: 0.0284 - dice_coef: 0.9790 - jacard_coef: 0.9590 - binary_accuracy: 0.9923\n",
            "Epoch 00035: val_dice_coef did not improve from 0.97832\n",
            "62/61 [==============================] - 53s 852ms/step - loss: 0.0543 - binary_crossentropy: 0.0284 - dice_coef: 0.9790 - jacard_coef: 0.9590 - binary_accuracy: 0.9923 - val_loss: 0.0563 - val_binary_crossentropy: 0.0493 - val_dice_coef: 0.9770 - val_jacard_coef: 0.9551 - val_binary_accuracy: 0.9881\n",
            "Epoch 36/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0552 - binary_crossentropy: 0.0343 - dice_coef: 0.9782 - jacard_coef: 0.9577 - binary_accuracy: 0.9918\n",
            "Epoch 00036: val_dice_coef improved from 0.97832 to 0.97920, saving model to net_lung_seg.hdf5\n",
            "62/61 [==============================] - 55s 881ms/step - loss: 0.0552 - binary_crossentropy: 0.0343 - dice_coef: 0.9782 - jacard_coef: 0.9577 - binary_accuracy: 0.9918 - val_loss: 0.0556 - val_binary_crossentropy: 0.0432 - val_dice_coef: 0.9792 - val_jacard_coef: 0.9593 - val_binary_accuracy: 0.9893\n",
            "Epoch 37/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0554 - binary_crossentropy: 0.0363 - dice_coef: 0.9785 - jacard_coef: 0.9581 - binary_accuracy: 0.9916\n",
            "Epoch 00037: val_dice_coef did not improve from 0.97920\n",
            "62/61 [==============================] - 53s 853ms/step - loss: 0.0554 - binary_crossentropy: 0.0363 - dice_coef: 0.9785 - jacard_coef: 0.9581 - binary_accuracy: 0.9916 - val_loss: 0.0561 - val_binary_crossentropy: 0.0469 - val_dice_coef: 0.9781 - val_jacard_coef: 0.9572 - val_binary_accuracy: 0.9886\n",
            "Epoch 38/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0549 - binary_crossentropy: 0.0339 - dice_coef: 0.9793 - jacard_coef: 0.9598 - binary_accuracy: 0.9920\n",
            "Epoch 00038: val_dice_coef did not improve from 0.97920\n",
            "62/61 [==============================] - 53s 852ms/step - loss: 0.0549 - binary_crossentropy: 0.0339 - dice_coef: 0.9793 - jacard_coef: 0.9598 - binary_accuracy: 0.9920 - val_loss: 0.0563 - val_binary_crossentropy: 0.0487 - val_dice_coef: 0.9775 - val_jacard_coef: 0.9561 - val_binary_accuracy: 0.9881\n",
            "Epoch 39/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0532 - binary_crossentropy: 0.0239 - dice_coef: 0.9812 - jacard_coef: 0.9632 - binary_accuracy: 0.9932\n",
            "Epoch 00039: val_dice_coef did not improve from 0.97920\n",
            "62/61 [==============================] - 53s 854ms/step - loss: 0.0532 - binary_crossentropy: 0.0239 - dice_coef: 0.9812 - jacard_coef: 0.9632 - binary_accuracy: 0.9932 - val_loss: 0.0562 - val_binary_crossentropy: 0.0474 - val_dice_coef: 0.9790 - val_jacard_coef: 0.9590 - val_binary_accuracy: 0.9889\n",
            "Epoch 40/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0540 - binary_crossentropy: 0.0291 - dice_coef: 0.9805 - jacard_coef: 0.9619 - binary_accuracy: 0.9927\n",
            "Epoch 00040: val_dice_coef improved from 0.97920 to 0.97923, saving model to net_lung_seg.hdf5\n",
            "62/61 [==============================] - 55s 883ms/step - loss: 0.0540 - binary_crossentropy: 0.0291 - dice_coef: 0.9805 - jacard_coef: 0.9619 - binary_accuracy: 0.9927 - val_loss: 0.0559 - val_binary_crossentropy: 0.0475 - val_dice_coef: 0.9792 - val_jacard_coef: 0.9594 - val_binary_accuracy: 0.9890\n",
            "Epoch 41/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0542 - binary_crossentropy: 0.0307 - dice_coef: 0.9807 - jacard_coef: 0.9625 - binary_accuracy: 0.9927\n",
            "Epoch 00041: val_dice_coef improved from 0.97923 to 0.97957, saving model to net_lung_seg.hdf5\n",
            "62/61 [==============================] - 54s 878ms/step - loss: 0.0542 - binary_crossentropy: 0.0307 - dice_coef: 0.9807 - jacard_coef: 0.9625 - binary_accuracy: 0.9927 - val_loss: 0.0556 - val_binary_crossentropy: 0.0455 - val_dice_coef: 0.9796 - val_jacard_coef: 0.9600 - val_binary_accuracy: 0.9892\n",
            "Epoch 42/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0529 - binary_crossentropy: 0.0236 - dice_coef: 0.9822 - jacard_coef: 0.9651 - binary_accuracy: 0.9934\n",
            "Epoch 00042: val_dice_coef did not improve from 0.97957\n",
            "62/61 [==============================] - 53s 850ms/step - loss: 0.0529 - binary_crossentropy: 0.0236 - dice_coef: 0.9822 - jacard_coef: 0.9651 - binary_accuracy: 0.9934 - val_loss: 0.0560 - val_binary_crossentropy: 0.0492 - val_dice_coef: 0.9789 - val_jacard_coef: 0.9588 - val_binary_accuracy: 0.9888\n",
            "Epoch 43/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0532 - binary_crossentropy: 0.0261 - dice_coef: 0.9819 - jacard_coef: 0.9646 - binary_accuracy: 0.9931\n",
            "Epoch 00043: val_dice_coef did not improve from 0.97957\n",
            "62/61 [==============================] - 53s 852ms/step - loss: 0.0532 - binary_crossentropy: 0.0261 - dice_coef: 0.9819 - jacard_coef: 0.9646 - binary_accuracy: 0.9931 - val_loss: 0.0572 - val_binary_crossentropy: 0.0561 - val_dice_coef: 0.9767 - val_jacard_coef: 0.9546 - val_binary_accuracy: 0.9876\n",
            "Epoch 44/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0528 - binary_crossentropy: 0.0224 - dice_coef: 0.9824 - jacard_coef: 0.9655 - binary_accuracy: 0.9934\n",
            "Epoch 00044: val_dice_coef did not improve from 0.97957\n",
            "62/61 [==============================] - 53s 851ms/step - loss: 0.0528 - binary_crossentropy: 0.0224 - dice_coef: 0.9824 - jacard_coef: 0.9655 - binary_accuracy: 0.9934 - val_loss: 0.0569 - val_binary_crossentropy: 0.0556 - val_dice_coef: 0.9779 - val_jacard_coef: 0.9568 - val_binary_accuracy: 0.9882\n",
            "Epoch 45/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0535 - binary_crossentropy: 0.0272 - dice_coef: 0.9817 - jacard_coef: 0.9642 - binary_accuracy: 0.9929\n",
            "Epoch 00045: val_dice_coef did not improve from 0.97957\n",
            "62/61 [==============================] - 53s 853ms/step - loss: 0.0535 - binary_crossentropy: 0.0272 - dice_coef: 0.9817 - jacard_coef: 0.9642 - binary_accuracy: 0.9929 - val_loss: 0.0566 - val_binary_crossentropy: 0.0509 - val_dice_coef: 0.9790 - val_jacard_coef: 0.9589 - val_binary_accuracy: 0.9887\n",
            "Epoch 46/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0540 - binary_crossentropy: 0.0305 - dice_coef: 0.9814 - jacard_coef: 0.9637 - binary_accuracy: 0.9925\n",
            "Epoch 00046: val_dice_coef did not improve from 0.97957\n",
            "62/61 [==============================] - 53s 851ms/step - loss: 0.0540 - binary_crossentropy: 0.0305 - dice_coef: 0.9814 - jacard_coef: 0.9637 - binary_accuracy: 0.9925 - val_loss: 0.0559 - val_binary_crossentropy: 0.0464 - val_dice_coef: 0.9793 - val_jacard_coef: 0.9596 - val_binary_accuracy: 0.9890\n",
            "Epoch 47/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0533 - binary_crossentropy: 0.0261 - dice_coef: 0.9818 - jacard_coef: 0.9643 - binary_accuracy: 0.9928\n",
            "Epoch 00047: val_dice_coef did not improve from 0.97957\n",
            "62/61 [==============================] - 53s 852ms/step - loss: 0.0533 - binary_crossentropy: 0.0261 - dice_coef: 0.9818 - jacard_coef: 0.9643 - binary_accuracy: 0.9928 - val_loss: 0.0563 - val_binary_crossentropy: 0.0503 - val_dice_coef: 0.9790 - val_jacard_coef: 0.9589 - val_binary_accuracy: 0.9889\n",
            "Epoch 48/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0544 - binary_crossentropy: 0.0330 - dice_coef: 0.9809 - jacard_coef: 0.9628 - binary_accuracy: 0.9922\n",
            "Epoch 00048: val_dice_coef did not improve from 0.97957\n",
            "62/61 [==============================] - 53s 852ms/step - loss: 0.0544 - binary_crossentropy: 0.0330 - dice_coef: 0.9809 - jacard_coef: 0.9628 - binary_accuracy: 0.9922 - val_loss: 0.0569 - val_binary_crossentropy: 0.0556 - val_dice_coef: 0.9785 - val_jacard_coef: 0.9581 - val_binary_accuracy: 0.9885\n",
            "Epoch 49/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0552 - binary_crossentropy: 0.0353 - dice_coef: 0.9785 - jacard_coef: 0.9581 - binary_accuracy: 0.9910\n",
            "Epoch 00049: val_dice_coef did not improve from 0.97957\n",
            "62/61 [==============================] - 53s 853ms/step - loss: 0.0552 - binary_crossentropy: 0.0353 - dice_coef: 0.9785 - jacard_coef: 0.9581 - binary_accuracy: 0.9910 - val_loss: 0.0674 - val_binary_crossentropy: 0.1158 - val_dice_coef: 0.9611 - val_jacard_coef: 0.9253 - val_binary_accuracy: 0.9789\n",
            "Epoch 50/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0564 - binary_crossentropy: 0.0413 - dice_coef: 0.9765 - jacard_coef: 0.9542 - binary_accuracy: 0.9898\n",
            "Epoch 00050: val_dice_coef did not improve from 0.97957\n",
            "62/61 [==============================] - 53s 855ms/step - loss: 0.0564 - binary_crossentropy: 0.0413 - dice_coef: 0.9765 - jacard_coef: 0.9542 - binary_accuracy: 0.9898 - val_loss: 0.0619 - val_binary_crossentropy: 0.0835 - val_dice_coef: 0.9676 - val_jacard_coef: 0.9373 - val_binary_accuracy: 0.9827\n",
            "Epoch 51/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0550 - binary_crossentropy: 0.0338 - dice_coef: 0.9786 - jacard_coef: 0.9582 - binary_accuracy: 0.9910\n",
            "Epoch 00051: val_dice_coef did not improve from 0.97957\n",
            "62/61 [==============================] - 53s 851ms/step - loss: 0.0550 - binary_crossentropy: 0.0338 - dice_coef: 0.9786 - jacard_coef: 0.9582 - binary_accuracy: 0.9910 - val_loss: 0.0570 - val_binary_crossentropy: 0.0564 - val_dice_coef: 0.9768 - val_jacard_coef: 0.9547 - val_binary_accuracy: 0.9876\n",
            "Epoch 52/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0543 - binary_crossentropy: 0.0301 - dice_coef: 0.9799 - jacard_coef: 0.9606 - binary_accuracy: 0.9915\n",
            "Epoch 00052: val_dice_coef did not improve from 0.97957\n",
            "62/61 [==============================] - 53s 852ms/step - loss: 0.0543 - binary_crossentropy: 0.0301 - dice_coef: 0.9799 - jacard_coef: 0.9606 - binary_accuracy: 0.9915 - val_loss: 0.0563 - val_binary_crossentropy: 0.0505 - val_dice_coef: 0.9783 - val_jacard_coef: 0.9576 - val_binary_accuracy: 0.9885\n",
            "Epoch 53/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0540 - binary_crossentropy: 0.0293 - dice_coef: 0.9808 - jacard_coef: 0.9624 - binary_accuracy: 0.9920\n",
            "Epoch 00053: val_dice_coef did not improve from 0.97957\n",
            "62/61 [==============================] - 53s 852ms/step - loss: 0.0540 - binary_crossentropy: 0.0293 - dice_coef: 0.9808 - jacard_coef: 0.9624 - binary_accuracy: 0.9920 - val_loss: 0.0581 - val_binary_crossentropy: 0.0624 - val_dice_coef: 0.9752 - val_jacard_coef: 0.9516 - val_binary_accuracy: 0.9865\n",
            "Epoch 54/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0539 - binary_crossentropy: 0.0295 - dice_coef: 0.9814 - jacard_coef: 0.9636 - binary_accuracy: 0.9922\n",
            "Epoch 00054: val_dice_coef did not improve from 0.97957\n",
            "62/61 [==============================] - 53s 854ms/step - loss: 0.0539 - binary_crossentropy: 0.0295 - dice_coef: 0.9814 - jacard_coef: 0.9636 - binary_accuracy: 0.9922 - val_loss: 0.0556 - val_binary_crossentropy: 0.0449 - val_dice_coef: 0.9795 - val_jacard_coef: 0.9599 - val_binary_accuracy: 0.9891\n",
            "Epoch 55/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0538 - binary_crossentropy: 0.0298 - dice_coef: 0.9820 - jacard_coef: 0.9648 - binary_accuracy: 0.9925\n",
            "Epoch 00055: val_dice_coef did not improve from 0.97957\n",
            "62/61 [==============================] - 53s 851ms/step - loss: 0.0538 - binary_crossentropy: 0.0298 - dice_coef: 0.9820 - jacard_coef: 0.9648 - binary_accuracy: 0.9925 - val_loss: 0.0554 - val_binary_crossentropy: 0.0455 - val_dice_coef: 0.9795 - val_jacard_coef: 0.9599 - val_binary_accuracy: 0.9891\n",
            "Epoch 56/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0528 - binary_crossentropy: 0.0237 - dice_coef: 0.9831 - jacard_coef: 0.9669 - binary_accuracy: 0.9931\n",
            "Epoch 00056: val_dice_coef did not improve from 0.97957\n",
            "62/61 [==============================] - 53s 854ms/step - loss: 0.0528 - binary_crossentropy: 0.0237 - dice_coef: 0.9831 - jacard_coef: 0.9669 - binary_accuracy: 0.9931 - val_loss: 0.0559 - val_binary_crossentropy: 0.0474 - val_dice_coef: 0.9794 - val_jacard_coef: 0.9598 - val_binary_accuracy: 0.9891\n",
            "Epoch 57/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0526 - binary_crossentropy: 0.0223 - dice_coef: 0.9837 - jacard_coef: 0.9679 - binary_accuracy: 0.9933\n",
            "Epoch 00057: val_dice_coef improved from 0.97957 to 0.97993, saving model to net_lung_seg.hdf5\n",
            "62/61 [==============================] - 55s 882ms/step - loss: 0.0526 - binary_crossentropy: 0.0223 - dice_coef: 0.9837 - jacard_coef: 0.9679 - binary_accuracy: 0.9933 - val_loss: 0.0554 - val_binary_crossentropy: 0.0450 - val_dice_coef: 0.9799 - val_jacard_coef: 0.9607 - val_binary_accuracy: 0.9893\n",
            "Epoch 58/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0528 - binary_crossentropy: 0.0244 - dice_coef: 0.9840 - jacard_coef: 0.9685 - binary_accuracy: 0.9934\n",
            "Epoch 00058: val_dice_coef improved from 0.97993 to 0.98009, saving model to net_lung_seg.hdf5\n",
            "62/61 [==============================] - 55s 879ms/step - loss: 0.0528 - binary_crossentropy: 0.0244 - dice_coef: 0.9840 - jacard_coef: 0.9685 - binary_accuracy: 0.9934 - val_loss: 0.0557 - val_binary_crossentropy: 0.0469 - val_dice_coef: 0.9801 - val_jacard_coef: 0.9610 - val_binary_accuracy: 0.9894\n",
            "Epoch 59/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0526 - binary_crossentropy: 0.0244 - dice_coef: 0.9843 - jacard_coef: 0.9692 - binary_accuracy: 0.9935\n",
            "Epoch 00059: val_dice_coef did not improve from 0.98009\n",
            "62/61 [==============================] - 53s 851ms/step - loss: 0.0526 - binary_crossentropy: 0.0244 - dice_coef: 0.9843 - jacard_coef: 0.9692 - binary_accuracy: 0.9935 - val_loss: 0.0561 - val_binary_crossentropy: 0.0504 - val_dice_coef: 0.9796 - val_jacard_coef: 0.9601 - val_binary_accuracy: 0.9890\n",
            "Epoch 60/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0530 - binary_crossentropy: 0.0279 - dice_coef: 0.9839 - jacard_coef: 0.9685 - binary_accuracy: 0.9933\n",
            "Epoch 00060: val_dice_coef improved from 0.98009 to 0.98034, saving model to net_lung_seg.hdf5\n",
            "62/61 [==============================] - 55s 880ms/step - loss: 0.0530 - binary_crossentropy: 0.0279 - dice_coef: 0.9839 - jacard_coef: 0.9685 - binary_accuracy: 0.9933 - val_loss: 0.0555 - val_binary_crossentropy: 0.0460 - val_dice_coef: 0.9803 - val_jacard_coef: 0.9615 - val_binary_accuracy: 0.9895\n",
            "Epoch 61/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0523 - binary_crossentropy: 0.0241 - dice_coef: 0.9847 - jacard_coef: 0.9700 - binary_accuracy: 0.9937\n",
            "Epoch 00061: val_dice_coef did not improve from 0.98034\n",
            "62/61 [==============================] - 53s 853ms/step - loss: 0.0523 - binary_crossentropy: 0.0241 - dice_coef: 0.9847 - jacard_coef: 0.9700 - binary_accuracy: 0.9937 - val_loss: 0.0558 - val_binary_crossentropy: 0.0476 - val_dice_coef: 0.9799 - val_jacard_coef: 0.9606 - val_binary_accuracy: 0.9892\n",
            "Epoch 62/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0515 - binary_crossentropy: 0.0183 - dice_coef: 0.9857 - jacard_coef: 0.9718 - binary_accuracy: 0.9942\n",
            "Epoch 00062: val_dice_coef did not improve from 0.98034\n",
            "62/61 [==============================] - 53s 851ms/step - loss: 0.0515 - binary_crossentropy: 0.0183 - dice_coef: 0.9857 - jacard_coef: 0.9718 - binary_accuracy: 0.9942 - val_loss: 0.0564 - val_binary_crossentropy: 0.0509 - val_dice_coef: 0.9798 - val_jacard_coef: 0.9605 - val_binary_accuracy: 0.9892\n",
            "Epoch 63/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0522 - binary_crossentropy: 0.0227 - dice_coef: 0.9850 - jacard_coef: 0.9705 - binary_accuracy: 0.9938\n",
            "Epoch 00063: val_dice_coef did not improve from 0.98034\n",
            "62/61 [==============================] - 53s 855ms/step - loss: 0.0522 - binary_crossentropy: 0.0227 - dice_coef: 0.9850 - jacard_coef: 0.9705 - binary_accuracy: 0.9938 - val_loss: 0.0567 - val_binary_crossentropy: 0.0555 - val_dice_coef: 0.9790 - val_jacard_coef: 0.9590 - val_binary_accuracy: 0.9887\n",
            "Epoch 64/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0514 - binary_crossentropy: 0.0182 - dice_coef: 0.9860 - jacard_coef: 0.9724 - binary_accuracy: 0.9943\n",
            "Epoch 00064: val_dice_coef improved from 0.98034 to 0.98049, saving model to net_lung_seg.hdf5\n",
            "62/61 [==============================] - 55s 883ms/step - loss: 0.0514 - binary_crossentropy: 0.0182 - dice_coef: 0.9860 - jacard_coef: 0.9724 - binary_accuracy: 0.9943 - val_loss: 0.0558 - val_binary_crossentropy: 0.0479 - val_dice_coef: 0.9805 - val_jacard_coef: 0.9618 - val_binary_accuracy: 0.9895\n",
            "Epoch 65/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0526 - binary_crossentropy: 0.0254 - dice_coef: 0.9849 - jacard_coef: 0.9703 - binary_accuracy: 0.9935\n",
            "Epoch 00065: val_dice_coef did not improve from 0.98049\n",
            "62/61 [==============================] - 53s 850ms/step - loss: 0.0526 - binary_crossentropy: 0.0254 - dice_coef: 0.9849 - jacard_coef: 0.9703 - binary_accuracy: 0.9935 - val_loss: 0.0555 - val_binary_crossentropy: 0.0476 - val_dice_coef: 0.9804 - val_jacard_coef: 0.9617 - val_binary_accuracy: 0.9895\n",
            "Epoch 66/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0520 - binary_crossentropy: 0.0212 - dice_coef: 0.9854 - jacard_coef: 0.9713 - binary_accuracy: 0.9939\n",
            "Epoch 00066: val_dice_coef did not improve from 0.98049\n",
            "62/61 [==============================] - 53s 852ms/step - loss: 0.0520 - binary_crossentropy: 0.0212 - dice_coef: 0.9854 - jacard_coef: 0.9713 - binary_accuracy: 0.9939 - val_loss: 0.0562 - val_binary_crossentropy: 0.0520 - val_dice_coef: 0.9799 - val_jacard_coef: 0.9607 - val_binary_accuracy: 0.9891\n",
            "Epoch 67/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0524 - binary_crossentropy: 0.0241 - dice_coef: 0.9850 - jacard_coef: 0.9704 - binary_accuracy: 0.9936\n",
            "Epoch 00067: val_dice_coef did not improve from 0.98049\n",
            "62/61 [==============================] - 53s 852ms/step - loss: 0.0524 - binary_crossentropy: 0.0241 - dice_coef: 0.9850 - jacard_coef: 0.9704 - binary_accuracy: 0.9936 - val_loss: 0.0572 - val_binary_crossentropy: 0.0580 - val_dice_coef: 0.9785 - val_jacard_coef: 0.9580 - val_binary_accuracy: 0.9884\n",
            "Epoch 68/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0544 - binary_crossentropy: 0.0384 - dice_coef: 0.9832 - jacard_coef: 0.9674 - binary_accuracy: 0.9924\n",
            "Epoch 00068: val_dice_coef did not improve from 0.98049\n",
            "62/61 [==============================] - 53s 855ms/step - loss: 0.0544 - binary_crossentropy: 0.0384 - dice_coef: 0.9832 - jacard_coef: 0.9674 - binary_accuracy: 0.9924 - val_loss: 0.0572 - val_binary_crossentropy: 0.0586 - val_dice_coef: 0.9785 - val_jacard_coef: 0.9579 - val_binary_accuracy: 0.9883\n",
            "Epoch 69/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0523 - binary_crossentropy: 0.0244 - dice_coef: 0.9849 - jacard_coef: 0.9703 - binary_accuracy: 0.9935\n",
            "Epoch 00069: val_dice_coef did not improve from 0.98049\n",
            "62/61 [==============================] - 53s 853ms/step - loss: 0.0523 - binary_crossentropy: 0.0244 - dice_coef: 0.9849 - jacard_coef: 0.9703 - binary_accuracy: 0.9935 - val_loss: 0.0567 - val_binary_crossentropy: 0.0540 - val_dice_coef: 0.9780 - val_jacard_coef: 0.9569 - val_binary_accuracy: 0.9881\n",
            "Epoch 70/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0517 - binary_crossentropy: 0.0195 - dice_coef: 0.9857 - jacard_coef: 0.9718 - binary_accuracy: 0.9939\n",
            "Epoch 00070: val_dice_coef did not improve from 0.98049\n",
            "62/61 [==============================] - 53s 853ms/step - loss: 0.0517 - binary_crossentropy: 0.0195 - dice_coef: 0.9857 - jacard_coef: 0.9718 - binary_accuracy: 0.9939 - val_loss: 0.0572 - val_binary_crossentropy: 0.0576 - val_dice_coef: 0.9787 - val_jacard_coef: 0.9584 - val_binary_accuracy: 0.9885\n",
            "Epoch 71/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0541 - binary_crossentropy: 0.0362 - dice_coef: 0.9834 - jacard_coef: 0.9677 - binary_accuracy: 0.9925\n",
            "Epoch 00071: val_dice_coef did not improve from 0.98049\n",
            "62/61 [==============================] - 53s 854ms/step - loss: 0.0541 - binary_crossentropy: 0.0362 - dice_coef: 0.9834 - jacard_coef: 0.9677 - binary_accuracy: 0.9925 - val_loss: 0.0563 - val_binary_crossentropy: 0.0522 - val_dice_coef: 0.9798 - val_jacard_coef: 0.9604 - val_binary_accuracy: 0.9891\n",
            "Epoch 72/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0513 - binary_crossentropy: 0.0181 - dice_coef: 0.9864 - jacard_coef: 0.9732 - binary_accuracy: 0.9942\n",
            "Epoch 00072: val_dice_coef did not improve from 0.98049\n",
            "62/61 [==============================] - 53s 850ms/step - loss: 0.0513 - binary_crossentropy: 0.0181 - dice_coef: 0.9864 - jacard_coef: 0.9732 - binary_accuracy: 0.9942 - val_loss: 0.0566 - val_binary_crossentropy: 0.0542 - val_dice_coef: 0.9799 - val_jacard_coef: 0.9607 - val_binary_accuracy: 0.9892\n",
            "Epoch 73/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0518 - binary_crossentropy: 0.0213 - dice_coef: 0.9863 - jacard_coef: 0.9730 - binary_accuracy: 0.9941\n",
            "Epoch 00073: val_dice_coef did not improve from 0.98049\n",
            "62/61 [==============================] - 53s 854ms/step - loss: 0.0518 - binary_crossentropy: 0.0213 - dice_coef: 0.9863 - jacard_coef: 0.9730 - binary_accuracy: 0.9941 - val_loss: 0.0561 - val_binary_crossentropy: 0.0506 - val_dice_coef: 0.9798 - val_jacard_coef: 0.9604 - val_binary_accuracy: 0.9891\n",
            "Epoch 74/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0515 - binary_crossentropy: 0.0199 - dice_coef: 0.9865 - jacard_coef: 0.9733 - binary_accuracy: 0.9943\n",
            "Epoch 00074: val_dice_coef did not improve from 0.98049\n",
            "62/61 [==============================] - 53s 854ms/step - loss: 0.0515 - binary_crossentropy: 0.0199 - dice_coef: 0.9865 - jacard_coef: 0.9733 - binary_accuracy: 0.9943 - val_loss: 0.0565 - val_binary_crossentropy: 0.0547 - val_dice_coef: 0.9799 - val_jacard_coef: 0.9607 - val_binary_accuracy: 0.9891\n",
            "Epoch 75/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0514 - binary_crossentropy: 0.0203 - dice_coef: 0.9868 - jacard_coef: 0.9739 - binary_accuracy: 0.9943\n",
            "Epoch 00075: val_dice_coef did not improve from 0.98049\n",
            "62/61 [==============================] - 53s 851ms/step - loss: 0.0514 - binary_crossentropy: 0.0203 - dice_coef: 0.9868 - jacard_coef: 0.9739 - binary_accuracy: 0.9943 - val_loss: 0.0568 - val_binary_crossentropy: 0.0552 - val_dice_coef: 0.9801 - val_jacard_coef: 0.9611 - val_binary_accuracy: 0.9892\n",
            "Epoch 76/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0510 - binary_crossentropy: 0.0168 - dice_coef: 0.9875 - jacard_coef: 0.9753 - binary_accuracy: 0.9947\n",
            "Epoch 00076: val_dice_coef did not improve from 0.98049\n",
            "62/61 [==============================] - 53s 852ms/step - loss: 0.0510 - binary_crossentropy: 0.0168 - dice_coef: 0.9875 - jacard_coef: 0.9753 - binary_accuracy: 0.9947 - val_loss: 0.0569 - val_binary_crossentropy: 0.0575 - val_dice_coef: 0.9796 - val_jacard_coef: 0.9601 - val_binary_accuracy: 0.9890\n",
            "Epoch 77/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0510 - binary_crossentropy: 0.0177 - dice_coef: 0.9875 - jacard_coef: 0.9753 - binary_accuracy: 0.9947\n",
            "Epoch 00077: val_dice_coef improved from 0.98049 to 0.98050, saving model to net_lung_seg.hdf5\n",
            "62/61 [==============================] - 55s 879ms/step - loss: 0.0510 - binary_crossentropy: 0.0177 - dice_coef: 0.9875 - jacard_coef: 0.9753 - binary_accuracy: 0.9947 - val_loss: 0.0563 - val_binary_crossentropy: 0.0530 - val_dice_coef: 0.9805 - val_jacard_coef: 0.9618 - val_binary_accuracy: 0.9895\n",
            "Epoch 78/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0514 - binary_crossentropy: 0.0214 - dice_coef: 0.9876 - jacard_coef: 0.9755 - binary_accuracy: 0.9946\n",
            "Epoch 00078: val_dice_coef did not improve from 0.98050\n",
            "62/61 [==============================] - 53s 855ms/step - loss: 0.0514 - binary_crossentropy: 0.0214 - dice_coef: 0.9876 - jacard_coef: 0.9755 - binary_accuracy: 0.9946 - val_loss: 0.0564 - val_binary_crossentropy: 0.0537 - val_dice_coef: 0.9803 - val_jacard_coef: 0.9615 - val_binary_accuracy: 0.9894\n",
            "Epoch 79/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0505 - binary_crossentropy: 0.0149 - dice_coef: 0.9885 - jacard_coef: 0.9773 - binary_accuracy: 0.9952\n",
            "Epoch 00079: val_dice_coef improved from 0.98050 to 0.98054, saving model to net_lung_seg.hdf5\n",
            "62/61 [==============================] - 55s 880ms/step - loss: 0.0505 - binary_crossentropy: 0.0149 - dice_coef: 0.9885 - jacard_coef: 0.9773 - binary_accuracy: 0.9952 - val_loss: 0.0560 - val_binary_crossentropy: 0.0519 - val_dice_coef: 0.9805 - val_jacard_coef: 0.9619 - val_binary_accuracy: 0.9894\n",
            "Epoch 80/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0505 - binary_crossentropy: 0.0157 - dice_coef: 0.9884 - jacard_coef: 0.9770 - binary_accuracy: 0.9951\n",
            "Epoch 00080: val_dice_coef did not improve from 0.98054\n",
            "62/61 [==============================] - 53s 854ms/step - loss: 0.0505 - binary_crossentropy: 0.0157 - dice_coef: 0.9884 - jacard_coef: 0.9770 - binary_accuracy: 0.9951 - val_loss: 0.0564 - val_binary_crossentropy: 0.0552 - val_dice_coef: 0.9801 - val_jacard_coef: 0.9610 - val_binary_accuracy: 0.9891\n",
            "Epoch 81/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0551 - binary_crossentropy: 0.0478 - dice_coef: 0.9846 - jacard_coef: 0.9712 - binary_accuracy: 0.9931\n",
            "Epoch 00081: val_dice_coef did not improve from 0.98054\n",
            "62/61 [==============================] - 53s 852ms/step - loss: 0.0551 - binary_crossentropy: 0.0478 - dice_coef: 0.9846 - jacard_coef: 0.9712 - binary_accuracy: 0.9931 - val_loss: 0.0562 - val_binary_crossentropy: 0.0532 - val_dice_coef: 0.9804 - val_jacard_coef: 0.9616 - val_binary_accuracy: 0.9893\n",
            "Epoch 82/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0509 - binary_crossentropy: 0.0178 - dice_coef: 0.9881 - jacard_coef: 0.9765 - binary_accuracy: 0.9949\n",
            "Epoch 00082: val_dice_coef did not improve from 0.98054\n",
            "62/61 [==============================] - 53s 854ms/step - loss: 0.0509 - binary_crossentropy: 0.0178 - dice_coef: 0.9881 - jacard_coef: 0.9765 - binary_accuracy: 0.9949 - val_loss: 0.0565 - val_binary_crossentropy: 0.0553 - val_dice_coef: 0.9804 - val_jacard_coef: 0.9617 - val_binary_accuracy: 0.9893\n",
            "Epoch 83/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0512 - binary_crossentropy: 0.0195 - dice_coef: 0.9878 - jacard_coef: 0.9759 - binary_accuracy: 0.9947\n",
            "Epoch 00083: val_dice_coef did not improve from 0.98054\n",
            "62/61 [==============================] - 53s 852ms/step - loss: 0.0512 - binary_crossentropy: 0.0195 - dice_coef: 0.9878 - jacard_coef: 0.9759 - binary_accuracy: 0.9947 - val_loss: 0.0567 - val_binary_crossentropy: 0.0577 - val_dice_coef: 0.9803 - val_jacard_coef: 0.9615 - val_binary_accuracy: 0.9892\n",
            "Epoch 84/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0509 - binary_crossentropy: 0.0178 - dice_coef: 0.9881 - jacard_coef: 0.9765 - binary_accuracy: 0.9949\n",
            "Epoch 00084: val_dice_coef did not improve from 0.98054\n",
            "62/61 [==============================] - 53s 852ms/step - loss: 0.0509 - binary_crossentropy: 0.0178 - dice_coef: 0.9881 - jacard_coef: 0.9765 - binary_accuracy: 0.9949 - val_loss: 0.0573 - val_binary_crossentropy: 0.0611 - val_dice_coef: 0.9800 - val_jacard_coef: 0.9609 - val_binary_accuracy: 0.9891\n",
            "Epoch 85/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0507 - binary_crossentropy: 0.0165 - dice_coef: 0.9883 - jacard_coef: 0.9769 - binary_accuracy: 0.9950\n",
            "Epoch 00085: val_dice_coef did not improve from 0.98054\n",
            "62/61 [==============================] - 53s 852ms/step - loss: 0.0507 - binary_crossentropy: 0.0165 - dice_coef: 0.9883 - jacard_coef: 0.9769 - binary_accuracy: 0.9950 - val_loss: 0.0573 - val_binary_crossentropy: 0.0620 - val_dice_coef: 0.9801 - val_jacard_coef: 0.9610 - val_binary_accuracy: 0.9891\n",
            "Epoch 86/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0508 - binary_crossentropy: 0.0172 - dice_coef: 0.9882 - jacard_coef: 0.9766 - binary_accuracy: 0.9949\n",
            "Epoch 00086: val_dice_coef did not improve from 0.98054\n",
            "62/61 [==============================] - 53s 850ms/step - loss: 0.0508 - binary_crossentropy: 0.0172 - dice_coef: 0.9882 - jacard_coef: 0.9766 - binary_accuracy: 0.9949 - val_loss: 0.0572 - val_binary_crossentropy: 0.0604 - val_dice_coef: 0.9803 - val_jacard_coef: 0.9614 - val_binary_accuracy: 0.9892\n",
            "Epoch 87/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0515 - binary_crossentropy: 0.0223 - dice_coef: 0.9877 - jacard_coef: 0.9757 - binary_accuracy: 0.9945\n",
            "Epoch 00087: val_dice_coef did not improve from 0.98054\n",
            "62/61 [==============================] - 53s 853ms/step - loss: 0.0515 - binary_crossentropy: 0.0223 - dice_coef: 0.9877 - jacard_coef: 0.9757 - binary_accuracy: 0.9945 - val_loss: 0.0573 - val_binary_crossentropy: 0.0612 - val_dice_coef: 0.9795 - val_jacard_coef: 0.9599 - val_binary_accuracy: 0.9889\n",
            "Epoch 88/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0505 - binary_crossentropy: 0.0157 - dice_coef: 0.9883 - jacard_coef: 0.9769 - binary_accuracy: 0.9949\n",
            "Epoch 00088: val_dice_coef did not improve from 0.98054\n",
            "62/61 [==============================] - 53s 853ms/step - loss: 0.0505 - binary_crossentropy: 0.0157 - dice_coef: 0.9883 - jacard_coef: 0.9769 - binary_accuracy: 0.9949 - val_loss: 0.0570 - val_binary_crossentropy: 0.0592 - val_dice_coef: 0.9797 - val_jacard_coef: 0.9603 - val_binary_accuracy: 0.9889\n",
            "Epoch 89/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0519 - binary_crossentropy: 0.0244 - dice_coef: 0.9867 - jacard_coef: 0.9739 - binary_accuracy: 0.9940\n",
            "Epoch 00089: val_dice_coef did not improve from 0.98054\n",
            "62/61 [==============================] - 53s 854ms/step - loss: 0.0519 - binary_crossentropy: 0.0244 - dice_coef: 0.9867 - jacard_coef: 0.9739 - binary_accuracy: 0.9940 - val_loss: 0.0571 - val_binary_crossentropy: 0.0609 - val_dice_coef: 0.9798 - val_jacard_coef: 0.9604 - val_binary_accuracy: 0.9890\n",
            "Epoch 90/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0512 - binary_crossentropy: 0.0192 - dice_coef: 0.9875 - jacard_coef: 0.9754 - binary_accuracy: 0.9944\n",
            "Epoch 00090: val_dice_coef did not improve from 0.98054\n",
            "62/61 [==============================] - 53s 852ms/step - loss: 0.0512 - binary_crossentropy: 0.0192 - dice_coef: 0.9875 - jacard_coef: 0.9754 - binary_accuracy: 0.9944 - val_loss: 0.0571 - val_binary_crossentropy: 0.0601 - val_dice_coef: 0.9796 - val_jacard_coef: 0.9602 - val_binary_accuracy: 0.9889\n",
            "Epoch 91/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0511 - binary_crossentropy: 0.0188 - dice_coef: 0.9878 - jacard_coef: 0.9760 - binary_accuracy: 0.9946\n",
            "Epoch 00091: val_dice_coef did not improve from 0.98054\n",
            "62/61 [==============================] - 53s 850ms/step - loss: 0.0511 - binary_crossentropy: 0.0188 - dice_coef: 0.9878 - jacard_coef: 0.9760 - binary_accuracy: 0.9946 - val_loss: 0.0574 - val_binary_crossentropy: 0.0609 - val_dice_coef: 0.9793 - val_jacard_coef: 0.9596 - val_binary_accuracy: 0.9888\n",
            "Epoch 92/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0522 - binary_crossentropy: 0.0270 - dice_coef: 0.9870 - jacard_coef: 0.9745 - binary_accuracy: 0.9941\n",
            "Epoch 00092: val_dice_coef did not improve from 0.98054\n",
            "62/61 [==============================] - 53s 853ms/step - loss: 0.0522 - binary_crossentropy: 0.0270 - dice_coef: 0.9870 - jacard_coef: 0.9745 - binary_accuracy: 0.9941 - val_loss: 0.0570 - val_binary_crossentropy: 0.0596 - val_dice_coef: 0.9793 - val_jacard_coef: 0.9594 - val_binary_accuracy: 0.9887\n",
            "Epoch 93/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0506 - binary_crossentropy: 0.0156 - dice_coef: 0.9884 - jacard_coef: 0.9770 - binary_accuracy: 0.9948\n",
            "Epoch 00093: val_dice_coef did not improve from 0.98054\n",
            "62/61 [==============================] - 53s 854ms/step - loss: 0.0506 - binary_crossentropy: 0.0156 - dice_coef: 0.9884 - jacard_coef: 0.9770 - binary_accuracy: 0.9948 - val_loss: 0.0567 - val_binary_crossentropy: 0.0576 - val_dice_coef: 0.9804 - val_jacard_coef: 0.9616 - val_binary_accuracy: 0.9893\n",
            "Epoch 94/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0521 - binary_crossentropy: 0.0264 - dice_coef: 0.9869 - jacard_coef: 0.9744 - binary_accuracy: 0.9940\n",
            "Epoch 00094: val_dice_coef did not improve from 0.98054\n",
            "62/61 [==============================] - 53s 853ms/step - loss: 0.0521 - binary_crossentropy: 0.0264 - dice_coef: 0.9869 - jacard_coef: 0.9744 - binary_accuracy: 0.9940 - val_loss: 0.0570 - val_binary_crossentropy: 0.0598 - val_dice_coef: 0.9803 - val_jacard_coef: 0.9614 - val_binary_accuracy: 0.9892\n",
            "Epoch 95/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0511 - binary_crossentropy: 0.0210 - dice_coef: 0.9884 - jacard_coef: 0.9771 - binary_accuracy: 0.9949\n",
            "Epoch 00095: val_dice_coef did not improve from 0.98054\n",
            "62/61 [==============================] - 53s 854ms/step - loss: 0.0511 - binary_crossentropy: 0.0210 - dice_coef: 0.9884 - jacard_coef: 0.9771 - binary_accuracy: 0.9949 - val_loss: 0.0574 - val_binary_crossentropy: 0.0617 - val_dice_coef: 0.9798 - val_jacard_coef: 0.9604 - val_binary_accuracy: 0.9889\n",
            "Epoch 96/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0510 - binary_crossentropy: 0.0195 - dice_coef: 0.9884 - jacard_coef: 0.9772 - binary_accuracy: 0.9948\n",
            "Epoch 00096: val_dice_coef improved from 0.98054 to 0.98091, saving model to net_lung_seg.hdf5\n",
            "62/61 [==============================] - 55s 883ms/step - loss: 0.0510 - binary_crossentropy: 0.0195 - dice_coef: 0.9884 - jacard_coef: 0.9772 - binary_accuracy: 0.9948 - val_loss: 0.0564 - val_binary_crossentropy: 0.0555 - val_dice_coef: 0.9809 - val_jacard_coef: 0.9626 - val_binary_accuracy: 0.9895\n",
            "Epoch 97/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0506 - binary_crossentropy: 0.0173 - dice_coef: 0.9891 - jacard_coef: 0.9784 - binary_accuracy: 0.9952\n",
            "Epoch 00097: val_dice_coef did not improve from 0.98091\n",
            "62/61 [==============================] - 53s 851ms/step - loss: 0.0506 - binary_crossentropy: 0.0173 - dice_coef: 0.9891 - jacard_coef: 0.9784 - binary_accuracy: 0.9952 - val_loss: 0.0568 - val_binary_crossentropy: 0.0577 - val_dice_coef: 0.9804 - val_jacard_coef: 0.9616 - val_binary_accuracy: 0.9893\n",
            "Epoch 98/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0506 - binary_crossentropy: 0.0181 - dice_coef: 0.9891 - jacard_coef: 0.9785 - binary_accuracy: 0.9952\n",
            "Epoch 00098: val_dice_coef improved from 0.98091 to 0.98105, saving model to net_lung_seg.hdf5\n",
            "62/61 [==============================] - 55s 881ms/step - loss: 0.0506 - binary_crossentropy: 0.0181 - dice_coef: 0.9891 - jacard_coef: 0.9785 - binary_accuracy: 0.9952 - val_loss: 0.0561 - val_binary_crossentropy: 0.0533 - val_dice_coef: 0.9810 - val_jacard_coef: 0.9629 - val_binary_accuracy: 0.9896\n",
            "Epoch 99/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0503 - binary_crossentropy: 0.0164 - dice_coef: 0.9896 - jacard_coef: 0.9794 - binary_accuracy: 0.9954\n",
            "Epoch 00099: val_dice_coef did not improve from 0.98105\n",
            "62/61 [==============================] - 53s 853ms/step - loss: 0.0503 - binary_crossentropy: 0.0164 - dice_coef: 0.9896 - jacard_coef: 0.9794 - binary_accuracy: 0.9954 - val_loss: 0.0564 - val_binary_crossentropy: 0.0556 - val_dice_coef: 0.9807 - val_jacard_coef: 0.9623 - val_binary_accuracy: 0.9895\n",
            "Epoch 100/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0504 - binary_crossentropy: 0.0165 - dice_coef: 0.9895 - jacard_coef: 0.9793 - binary_accuracy: 0.9954\n",
            "Epoch 00100: val_dice_coef did not improve from 0.98105\n",
            "62/61 [==============================] - 53s 851ms/step - loss: 0.0504 - binary_crossentropy: 0.0165 - dice_coef: 0.9895 - jacard_coef: 0.9793 - binary_accuracy: 0.9954 - val_loss: 0.0571 - val_binary_crossentropy: 0.0613 - val_dice_coef: 0.9797 - val_jacard_coef: 0.9602 - val_binary_accuracy: 0.9888\n",
            "Epoch 101/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0503 - binary_crossentropy: 0.0158 - dice_coef: 0.9898 - jacard_coef: 0.9798 - binary_accuracy: 0.9955\n",
            "Epoch 00101: val_dice_coef did not improve from 0.98105\n",
            "62/61 [==============================] - 53s 852ms/step - loss: 0.0503 - binary_crossentropy: 0.0158 - dice_coef: 0.9898 - jacard_coef: 0.9798 - binary_accuracy: 0.9955 - val_loss: 0.0567 - val_binary_crossentropy: 0.0590 - val_dice_coef: 0.9809 - val_jacard_coef: 0.9625 - val_binary_accuracy: 0.9895\n",
            "Epoch 102/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0500 - binary_crossentropy: 0.0150 - dice_coef: 0.9898 - jacard_coef: 0.9798 - binary_accuracy: 0.9955\n",
            "Epoch 00102: val_dice_coef did not improve from 0.98105\n",
            "62/61 [==============================] - 53s 854ms/step - loss: 0.0500 - binary_crossentropy: 0.0150 - dice_coef: 0.9898 - jacard_coef: 0.9798 - binary_accuracy: 0.9955 - val_loss: 0.0569 - val_binary_crossentropy: 0.0608 - val_dice_coef: 0.9806 - val_jacard_coef: 0.9621 - val_binary_accuracy: 0.9894\n",
            "Epoch 103/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0507 - binary_crossentropy: 0.0183 - dice_coef: 0.9893 - jacard_coef: 0.9789 - binary_accuracy: 0.9952\n",
            "Epoch 00103: val_dice_coef did not improve from 0.98105\n",
            "62/61 [==============================] - 53s 852ms/step - loss: 0.0507 - binary_crossentropy: 0.0183 - dice_coef: 0.9893 - jacard_coef: 0.9789 - binary_accuracy: 0.9952 - val_loss: 0.0568 - val_binary_crossentropy: 0.0574 - val_dice_coef: 0.9804 - val_jacard_coef: 0.9616 - val_binary_accuracy: 0.9892\n",
            "Epoch 104/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0504 - binary_crossentropy: 0.0166 - dice_coef: 0.9892 - jacard_coef: 0.9787 - binary_accuracy: 0.9952\n",
            "Epoch 00104: val_dice_coef did not improve from 0.98105\n",
            "62/61 [==============================] - 53s 851ms/step - loss: 0.0504 - binary_crossentropy: 0.0166 - dice_coef: 0.9892 - jacard_coef: 0.9787 - binary_accuracy: 0.9952 - val_loss: 0.0570 - val_binary_crossentropy: 0.0598 - val_dice_coef: 0.9806 - val_jacard_coef: 0.9619 - val_binary_accuracy: 0.9894\n",
            "Epoch 105/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0516 - binary_crossentropy: 0.0240 - dice_coef: 0.9881 - jacard_coef: 0.9767 - binary_accuracy: 0.9946\n",
            "Epoch 00105: val_dice_coef did not improve from 0.98105\n",
            "62/61 [==============================] - 53s 852ms/step - loss: 0.0516 - binary_crossentropy: 0.0240 - dice_coef: 0.9881 - jacard_coef: 0.9767 - binary_accuracy: 0.9946 - val_loss: 0.0573 - val_binary_crossentropy: 0.0619 - val_dice_coef: 0.9800 - val_jacard_coef: 0.9609 - val_binary_accuracy: 0.9891\n",
            "Epoch 106/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0524 - binary_crossentropy: 0.0294 - dice_coef: 0.9874 - jacard_coef: 0.9754 - binary_accuracy: 0.9942\n",
            "Epoch 00106: val_dice_coef did not improve from 0.98105\n",
            "62/61 [==============================] - 53s 850ms/step - loss: 0.0524 - binary_crossentropy: 0.0294 - dice_coef: 0.9874 - jacard_coef: 0.9754 - binary_accuracy: 0.9942 - val_loss: 0.0575 - val_binary_crossentropy: 0.0623 - val_dice_coef: 0.9798 - val_jacard_coef: 0.9605 - val_binary_accuracy: 0.9889\n",
            "Epoch 107/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0529 - binary_crossentropy: 0.0330 - dice_coef: 0.9869 - jacard_coef: 0.9746 - binary_accuracy: 0.9937\n",
            "Epoch 00107: val_dice_coef did not improve from 0.98105\n",
            "62/61 [==============================] - 53s 850ms/step - loss: 0.0529 - binary_crossentropy: 0.0330 - dice_coef: 0.9869 - jacard_coef: 0.9746 - binary_accuracy: 0.9937 - val_loss: 0.0570 - val_binary_crossentropy: 0.0602 - val_dice_coef: 0.9802 - val_jacard_coef: 0.9612 - val_binary_accuracy: 0.9892\n",
            "Epoch 108/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0511 - binary_crossentropy: 0.0213 - dice_coef: 0.9883 - jacard_coef: 0.9769 - binary_accuracy: 0.9947\n",
            "Epoch 00108: val_dice_coef did not improve from 0.98105\n",
            "62/61 [==============================] - 53s 853ms/step - loss: 0.0511 - binary_crossentropy: 0.0213 - dice_coef: 0.9883 - jacard_coef: 0.9769 - binary_accuracy: 0.9947 - val_loss: 0.0569 - val_binary_crossentropy: 0.0601 - val_dice_coef: 0.9804 - val_jacard_coef: 0.9617 - val_binary_accuracy: 0.9893\n",
            "Epoch 109/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0503 - binary_crossentropy: 0.0147 - dice_coef: 0.9892 - jacard_coef: 0.9786 - binary_accuracy: 0.9952\n",
            "Epoch 00109: val_dice_coef did not improve from 0.98105\n",
            "62/61 [==============================] - 53s 850ms/step - loss: 0.0503 - binary_crossentropy: 0.0147 - dice_coef: 0.9892 - jacard_coef: 0.9786 - binary_accuracy: 0.9952 - val_loss: 0.0572 - val_binary_crossentropy: 0.0614 - val_dice_coef: 0.9797 - val_jacard_coef: 0.9603 - val_binary_accuracy: 0.9889\n",
            "Epoch 110/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0509 - binary_crossentropy: 0.0185 - dice_coef: 0.9886 - jacard_coef: 0.9775 - binary_accuracy: 0.9948\n",
            "Epoch 00110: val_dice_coef did not improve from 0.98105\n",
            "62/61 [==============================] - 53s 851ms/step - loss: 0.0509 - binary_crossentropy: 0.0185 - dice_coef: 0.9886 - jacard_coef: 0.9775 - binary_accuracy: 0.9948 - val_loss: 0.0573 - val_binary_crossentropy: 0.0632 - val_dice_coef: 0.9800 - val_jacard_coef: 0.9608 - val_binary_accuracy: 0.9890\n",
            "Epoch 111/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0524 - binary_crossentropy: 0.0306 - dice_coef: 0.9871 - jacard_coef: 0.9749 - binary_accuracy: 0.9940\n",
            "Epoch 00111: val_dice_coef did not improve from 0.98105\n",
            "62/61 [==============================] - 53s 854ms/step - loss: 0.0524 - binary_crossentropy: 0.0306 - dice_coef: 0.9871 - jacard_coef: 0.9749 - binary_accuracy: 0.9940 - val_loss: 0.0569 - val_binary_crossentropy: 0.0582 - val_dice_coef: 0.9804 - val_jacard_coef: 0.9616 - val_binary_accuracy: 0.9893\n",
            "Epoch 112/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0529 - binary_crossentropy: 0.0327 - dice_coef: 0.9870 - jacard_coef: 0.9747 - binary_accuracy: 0.9938\n",
            "Epoch 00112: val_dice_coef did not improve from 0.98105\n",
            "62/61 [==============================] - 53s 853ms/step - loss: 0.0529 - binary_crossentropy: 0.0327 - dice_coef: 0.9870 - jacard_coef: 0.9747 - binary_accuracy: 0.9938 - val_loss: 0.0576 - val_binary_crossentropy: 0.0641 - val_dice_coef: 0.9798 - val_jacard_coef: 0.9605 - val_binary_accuracy: 0.9890\n",
            "Epoch 113/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0510 - binary_crossentropy: 0.0208 - dice_coef: 0.9888 - jacard_coef: 0.9780 - binary_accuracy: 0.9949\n",
            "Epoch 00113: val_dice_coef did not improve from 0.98105\n",
            "62/61 [==============================] - 53s 852ms/step - loss: 0.0510 - binary_crossentropy: 0.0208 - dice_coef: 0.9888 - jacard_coef: 0.9780 - binary_accuracy: 0.9949 - val_loss: 0.0581 - val_binary_crossentropy: 0.0681 - val_dice_coef: 0.9788 - val_jacard_coef: 0.9587 - val_binary_accuracy: 0.9884\n",
            "Epoch 114/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0518 - binary_crossentropy: 0.0261 - dice_coef: 0.9881 - jacard_coef: 0.9768 - binary_accuracy: 0.9945\n",
            "Epoch 00114: val_dice_coef did not improve from 0.98105\n",
            "62/61 [==============================] - 53s 854ms/step - loss: 0.0518 - binary_crossentropy: 0.0261 - dice_coef: 0.9881 - jacard_coef: 0.9768 - binary_accuracy: 0.9945 - val_loss: 0.0570 - val_binary_crossentropy: 0.0595 - val_dice_coef: 0.9802 - val_jacard_coef: 0.9612 - val_binary_accuracy: 0.9891\n",
            "Epoch 115/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0509 - binary_crossentropy: 0.0198 - dice_coef: 0.9891 - jacard_coef: 0.9785 - binary_accuracy: 0.9951\n",
            "Epoch 00115: val_dice_coef did not improve from 0.98105\n",
            "62/61 [==============================] - 53s 853ms/step - loss: 0.0509 - binary_crossentropy: 0.0198 - dice_coef: 0.9891 - jacard_coef: 0.9785 - binary_accuracy: 0.9951 - val_loss: 0.0568 - val_binary_crossentropy: 0.0583 - val_dice_coef: 0.9806 - val_jacard_coef: 0.9619 - val_binary_accuracy: 0.9895\n",
            "Epoch 116/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0504 - binary_crossentropy: 0.0167 - dice_coef: 0.9897 - jacard_coef: 0.9797 - binary_accuracy: 0.9954\n",
            "Epoch 00116: val_dice_coef did not improve from 0.98105\n",
            "62/61 [==============================] - 53s 852ms/step - loss: 0.0504 - binary_crossentropy: 0.0167 - dice_coef: 0.9897 - jacard_coef: 0.9797 - binary_accuracy: 0.9954 - val_loss: 0.0570 - val_binary_crossentropy: 0.0609 - val_dice_coef: 0.9810 - val_jacard_coef: 0.9627 - val_binary_accuracy: 0.9895\n",
            "Epoch 117/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0510 - binary_crossentropy: 0.0215 - dice_coef: 0.9889 - jacard_coef: 0.9782 - binary_accuracy: 0.9949\n",
            "Epoch 00117: val_dice_coef did not improve from 0.98105\n",
            "62/61 [==============================] - 53s 852ms/step - loss: 0.0510 - binary_crossentropy: 0.0215 - dice_coef: 0.9889 - jacard_coef: 0.9782 - binary_accuracy: 0.9949 - val_loss: 0.0565 - val_binary_crossentropy: 0.0560 - val_dice_coef: 0.9807 - val_jacard_coef: 0.9622 - val_binary_accuracy: 0.9894\n",
            "Epoch 118/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0497 - binary_crossentropy: 0.0138 - dice_coef: 0.9905 - jacard_coef: 0.9812 - binary_accuracy: 0.9958\n",
            "Epoch 00118: val_dice_coef did not improve from 0.98105\n",
            "62/61 [==============================] - 53s 854ms/step - loss: 0.0497 - binary_crossentropy: 0.0138 - dice_coef: 0.9905 - jacard_coef: 0.9812 - binary_accuracy: 0.9958 - val_loss: 0.0565 - val_binary_crossentropy: 0.0566 - val_dice_coef: 0.9810 - val_jacard_coef: 0.9628 - val_binary_accuracy: 0.9896\n",
            "Epoch 119/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0529 - binary_crossentropy: 0.0358 - dice_coef: 0.9880 - jacard_coef: 0.9770 - binary_accuracy: 0.9942\n",
            "Epoch 00119: val_dice_coef did not improve from 0.98105\n",
            "62/61 [==============================] - 53s 855ms/step - loss: 0.0529 - binary_crossentropy: 0.0358 - dice_coef: 0.9880 - jacard_coef: 0.9770 - binary_accuracy: 0.9942 - val_loss: 0.0569 - val_binary_crossentropy: 0.0585 - val_dice_coef: 0.9805 - val_jacard_coef: 0.9618 - val_binary_accuracy: 0.9893\n",
            "Epoch 120/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0503 - binary_crossentropy: 0.0176 - dice_coef: 0.9900 - jacard_coef: 0.9803 - binary_accuracy: 0.9955\n",
            "Epoch 00120: val_dice_coef improved from 0.98105 to 0.98108, saving model to net_lung_seg.hdf5\n",
            "62/61 [==============================] - 55s 883ms/step - loss: 0.0503 - binary_crossentropy: 0.0176 - dice_coef: 0.9900 - jacard_coef: 0.9803 - binary_accuracy: 0.9955 - val_loss: 0.0569 - val_binary_crossentropy: 0.0599 - val_dice_coef: 0.9811 - val_jacard_coef: 0.9629 - val_binary_accuracy: 0.9896\n",
            "Epoch 121/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0509 - binary_crossentropy: 0.0209 - dice_coef: 0.9895 - jacard_coef: 0.9793 - binary_accuracy: 0.9951\n",
            "Epoch 00121: val_dice_coef did not improve from 0.98108\n",
            "62/61 [==============================] - 53s 853ms/step - loss: 0.0509 - binary_crossentropy: 0.0209 - dice_coef: 0.9895 - jacard_coef: 0.9793 - binary_accuracy: 0.9951 - val_loss: 0.0572 - val_binary_crossentropy: 0.0624 - val_dice_coef: 0.9807 - val_jacard_coef: 0.9622 - val_binary_accuracy: 0.9894\n",
            "Epoch 122/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0504 - binary_crossentropy: 0.0174 - dice_coef: 0.9902 - jacard_coef: 0.9807 - binary_accuracy: 0.9956\n",
            "Epoch 00122: val_dice_coef did not improve from 0.98108\n",
            "62/61 [==============================] - 53s 854ms/step - loss: 0.0504 - binary_crossentropy: 0.0174 - dice_coef: 0.9902 - jacard_coef: 0.9807 - binary_accuracy: 0.9956 - val_loss: 0.0568 - val_binary_crossentropy: 0.0596 - val_dice_coef: 0.9810 - val_jacard_coef: 0.9628 - val_binary_accuracy: 0.9896\n",
            "Epoch 123/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0508 - binary_crossentropy: 0.0208 - dice_coef: 0.9896 - jacard_coef: 0.9795 - binary_accuracy: 0.9952\n",
            "Epoch 00123: val_dice_coef did not improve from 0.98108\n",
            "62/61 [==============================] - 53s 857ms/step - loss: 0.0508 - binary_crossentropy: 0.0208 - dice_coef: 0.9896 - jacard_coef: 0.9795 - binary_accuracy: 0.9952 - val_loss: 0.0568 - val_binary_crossentropy: 0.0605 - val_dice_coef: 0.9807 - val_jacard_coef: 0.9622 - val_binary_accuracy: 0.9894\n",
            "Epoch 124/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0504 - binary_crossentropy: 0.0180 - dice_coef: 0.9900 - jacard_coef: 0.9803 - binary_accuracy: 0.9955\n",
            "Epoch 00124: val_dice_coef did not improve from 0.98108\n",
            "62/61 [==============================] - 53s 852ms/step - loss: 0.0504 - binary_crossentropy: 0.0180 - dice_coef: 0.9900 - jacard_coef: 0.9803 - binary_accuracy: 0.9955 - val_loss: 0.0570 - val_binary_crossentropy: 0.0610 - val_dice_coef: 0.9807 - val_jacard_coef: 0.9622 - val_binary_accuracy: 0.9894\n",
            "Epoch 125/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0501 - binary_crossentropy: 0.0158 - dice_coef: 0.9902 - jacard_coef: 0.9807 - binary_accuracy: 0.9956\n",
            "Epoch 00125: val_dice_coef did not improve from 0.98108\n",
            "62/61 [==============================] - 53s 855ms/step - loss: 0.0501 - binary_crossentropy: 0.0158 - dice_coef: 0.9902 - jacard_coef: 0.9807 - binary_accuracy: 0.9956 - val_loss: 0.0572 - val_binary_crossentropy: 0.0613 - val_dice_coef: 0.9806 - val_jacard_coef: 0.9619 - val_binary_accuracy: 0.9893\n",
            "Epoch 126/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0511 - binary_crossentropy: 0.0218 - dice_coef: 0.9893 - jacard_coef: 0.9790 - binary_accuracy: 0.9951\n",
            "Epoch 00126: val_dice_coef improved from 0.98108 to 0.98116, saving model to net_lung_seg.hdf5\n",
            "62/61 [==============================] - 55s 885ms/step - loss: 0.0511 - binary_crossentropy: 0.0218 - dice_coef: 0.9893 - jacard_coef: 0.9790 - binary_accuracy: 0.9951 - val_loss: 0.0567 - val_binary_crossentropy: 0.0585 - val_dice_coef: 0.9812 - val_jacard_coef: 0.9631 - val_binary_accuracy: 0.9896\n",
            "Epoch 127/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0534 - binary_crossentropy: 0.0384 - dice_coef: 0.9869 - jacard_coef: 0.9752 - binary_accuracy: 0.9938\n",
            "Epoch 00127: val_dice_coef did not improve from 0.98116\n",
            "62/61 [==============================] - 53s 853ms/step - loss: 0.0534 - binary_crossentropy: 0.0384 - dice_coef: 0.9869 - jacard_coef: 0.9752 - binary_accuracy: 0.9938 - val_loss: 0.0575 - val_binary_crossentropy: 0.0641 - val_dice_coef: 0.9802 - val_jacard_coef: 0.9612 - val_binary_accuracy: 0.9891\n",
            "Epoch 128/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0519 - binary_crossentropy: 0.0276 - dice_coef: 0.9884 - jacard_coef: 0.9775 - binary_accuracy: 0.9946\n",
            "Epoch 00128: val_dice_coef did not improve from 0.98116\n",
            "62/61 [==============================] - 53s 854ms/step - loss: 0.0519 - binary_crossentropy: 0.0276 - dice_coef: 0.9884 - jacard_coef: 0.9775 - binary_accuracy: 0.9946 - val_loss: 0.0572 - val_binary_crossentropy: 0.0603 - val_dice_coef: 0.9798 - val_jacard_coef: 0.9606 - val_binary_accuracy: 0.9889\n",
            "Epoch 129/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0514 - binary_crossentropy: 0.0232 - dice_coef: 0.9885 - jacard_coef: 0.9775 - binary_accuracy: 0.9947\n",
            "Epoch 00129: val_dice_coef did not improve from 0.98116\n",
            "62/61 [==============================] - 53s 854ms/step - loss: 0.0514 - binary_crossentropy: 0.0232 - dice_coef: 0.9885 - jacard_coef: 0.9775 - binary_accuracy: 0.9947 - val_loss: 0.0574 - val_binary_crossentropy: 0.0651 - val_dice_coef: 0.9803 - val_jacard_coef: 0.9615 - val_binary_accuracy: 0.9892\n",
            "Epoch 130/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0507 - binary_crossentropy: 0.0184 - dice_coef: 0.9892 - jacard_coef: 0.9787 - binary_accuracy: 0.9950\n",
            "Epoch 00130: val_dice_coef did not improve from 0.98116\n",
            "62/61 [==============================] - 53s 854ms/step - loss: 0.0507 - binary_crossentropy: 0.0184 - dice_coef: 0.9892 - jacard_coef: 0.9787 - binary_accuracy: 0.9950 - val_loss: 0.0574 - val_binary_crossentropy: 0.0623 - val_dice_coef: 0.9801 - val_jacard_coef: 0.9609 - val_binary_accuracy: 0.9891\n",
            "Epoch 131/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0504 - binary_crossentropy: 0.0164 - dice_coef: 0.9896 - jacard_coef: 0.9795 - binary_accuracy: 0.9953\n",
            "Epoch 00131: val_dice_coef did not improve from 0.98116\n",
            "62/61 [==============================] - 53s 853ms/step - loss: 0.0504 - binary_crossentropy: 0.0164 - dice_coef: 0.9896 - jacard_coef: 0.9795 - binary_accuracy: 0.9953 - val_loss: 0.0576 - val_binary_crossentropy: 0.0643 - val_dice_coef: 0.9799 - val_jacard_coef: 0.9606 - val_binary_accuracy: 0.9889\n",
            "Epoch 132/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0517 - binary_crossentropy: 0.0253 - dice_coef: 0.9884 - jacard_coef: 0.9774 - binary_accuracy: 0.9947\n",
            "Epoch 00132: val_dice_coef did not improve from 0.98116\n",
            "62/61 [==============================] - 53s 854ms/step - loss: 0.0517 - binary_crossentropy: 0.0253 - dice_coef: 0.9884 - jacard_coef: 0.9774 - binary_accuracy: 0.9947 - val_loss: 0.0578 - val_binary_crossentropy: 0.0636 - val_dice_coef: 0.9794 - val_jacard_coef: 0.9598 - val_binary_accuracy: 0.9888\n",
            "Epoch 133/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0498 - binary_crossentropy: 0.0134 - dice_coef: 0.9905 - jacard_coef: 0.9811 - binary_accuracy: 0.9957\n",
            "Epoch 00133: val_dice_coef did not improve from 0.98116\n",
            "62/61 [==============================] - 53s 852ms/step - loss: 0.0498 - binary_crossentropy: 0.0134 - dice_coef: 0.9905 - jacard_coef: 0.9811 - binary_accuracy: 0.9957 - val_loss: 0.0585 - val_binary_crossentropy: 0.0706 - val_dice_coef: 0.9797 - val_jacard_coef: 0.9602 - val_binary_accuracy: 0.9888\n",
            "Epoch 134/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0512 - binary_crossentropy: 0.0236 - dice_coef: 0.9893 - jacard_coef: 0.9790 - binary_accuracy: 0.9949\n",
            "Epoch 00134: val_dice_coef did not improve from 0.98116\n",
            "62/61 [==============================] - 53s 856ms/step - loss: 0.0512 - binary_crossentropy: 0.0236 - dice_coef: 0.9893 - jacard_coef: 0.9790 - binary_accuracy: 0.9949 - val_loss: 0.0574 - val_binary_crossentropy: 0.0628 - val_dice_coef: 0.9801 - val_jacard_coef: 0.9611 - val_binary_accuracy: 0.9892\n",
            "Epoch 135/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0522 - binary_crossentropy: 0.0302 - dice_coef: 0.9884 - jacard_coef: 0.9777 - binary_accuracy: 0.9944\n",
            "Epoch 00135: val_dice_coef did not improve from 0.98116\n",
            "62/61 [==============================] - 53s 851ms/step - loss: 0.0522 - binary_crossentropy: 0.0302 - dice_coef: 0.9884 - jacard_coef: 0.9777 - binary_accuracy: 0.9944 - val_loss: 0.0570 - val_binary_crossentropy: 0.0594 - val_dice_coef: 0.9801 - val_jacard_coef: 0.9610 - val_binary_accuracy: 0.9891\n",
            "Epoch 136/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0500 - binary_crossentropy: 0.0152 - dice_coef: 0.9905 - jacard_coef: 0.9812 - binary_accuracy: 0.9957\n",
            "Epoch 00136: val_dice_coef did not improve from 0.98116\n",
            "62/61 [==============================] - 53s 853ms/step - loss: 0.0500 - binary_crossentropy: 0.0152 - dice_coef: 0.9905 - jacard_coef: 0.9812 - binary_accuracy: 0.9957 - val_loss: 0.0564 - val_binary_crossentropy: 0.0563 - val_dice_coef: 0.9810 - val_jacard_coef: 0.9627 - val_binary_accuracy: 0.9896\n",
            "Epoch 137/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0508 - binary_crossentropy: 0.0210 - dice_coef: 0.9900 - jacard_coef: 0.9803 - binary_accuracy: 0.9954\n",
            "Epoch 00137: val_dice_coef did not improve from 0.98116\n",
            "62/61 [==============================] - 53s 855ms/step - loss: 0.0508 - binary_crossentropy: 0.0210 - dice_coef: 0.9900 - jacard_coef: 0.9803 - binary_accuracy: 0.9954 - val_loss: 0.0572 - val_binary_crossentropy: 0.0612 - val_dice_coef: 0.9798 - val_jacard_coef: 0.9605 - val_binary_accuracy: 0.9889\n",
            "Epoch 138/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0499 - binary_crossentropy: 0.0153 - dice_coef: 0.9907 - jacard_coef: 0.9816 - binary_accuracy: 0.9958\n",
            "Epoch 00138: val_dice_coef did not improve from 0.98116\n",
            "62/61 [==============================] - 53s 854ms/step - loss: 0.0499 - binary_crossentropy: 0.0153 - dice_coef: 0.9907 - jacard_coef: 0.9816 - binary_accuracy: 0.9958 - val_loss: 0.0571 - val_binary_crossentropy: 0.0621 - val_dice_coef: 0.9807 - val_jacard_coef: 0.9623 - val_binary_accuracy: 0.9895\n",
            "Epoch 139/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0514 - binary_crossentropy: 0.0253 - dice_coef: 0.9893 - jacard_coef: 0.9792 - binary_accuracy: 0.9951\n",
            "Epoch 00139: val_dice_coef did not improve from 0.98116\n",
            "62/61 [==============================] - 53s 854ms/step - loss: 0.0514 - binary_crossentropy: 0.0253 - dice_coef: 0.9893 - jacard_coef: 0.9792 - binary_accuracy: 0.9951 - val_loss: 0.0569 - val_binary_crossentropy: 0.0593 - val_dice_coef: 0.9809 - val_jacard_coef: 0.9625 - val_binary_accuracy: 0.9895\n",
            "Epoch 140/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0496 - binary_crossentropy: 0.0136 - dice_coef: 0.9913 - jacard_coef: 0.9827 - binary_accuracy: 0.9961\n",
            "Epoch 00140: val_dice_coef did not improve from 0.98116\n",
            "62/61 [==============================] - 53s 854ms/step - loss: 0.0496 - binary_crossentropy: 0.0136 - dice_coef: 0.9913 - jacard_coef: 0.9827 - binary_accuracy: 0.9961 - val_loss: 0.0573 - val_binary_crossentropy: 0.0623 - val_dice_coef: 0.9807 - val_jacard_coef: 0.9623 - val_binary_accuracy: 0.9894\n",
            "Epoch 141/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0515 - binary_crossentropy: 0.0263 - dice_coef: 0.9892 - jacard_coef: 0.9792 - binary_accuracy: 0.9949\n",
            "Epoch 00141: val_dice_coef did not improve from 0.98116\n",
            "62/61 [==============================] - 53s 855ms/step - loss: 0.0515 - binary_crossentropy: 0.0263 - dice_coef: 0.9892 - jacard_coef: 0.9792 - binary_accuracy: 0.9949 - val_loss: 0.0570 - val_binary_crossentropy: 0.0613 - val_dice_coef: 0.9808 - val_jacard_coef: 0.9625 - val_binary_accuracy: 0.9895\n",
            "Epoch 142/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0499 - binary_crossentropy: 0.0159 - dice_coef: 0.9910 - jacard_coef: 0.9821 - binary_accuracy: 0.9958\n",
            "Epoch 00142: val_dice_coef did not improve from 0.98116\n",
            "62/61 [==============================] - 53s 853ms/step - loss: 0.0499 - binary_crossentropy: 0.0159 - dice_coef: 0.9910 - jacard_coef: 0.9821 - binary_accuracy: 0.9958 - val_loss: 0.0570 - val_binary_crossentropy: 0.0604 - val_dice_coef: 0.9806 - val_jacard_coef: 0.9621 - val_binary_accuracy: 0.9893\n",
            "Epoch 143/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0497 - binary_crossentropy: 0.0144 - dice_coef: 0.9911 - jacard_coef: 0.9824 - binary_accuracy: 0.9960\n",
            "Epoch 00143: val_dice_coef did not improve from 0.98116\n",
            "62/61 [==============================] - 53s 855ms/step - loss: 0.0497 - binary_crossentropy: 0.0144 - dice_coef: 0.9911 - jacard_coef: 0.9824 - binary_accuracy: 0.9960 - val_loss: 0.0571 - val_binary_crossentropy: 0.0622 - val_dice_coef: 0.9807 - val_jacard_coef: 0.9622 - val_binary_accuracy: 0.9894\n",
            "Epoch 144/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0509 - binary_crossentropy: 0.0222 - dice_coef: 0.9900 - jacard_coef: 0.9804 - binary_accuracy: 0.9953\n",
            "Epoch 00144: val_dice_coef did not improve from 0.98116\n",
            "62/61 [==============================] - 53s 854ms/step - loss: 0.0509 - binary_crossentropy: 0.0222 - dice_coef: 0.9900 - jacard_coef: 0.9804 - binary_accuracy: 0.9953 - val_loss: 0.0572 - val_binary_crossentropy: 0.0614 - val_dice_coef: 0.9806 - val_jacard_coef: 0.9620 - val_binary_accuracy: 0.9893\n",
            "Epoch 145/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0509 - binary_crossentropy: 0.0212 - dice_coef: 0.9899 - jacard_coef: 0.9801 - binary_accuracy: 0.9952\n",
            "Epoch 00145: val_dice_coef did not improve from 0.98116\n",
            "62/61 [==============================] - 53s 853ms/step - loss: 0.0509 - binary_crossentropy: 0.0212 - dice_coef: 0.9899 - jacard_coef: 0.9801 - binary_accuracy: 0.9952 - val_loss: 0.0580 - val_binary_crossentropy: 0.0696 - val_dice_coef: 0.9799 - val_jacard_coef: 0.9607 - val_binary_accuracy: 0.9890\n",
            "Epoch 146/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0498 - binary_crossentropy: 0.0141 - dice_coef: 0.9908 - jacard_coef: 0.9817 - binary_accuracy: 0.9958\n",
            "Epoch 00146: val_dice_coef did not improve from 0.98116\n",
            "62/61 [==============================] - 53s 855ms/step - loss: 0.0498 - binary_crossentropy: 0.0141 - dice_coef: 0.9908 - jacard_coef: 0.9817 - binary_accuracy: 0.9958 - val_loss: 0.0583 - val_binary_crossentropy: 0.0715 - val_dice_coef: 0.9795 - val_jacard_coef: 0.9598 - val_binary_accuracy: 0.9887\n",
            "Epoch 147/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0505 - binary_crossentropy: 0.0192 - dice_coef: 0.9900 - jacard_coef: 0.9803 - binary_accuracy: 0.9953\n",
            "Epoch 00147: val_dice_coef did not improve from 0.98116\n",
            "62/61 [==============================] - 53s 856ms/step - loss: 0.0505 - binary_crossentropy: 0.0192 - dice_coef: 0.9900 - jacard_coef: 0.9803 - binary_accuracy: 0.9953 - val_loss: 0.0579 - val_binary_crossentropy: 0.0660 - val_dice_coef: 0.9801 - val_jacard_coef: 0.9610 - val_binary_accuracy: 0.9890\n",
            "Epoch 148/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0502 - binary_crossentropy: 0.0154 - dice_coef: 0.9904 - jacard_coef: 0.9810 - binary_accuracy: 0.9955\n",
            "Epoch 00148: val_dice_coef did not improve from 0.98116\n",
            "62/61 [==============================] - 53s 856ms/step - loss: 0.0502 - binary_crossentropy: 0.0154 - dice_coef: 0.9904 - jacard_coef: 0.9810 - binary_accuracy: 0.9955 - val_loss: 0.0574 - val_binary_crossentropy: 0.0632 - val_dice_coef: 0.9805 - val_jacard_coef: 0.9618 - val_binary_accuracy: 0.9893\n",
            "Epoch 149/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0500 - binary_crossentropy: 0.0147 - dice_coef: 0.9905 - jacard_coef: 0.9811 - binary_accuracy: 0.9956\n",
            "Epoch 00149: val_dice_coef did not improve from 0.98116\n",
            "62/61 [==============================] - 53s 854ms/step - loss: 0.0500 - binary_crossentropy: 0.0147 - dice_coef: 0.9905 - jacard_coef: 0.9811 - binary_accuracy: 0.9956 - val_loss: 0.0580 - val_binary_crossentropy: 0.0676 - val_dice_coef: 0.9801 - val_jacard_coef: 0.9610 - val_binary_accuracy: 0.9890\n",
            "Epoch 150/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0501 - binary_crossentropy: 0.0156 - dice_coef: 0.9905 - jacard_coef: 0.9812 - binary_accuracy: 0.9956\n",
            "Epoch 00150: val_dice_coef did not improve from 0.98116\n",
            "62/61 [==============================] - 53s 856ms/step - loss: 0.0501 - binary_crossentropy: 0.0156 - dice_coef: 0.9905 - jacard_coef: 0.9812 - binary_accuracy: 0.9956 - val_loss: 0.0576 - val_binary_crossentropy: 0.0651 - val_dice_coef: 0.9804 - val_jacard_coef: 0.9616 - val_binary_accuracy: 0.9893\n",
            "Epoch 151/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0499 - binary_crossentropy: 0.0140 - dice_coef: 0.9907 - jacard_coef: 0.9815 - binary_accuracy: 0.9957\n",
            "Epoch 00151: val_dice_coef did not improve from 0.98116\n",
            "62/61 [==============================] - 53s 855ms/step - loss: 0.0499 - binary_crossentropy: 0.0140 - dice_coef: 0.9907 - jacard_coef: 0.9815 - binary_accuracy: 0.9957 - val_loss: 0.0578 - val_binary_crossentropy: 0.0651 - val_dice_coef: 0.9800 - val_jacard_coef: 0.9608 - val_binary_accuracy: 0.9890\n",
            "Epoch 152/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0503 - binary_crossentropy: 0.0178 - dice_coef: 0.9902 - jacard_coef: 0.9807 - binary_accuracy: 0.9955\n",
            "Epoch 00152: val_dice_coef improved from 0.98116 to 0.98122, saving model to net_lung_seg.hdf5\n",
            "62/61 [==============================] - 55s 886ms/step - loss: 0.0503 - binary_crossentropy: 0.0178 - dice_coef: 0.9902 - jacard_coef: 0.9807 - binary_accuracy: 0.9955 - val_loss: 0.0559 - val_binary_crossentropy: 0.0529 - val_dice_coef: 0.9812 - val_jacard_coef: 0.9632 - val_binary_accuracy: 0.9897\n",
            "Epoch 153/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0499 - binary_crossentropy: 0.0150 - dice_coef: 0.9908 - jacard_coef: 0.9819 - binary_accuracy: 0.9958\n",
            "Epoch 00153: val_dice_coef improved from 0.98122 to 0.98151, saving model to net_lung_seg.hdf5\n",
            "62/61 [==============================] - 55s 884ms/step - loss: 0.0499 - binary_crossentropy: 0.0150 - dice_coef: 0.9908 - jacard_coef: 0.9819 - binary_accuracy: 0.9958 - val_loss: 0.0563 - val_binary_crossentropy: 0.0563 - val_dice_coef: 0.9815 - val_jacard_coef: 0.9637 - val_binary_accuracy: 0.9898\n",
            "Epoch 154/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0499 - binary_crossentropy: 0.0158 - dice_coef: 0.9908 - jacard_coef: 0.9818 - binary_accuracy: 0.9958\n",
            "Epoch 00154: val_dice_coef did not improve from 0.98151\n",
            "62/61 [==============================] - 53s 853ms/step - loss: 0.0499 - binary_crossentropy: 0.0158 - dice_coef: 0.9908 - jacard_coef: 0.9818 - binary_accuracy: 0.9958 - val_loss: 0.0568 - val_binary_crossentropy: 0.0593 - val_dice_coef: 0.9809 - val_jacard_coef: 0.9626 - val_binary_accuracy: 0.9894\n",
            "Epoch 155/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0504 - binary_crossentropy: 0.0186 - dice_coef: 0.9905 - jacard_coef: 0.9812 - binary_accuracy: 0.9955\n",
            "Epoch 00155: val_dice_coef did not improve from 0.98151\n",
            "62/61 [==============================] - 53s 856ms/step - loss: 0.0504 - binary_crossentropy: 0.0186 - dice_coef: 0.9905 - jacard_coef: 0.9812 - binary_accuracy: 0.9955 - val_loss: 0.0571 - val_binary_crossentropy: 0.0612 - val_dice_coef: 0.9807 - val_jacard_coef: 0.9622 - val_binary_accuracy: 0.9894\n",
            "Epoch 156/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0498 - binary_crossentropy: 0.0156 - dice_coef: 0.9911 - jacard_coef: 0.9823 - binary_accuracy: 0.9959\n",
            "Epoch 00156: val_dice_coef did not improve from 0.98151\n",
            "62/61 [==============================] - 53s 858ms/step - loss: 0.0498 - binary_crossentropy: 0.0156 - dice_coef: 0.9911 - jacard_coef: 0.9823 - binary_accuracy: 0.9959 - val_loss: 0.0567 - val_binary_crossentropy: 0.0588 - val_dice_coef: 0.9810 - val_jacard_coef: 0.9629 - val_binary_accuracy: 0.9896\n",
            "Epoch 157/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0506 - binary_crossentropy: 0.0206 - dice_coef: 0.9905 - jacard_coef: 0.9814 - binary_accuracy: 0.9955\n",
            "Epoch 00157: val_dice_coef did not improve from 0.98151\n",
            "62/61 [==============================] - 53s 855ms/step - loss: 0.0506 - binary_crossentropy: 0.0206 - dice_coef: 0.9905 - jacard_coef: 0.9814 - binary_accuracy: 0.9955 - val_loss: 0.0566 - val_binary_crossentropy: 0.0588 - val_dice_coef: 0.9813 - val_jacard_coef: 0.9633 - val_binary_accuracy: 0.9897\n",
            "Epoch 158/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0505 - binary_crossentropy: 0.0204 - dice_coef: 0.9905 - jacard_coef: 0.9814 - binary_accuracy: 0.9955\n",
            "Epoch 00158: val_dice_coef did not improve from 0.98151\n",
            "62/61 [==============================] - 53s 855ms/step - loss: 0.0505 - binary_crossentropy: 0.0204 - dice_coef: 0.9905 - jacard_coef: 0.9814 - binary_accuracy: 0.9955 - val_loss: 0.0566 - val_binary_crossentropy: 0.0577 - val_dice_coef: 0.9812 - val_jacard_coef: 0.9632 - val_binary_accuracy: 0.9897\n",
            "Epoch 159/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0502 - binary_crossentropy: 0.0173 - dice_coef: 0.9912 - jacard_coef: 0.9827 - binary_accuracy: 0.9959\n",
            "Epoch 00159: val_dice_coef did not improve from 0.98151\n",
            "62/61 [==============================] - 53s 854ms/step - loss: 0.0502 - binary_crossentropy: 0.0173 - dice_coef: 0.9912 - jacard_coef: 0.9827 - binary_accuracy: 0.9959 - val_loss: 0.0568 - val_binary_crossentropy: 0.0588 - val_dice_coef: 0.9811 - val_jacard_coef: 0.9630 - val_binary_accuracy: 0.9896\n",
            "Epoch 160/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0501 - binary_crossentropy: 0.0168 - dice_coef: 0.9913 - jacard_coef: 0.9828 - binary_accuracy: 0.9960\n",
            "Epoch 00160: val_dice_coef did not improve from 0.98151\n",
            "62/61 [==============================] - 53s 853ms/step - loss: 0.0501 - binary_crossentropy: 0.0168 - dice_coef: 0.9913 - jacard_coef: 0.9828 - binary_accuracy: 0.9960 - val_loss: 0.0570 - val_binary_crossentropy: 0.0617 - val_dice_coef: 0.9814 - val_jacard_coef: 0.9635 - val_binary_accuracy: 0.9897\n",
            "Epoch 161/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0505 - binary_crossentropy: 0.0207 - dice_coef: 0.9907 - jacard_coef: 0.9818 - binary_accuracy: 0.9957\n",
            "Epoch 00161: val_dice_coef did not improve from 0.98151\n",
            "62/61 [==============================] - 53s 851ms/step - loss: 0.0505 - binary_crossentropy: 0.0207 - dice_coef: 0.9907 - jacard_coef: 0.9818 - binary_accuracy: 0.9957 - val_loss: 0.0569 - val_binary_crossentropy: 0.0616 - val_dice_coef: 0.9814 - val_jacard_coef: 0.9635 - val_binary_accuracy: 0.9898\n",
            "Epoch 162/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0499 - binary_crossentropy: 0.0165 - dice_coef: 0.9913 - jacard_coef: 0.9829 - binary_accuracy: 0.9960\n",
            "Epoch 00162: val_dice_coef did not improve from 0.98151\n",
            "62/61 [==============================] - 53s 853ms/step - loss: 0.0499 - binary_crossentropy: 0.0165 - dice_coef: 0.9913 - jacard_coef: 0.9829 - binary_accuracy: 0.9960 - val_loss: 0.0567 - val_binary_crossentropy: 0.0589 - val_dice_coef: 0.9812 - val_jacard_coef: 0.9632 - val_binary_accuracy: 0.9897\n",
            "Epoch 163/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0509 - binary_crossentropy: 0.0221 - dice_coef: 0.9902 - jacard_coef: 0.9810 - binary_accuracy: 0.9955\n",
            "Epoch 00163: val_dice_coef did not improve from 0.98151\n",
            "62/61 [==============================] - 53s 853ms/step - loss: 0.0509 - binary_crossentropy: 0.0221 - dice_coef: 0.9902 - jacard_coef: 0.9810 - binary_accuracy: 0.9955 - val_loss: 0.0571 - val_binary_crossentropy: 0.0623 - val_dice_coef: 0.9810 - val_jacard_coef: 0.9628 - val_binary_accuracy: 0.9896\n",
            "Epoch 164/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0496 - binary_crossentropy: 0.0143 - dice_coef: 0.9915 - jacard_coef: 0.9831 - binary_accuracy: 0.9961\n",
            "Epoch 00164: val_dice_coef did not improve from 0.98151\n",
            "62/61 [==============================] - 53s 853ms/step - loss: 0.0496 - binary_crossentropy: 0.0143 - dice_coef: 0.9915 - jacard_coef: 0.9831 - binary_accuracy: 0.9961 - val_loss: 0.0577 - val_binary_crossentropy: 0.0658 - val_dice_coef: 0.9807 - val_jacard_coef: 0.9622 - val_binary_accuracy: 0.9894\n",
            "Epoch 165/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0511 - binary_crossentropy: 0.0240 - dice_coef: 0.9898 - jacard_coef: 0.9802 - binary_accuracy: 0.9952\n",
            "Epoch 00165: val_dice_coef did not improve from 0.98151\n",
            "62/61 [==============================] - 53s 853ms/step - loss: 0.0511 - binary_crossentropy: 0.0240 - dice_coef: 0.9898 - jacard_coef: 0.9802 - binary_accuracy: 0.9952 - val_loss: 0.0581 - val_binary_crossentropy: 0.0704 - val_dice_coef: 0.9805 - val_jacard_coef: 0.9619 - val_binary_accuracy: 0.9893\n",
            "Epoch 166/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0500 - binary_crossentropy: 0.0158 - dice_coef: 0.9910 - jacard_coef: 0.9822 - binary_accuracy: 0.9958\n",
            "Epoch 00166: val_dice_coef did not improve from 0.98151\n",
            "62/61 [==============================] - 53s 853ms/step - loss: 0.0500 - binary_crossentropy: 0.0158 - dice_coef: 0.9910 - jacard_coef: 0.9822 - binary_accuracy: 0.9958 - val_loss: 0.0584 - val_binary_crossentropy: 0.0723 - val_dice_coef: 0.9799 - val_jacard_coef: 0.9607 - val_binary_accuracy: 0.9890\n",
            "Epoch 167/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0503 - binary_crossentropy: 0.0180 - dice_coef: 0.9906 - jacard_coef: 0.9816 - binary_accuracy: 0.9957\n",
            "Epoch 00167: val_dice_coef did not improve from 0.98151\n",
            "62/61 [==============================] - 53s 852ms/step - loss: 0.0503 - binary_crossentropy: 0.0180 - dice_coef: 0.9906 - jacard_coef: 0.9816 - binary_accuracy: 0.9957 - val_loss: 0.0595 - val_binary_crossentropy: 0.0774 - val_dice_coef: 0.9779 - val_jacard_coef: 0.9568 - val_binary_accuracy: 0.9878\n",
            "Epoch 168/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0501 - binary_crossentropy: 0.0156 - dice_coef: 0.9908 - jacard_coef: 0.9818 - binary_accuracy: 0.9958\n",
            "Epoch 00168: val_dice_coef did not improve from 0.98151\n",
            "62/61 [==============================] - 53s 854ms/step - loss: 0.0501 - binary_crossentropy: 0.0156 - dice_coef: 0.9908 - jacard_coef: 0.9818 - binary_accuracy: 0.9958 - val_loss: 0.0582 - val_binary_crossentropy: 0.0699 - val_dice_coef: 0.9801 - val_jacard_coef: 0.9611 - val_binary_accuracy: 0.9891\n",
            "Epoch 169/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0510 - binary_crossentropy: 0.0230 - dice_coef: 0.9896 - jacard_coef: 0.9797 - binary_accuracy: 0.9951\n",
            "Epoch 00169: val_dice_coef did not improve from 0.98151\n",
            "62/61 [==============================] - 53s 856ms/step - loss: 0.0510 - binary_crossentropy: 0.0230 - dice_coef: 0.9896 - jacard_coef: 0.9797 - binary_accuracy: 0.9951 - val_loss: 0.0581 - val_binary_crossentropy: 0.0680 - val_dice_coef: 0.9799 - val_jacard_coef: 0.9607 - val_binary_accuracy: 0.9890\n",
            "Epoch 170/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0510 - binary_crossentropy: 0.0225 - dice_coef: 0.9896 - jacard_coef: 0.9797 - binary_accuracy: 0.9951\n",
            "Epoch 00170: val_dice_coef did not improve from 0.98151\n",
            "62/61 [==============================] - 53s 857ms/step - loss: 0.0510 - binary_crossentropy: 0.0225 - dice_coef: 0.9896 - jacard_coef: 0.9797 - binary_accuracy: 0.9951 - val_loss: 0.0579 - val_binary_crossentropy: 0.0683 - val_dice_coef: 0.9801 - val_jacard_coef: 0.9611 - val_binary_accuracy: 0.9891\n",
            "Epoch 171/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0504 - binary_crossentropy: 0.0180 - dice_coef: 0.9904 - jacard_coef: 0.9811 - binary_accuracy: 0.9955\n",
            "Epoch 00171: val_dice_coef did not improve from 0.98151\n",
            "62/61 [==============================] - 53s 857ms/step - loss: 0.0504 - binary_crossentropy: 0.0180 - dice_coef: 0.9904 - jacard_coef: 0.9811 - binary_accuracy: 0.9955 - val_loss: 0.0572 - val_binary_crossentropy: 0.0617 - val_dice_coef: 0.9804 - val_jacard_coef: 0.9617 - val_binary_accuracy: 0.9894\n",
            "Epoch 172/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0499 - binary_crossentropy: 0.0154 - dice_coef: 0.9909 - jacard_coef: 0.9820 - binary_accuracy: 0.9958\n",
            "Epoch 00172: val_dice_coef did not improve from 0.98151\n",
            "62/61 [==============================] - 53s 857ms/step - loss: 0.0499 - binary_crossentropy: 0.0154 - dice_coef: 0.9909 - jacard_coef: 0.9820 - binary_accuracy: 0.9958 - val_loss: 0.0566 - val_binary_crossentropy: 0.0581 - val_dice_coef: 0.9813 - val_jacard_coef: 0.9633 - val_binary_accuracy: 0.9897\n",
            "Epoch 173/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0517 - binary_crossentropy: 0.0287 - dice_coef: 0.9895 - jacard_coef: 0.9797 - binary_accuracy: 0.9949\n",
            "Epoch 00173: val_dice_coef did not improve from 0.98151\n",
            "62/61 [==============================] - 53s 855ms/step - loss: 0.0517 - binary_crossentropy: 0.0287 - dice_coef: 0.9895 - jacard_coef: 0.9797 - binary_accuracy: 0.9949 - val_loss: 0.0571 - val_binary_crossentropy: 0.0607 - val_dice_coef: 0.9806 - val_jacard_coef: 0.9620 - val_binary_accuracy: 0.9894\n",
            "Epoch 174/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0498 - binary_crossentropy: 0.0138 - dice_coef: 0.9914 - jacard_coef: 0.9830 - binary_accuracy: 0.9961\n",
            "Epoch 00174: val_dice_coef did not improve from 0.98151\n",
            "62/61 [==============================] - 53s 855ms/step - loss: 0.0498 - binary_crossentropy: 0.0138 - dice_coef: 0.9914 - jacard_coef: 0.9830 - binary_accuracy: 0.9961 - val_loss: 0.0571 - val_binary_crossentropy: 0.0610 - val_dice_coef: 0.9809 - val_jacard_coef: 0.9625 - val_binary_accuracy: 0.9895\n",
            "Epoch 175/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0517 - binary_crossentropy: 0.0285 - dice_coef: 0.9895 - jacard_coef: 0.9798 - binary_accuracy: 0.9950\n",
            "Epoch 00175: val_dice_coef improved from 0.98151 to 0.98181, saving model to net_lung_seg.hdf5\n",
            "62/61 [==============================] - 55s 883ms/step - loss: 0.0517 - binary_crossentropy: 0.0285 - dice_coef: 0.9895 - jacard_coef: 0.9798 - binary_accuracy: 0.9950 - val_loss: 0.0561 - val_binary_crossentropy: 0.0547 - val_dice_coef: 0.9818 - val_jacard_coef: 0.9643 - val_binary_accuracy: 0.9900\n",
            "Epoch 176/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0505 - binary_crossentropy: 0.0204 - dice_coef: 0.9905 - jacard_coef: 0.9815 - binary_accuracy: 0.9956\n",
            "Epoch 00176: val_dice_coef did not improve from 0.98181\n",
            "62/61 [==============================] - 53s 855ms/step - loss: 0.0505 - binary_crossentropy: 0.0204 - dice_coef: 0.9905 - jacard_coef: 0.9815 - binary_accuracy: 0.9956 - val_loss: 0.0567 - val_binary_crossentropy: 0.0586 - val_dice_coef: 0.9812 - val_jacard_coef: 0.9632 - val_binary_accuracy: 0.9897\n",
            "Epoch 177/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0494 - binary_crossentropy: 0.0127 - dice_coef: 0.9919 - jacard_coef: 0.9840 - binary_accuracy: 0.9963\n",
            "Epoch 00177: val_dice_coef did not improve from 0.98181\n",
            "62/61 [==============================] - 53s 853ms/step - loss: 0.0494 - binary_crossentropy: 0.0127 - dice_coef: 0.9919 - jacard_coef: 0.9840 - binary_accuracy: 0.9963 - val_loss: 0.0566 - val_binary_crossentropy: 0.0589 - val_dice_coef: 0.9814 - val_jacard_coef: 0.9635 - val_binary_accuracy: 0.9898\n",
            "Epoch 178/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0506 - binary_crossentropy: 0.0215 - dice_coef: 0.9906 - jacard_coef: 0.9817 - binary_accuracy: 0.9955\n",
            "Epoch 00178: val_dice_coef did not improve from 0.98181\n",
            "62/61 [==============================] - 53s 855ms/step - loss: 0.0506 - binary_crossentropy: 0.0215 - dice_coef: 0.9906 - jacard_coef: 0.9817 - binary_accuracy: 0.9955 - val_loss: 0.0568 - val_binary_crossentropy: 0.0596 - val_dice_coef: 0.9809 - val_jacard_coef: 0.9626 - val_binary_accuracy: 0.9895\n",
            "Epoch 179/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0499 - binary_crossentropy: 0.0168 - dice_coef: 0.9913 - jacard_coef: 0.9830 - binary_accuracy: 0.9960\n",
            "Epoch 00179: val_dice_coef did not improve from 0.98181\n",
            "62/61 [==============================] - 53s 853ms/step - loss: 0.0499 - binary_crossentropy: 0.0168 - dice_coef: 0.9913 - jacard_coef: 0.9830 - binary_accuracy: 0.9960 - val_loss: 0.0576 - val_binary_crossentropy: 0.0663 - val_dice_coef: 0.9807 - val_jacard_coef: 0.9622 - val_binary_accuracy: 0.9894\n",
            "Epoch 180/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0495 - binary_crossentropy: 0.0136 - dice_coef: 0.9920 - jacard_coef: 0.9841 - binary_accuracy: 0.9963\n",
            "Epoch 00180: val_dice_coef did not improve from 0.98181\n",
            "62/61 [==============================] - 53s 855ms/step - loss: 0.0495 - binary_crossentropy: 0.0136 - dice_coef: 0.9920 - jacard_coef: 0.9841 - binary_accuracy: 0.9963 - val_loss: 0.0578 - val_binary_crossentropy: 0.0679 - val_dice_coef: 0.9807 - val_jacard_coef: 0.9623 - val_binary_accuracy: 0.9894\n",
            "Epoch 181/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0496 - binary_crossentropy: 0.0151 - dice_coef: 0.9915 - jacard_coef: 0.9833 - binary_accuracy: 0.9961\n",
            "Epoch 00181: val_dice_coef did not improve from 0.98181\n",
            "62/61 [==============================] - 53s 853ms/step - loss: 0.0496 - binary_crossentropy: 0.0151 - dice_coef: 0.9915 - jacard_coef: 0.9833 - binary_accuracy: 0.9961 - val_loss: 0.0579 - val_binary_crossentropy: 0.0680 - val_dice_coef: 0.9808 - val_jacard_coef: 0.9623 - val_binary_accuracy: 0.9894\n",
            "Epoch 182/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0516 - binary_crossentropy: 0.0282 - dice_coef: 0.9898 - jacard_coef: 0.9805 - binary_accuracy: 0.9953\n",
            "Epoch 00182: val_dice_coef did not improve from 0.98181\n",
            "62/61 [==============================] - 53s 854ms/step - loss: 0.0516 - binary_crossentropy: 0.0282 - dice_coef: 0.9898 - jacard_coef: 0.9805 - binary_accuracy: 0.9953 - val_loss: 0.0574 - val_binary_crossentropy: 0.0638 - val_dice_coef: 0.9807 - val_jacard_coef: 0.9622 - val_binary_accuracy: 0.9894\n",
            "Epoch 183/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0495 - binary_crossentropy: 0.0138 - dice_coef: 0.9918 - jacard_coef: 0.9837 - binary_accuracy: 0.9962\n",
            "Epoch 00183: val_dice_coef did not improve from 0.98181\n",
            "62/61 [==============================] - 53s 855ms/step - loss: 0.0495 - binary_crossentropy: 0.0138 - dice_coef: 0.9918 - jacard_coef: 0.9837 - binary_accuracy: 0.9962 - val_loss: 0.0574 - val_binary_crossentropy: 0.0643 - val_dice_coef: 0.9807 - val_jacard_coef: 0.9623 - val_binary_accuracy: 0.9894\n",
            "Epoch 184/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0498 - binary_crossentropy: 0.0163 - dice_coef: 0.9913 - jacard_coef: 0.9828 - binary_accuracy: 0.9960\n",
            "Epoch 00184: val_dice_coef did not improve from 0.98181\n",
            "62/61 [==============================] - 53s 852ms/step - loss: 0.0498 - binary_crossentropy: 0.0163 - dice_coef: 0.9913 - jacard_coef: 0.9828 - binary_accuracy: 0.9960 - val_loss: 0.0581 - val_binary_crossentropy: 0.0696 - val_dice_coef: 0.9805 - val_jacard_coef: 0.9619 - val_binary_accuracy: 0.9893\n",
            "Epoch 185/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0504 - binary_crossentropy: 0.0197 - dice_coef: 0.9909 - jacard_coef: 0.9822 - binary_accuracy: 0.9957\n",
            "Epoch 00185: val_dice_coef did not improve from 0.98181\n",
            "62/61 [==============================] - 53s 853ms/step - loss: 0.0504 - binary_crossentropy: 0.0197 - dice_coef: 0.9909 - jacard_coef: 0.9822 - binary_accuracy: 0.9957 - val_loss: 0.0571 - val_binary_crossentropy: 0.0616 - val_dice_coef: 0.9807 - val_jacard_coef: 0.9622 - val_binary_accuracy: 0.9894\n",
            "Epoch 186/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0495 - binary_crossentropy: 0.0129 - dice_coef: 0.9917 - jacard_coef: 0.9836 - binary_accuracy: 0.9963\n",
            "Epoch 00186: val_dice_coef did not improve from 0.98181\n",
            "62/61 [==============================] - 53s 853ms/step - loss: 0.0495 - binary_crossentropy: 0.0129 - dice_coef: 0.9917 - jacard_coef: 0.9836 - binary_accuracy: 0.9963 - val_loss: 0.0579 - val_binary_crossentropy: 0.0695 - val_dice_coef: 0.9805 - val_jacard_coef: 0.9619 - val_binary_accuracy: 0.9893\n",
            "Epoch 187/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0500 - binary_crossentropy: 0.0165 - dice_coef: 0.9911 - jacard_coef: 0.9824 - binary_accuracy: 0.9958\n",
            "Epoch 00187: val_dice_coef did not improve from 0.98181\n",
            "62/61 [==============================] - 53s 852ms/step - loss: 0.0500 - binary_crossentropy: 0.0165 - dice_coef: 0.9911 - jacard_coef: 0.9824 - binary_accuracy: 0.9958 - val_loss: 0.0575 - val_binary_crossentropy: 0.0660 - val_dice_coef: 0.9808 - val_jacard_coef: 0.9624 - val_binary_accuracy: 0.9894\n",
            "Epoch 188/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0506 - binary_crossentropy: 0.0199 - dice_coef: 0.9905 - jacard_coef: 0.9814 - binary_accuracy: 0.9956\n",
            "Epoch 00188: val_dice_coef did not improve from 0.98181\n",
            "62/61 [==============================] - 53s 853ms/step - loss: 0.0506 - binary_crossentropy: 0.0199 - dice_coef: 0.9905 - jacard_coef: 0.9814 - binary_accuracy: 0.9956 - val_loss: 0.0572 - val_binary_crossentropy: 0.0632 - val_dice_coef: 0.9805 - val_jacard_coef: 0.9619 - val_binary_accuracy: 0.9893\n",
            "Epoch 189/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0497 - binary_crossentropy: 0.0146 - dice_coef: 0.9911 - jacard_coef: 0.9824 - binary_accuracy: 0.9960\n",
            "Epoch 00189: val_dice_coef did not improve from 0.98181\n",
            "62/61 [==============================] - 53s 852ms/step - loss: 0.0497 - binary_crossentropy: 0.0146 - dice_coef: 0.9911 - jacard_coef: 0.9824 - binary_accuracy: 0.9960 - val_loss: 0.0571 - val_binary_crossentropy: 0.0624 - val_dice_coef: 0.9808 - val_jacard_coef: 0.9625 - val_binary_accuracy: 0.9895\n",
            "Epoch 190/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0495 - binary_crossentropy: 0.0122 - dice_coef: 0.9918 - jacard_coef: 0.9838 - binary_accuracy: 0.9962\n",
            "Epoch 00190: val_dice_coef did not improve from 0.98181\n",
            "62/61 [==============================] - 53s 853ms/step - loss: 0.0495 - binary_crossentropy: 0.0122 - dice_coef: 0.9918 - jacard_coef: 0.9838 - binary_accuracy: 0.9962 - val_loss: 0.0573 - val_binary_crossentropy: 0.0645 - val_dice_coef: 0.9811 - val_jacard_coef: 0.9631 - val_binary_accuracy: 0.9896\n",
            "Epoch 191/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0511 - binary_crossentropy: 0.0242 - dice_coef: 0.9900 - jacard_coef: 0.9805 - binary_accuracy: 0.9954\n",
            "Epoch 00191: val_dice_coef did not improve from 0.98181\n",
            "62/61 [==============================] - 53s 853ms/step - loss: 0.0511 - binary_crossentropy: 0.0242 - dice_coef: 0.9900 - jacard_coef: 0.9805 - binary_accuracy: 0.9954 - val_loss: 0.0567 - val_binary_crossentropy: 0.0587 - val_dice_coef: 0.9810 - val_jacard_coef: 0.9628 - val_binary_accuracy: 0.9896\n",
            "Epoch 192/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0491 - binary_crossentropy: 0.0108 - dice_coef: 0.9922 - jacard_coef: 0.9845 - binary_accuracy: 0.9965\n",
            "Epoch 00192: val_dice_coef did not improve from 0.98181\n",
            "62/61 [==============================] - 53s 854ms/step - loss: 0.0491 - binary_crossentropy: 0.0108 - dice_coef: 0.9922 - jacard_coef: 0.9845 - binary_accuracy: 0.9965 - val_loss: 0.0570 - val_binary_crossentropy: 0.0629 - val_dice_coef: 0.9812 - val_jacard_coef: 0.9632 - val_binary_accuracy: 0.9897\n",
            "Epoch 193/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0496 - binary_crossentropy: 0.0145 - dice_coef: 0.9917 - jacard_coef: 0.9836 - binary_accuracy: 0.9962\n",
            "Epoch 00193: val_dice_coef did not improve from 0.98181\n",
            "62/61 [==============================] - 53s 849ms/step - loss: 0.0496 - binary_crossentropy: 0.0145 - dice_coef: 0.9917 - jacard_coef: 0.9836 - binary_accuracy: 0.9962 - val_loss: 0.0566 - val_binary_crossentropy: 0.0592 - val_dice_coef: 0.9814 - val_jacard_coef: 0.9636 - val_binary_accuracy: 0.9898\n",
            "Epoch 194/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0499 - binary_crossentropy: 0.0168 - dice_coef: 0.9916 - jacard_coef: 0.9834 - binary_accuracy: 0.9961\n",
            "Epoch 00194: val_dice_coef did not improve from 0.98181\n",
            "62/61 [==============================] - 53s 853ms/step - loss: 0.0499 - binary_crossentropy: 0.0168 - dice_coef: 0.9916 - jacard_coef: 0.9834 - binary_accuracy: 0.9961 - val_loss: 0.0570 - val_binary_crossentropy: 0.0624 - val_dice_coef: 0.9812 - val_jacard_coef: 0.9632 - val_binary_accuracy: 0.9897\n",
            "Epoch 195/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0505 - binary_crossentropy: 0.0206 - dice_coef: 0.9905 - jacard_coef: 0.9814 - binary_accuracy: 0.9957\n",
            "Epoch 00195: val_dice_coef did not improve from 0.98181\n",
            "62/61 [==============================] - 53s 852ms/step - loss: 0.0505 - binary_crossentropy: 0.0206 - dice_coef: 0.9905 - jacard_coef: 0.9814 - binary_accuracy: 0.9957 - val_loss: 0.0570 - val_binary_crossentropy: 0.0609 - val_dice_coef: 0.9808 - val_jacard_coef: 0.9624 - val_binary_accuracy: 0.9895\n",
            "Epoch 196/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0513 - binary_crossentropy: 0.0233 - dice_coef: 0.9898 - jacard_coef: 0.9801 - binary_accuracy: 0.9952\n",
            "Epoch 00196: val_dice_coef did not improve from 0.98181\n",
            "62/61 [==============================] - 53s 855ms/step - loss: 0.0513 - binary_crossentropy: 0.0233 - dice_coef: 0.9898 - jacard_coef: 0.9801 - binary_accuracy: 0.9952 - val_loss: 0.0578 - val_binary_crossentropy: 0.0661 - val_dice_coef: 0.9801 - val_jacard_coef: 0.9611 - val_binary_accuracy: 0.9891\n",
            "Epoch 197/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0515 - binary_crossentropy: 0.0263 - dice_coef: 0.9894 - jacard_coef: 0.9795 - binary_accuracy: 0.9949\n",
            "Epoch 00197: val_dice_coef did not improve from 0.98181\n",
            "62/61 [==============================] - 53s 850ms/step - loss: 0.0515 - binary_crossentropy: 0.0263 - dice_coef: 0.9894 - jacard_coef: 0.9795 - binary_accuracy: 0.9949 - val_loss: 0.0585 - val_binary_crossentropy: 0.0714 - val_dice_coef: 0.9797 - val_jacard_coef: 0.9604 - val_binary_accuracy: 0.9889\n",
            "Epoch 198/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0492 - binary_crossentropy: 0.0114 - dice_coef: 0.9921 - jacard_coef: 0.9842 - binary_accuracy: 0.9964\n",
            "Epoch 00198: val_dice_coef did not improve from 0.98181\n",
            "62/61 [==============================] - 53s 850ms/step - loss: 0.0492 - binary_crossentropy: 0.0114 - dice_coef: 0.9921 - jacard_coef: 0.9842 - binary_accuracy: 0.9964 - val_loss: 0.0570 - val_binary_crossentropy: 0.0620 - val_dice_coef: 0.9811 - val_jacard_coef: 0.9630 - val_binary_accuracy: 0.9896\n",
            "Epoch 199/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0502 - binary_crossentropy: 0.0177 - dice_coef: 0.9912 - jacard_coef: 0.9826 - binary_accuracy: 0.9959\n",
            "Epoch 00199: val_dice_coef did not improve from 0.98181\n",
            "62/61 [==============================] - 53s 852ms/step - loss: 0.0502 - binary_crossentropy: 0.0177 - dice_coef: 0.9912 - jacard_coef: 0.9826 - binary_accuracy: 0.9959 - val_loss: 0.0572 - val_binary_crossentropy: 0.0625 - val_dice_coef: 0.9809 - val_jacard_coef: 0.9626 - val_binary_accuracy: 0.9895\n",
            "Epoch 200/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0493 - binary_crossentropy: 0.0127 - dice_coef: 0.9922 - jacard_coef: 0.9846 - binary_accuracy: 0.9964\n",
            "Epoch 00200: val_dice_coef did not improve from 0.98181\n",
            "62/61 [==============================] - 53s 854ms/step - loss: 0.0493 - binary_crossentropy: 0.0127 - dice_coef: 0.9922 - jacard_coef: 0.9846 - binary_accuracy: 0.9964 - val_loss: 0.0573 - val_binary_crossentropy: 0.0646 - val_dice_coef: 0.9810 - val_jacard_coef: 0.9628 - val_binary_accuracy: 0.9896\n",
            "Epoch 201/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0497 - binary_crossentropy: 0.0153 - dice_coef: 0.9917 - jacard_coef: 0.9836 - binary_accuracy: 0.9962\n",
            "Epoch 00201: val_dice_coef did not improve from 0.98181\n",
            "62/61 [==============================] - 53s 854ms/step - loss: 0.0497 - binary_crossentropy: 0.0153 - dice_coef: 0.9917 - jacard_coef: 0.9836 - binary_accuracy: 0.9962 - val_loss: 0.0573 - val_binary_crossentropy: 0.0639 - val_dice_coef: 0.9811 - val_jacard_coef: 0.9629 - val_binary_accuracy: 0.9896\n",
            "Epoch 202/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0502 - binary_crossentropy: 0.0190 - dice_coef: 0.9912 - jacard_coef: 0.9827 - binary_accuracy: 0.9958\n",
            "Epoch 00202: val_dice_coef did not improve from 0.98181\n",
            "62/61 [==============================] - 53s 853ms/step - loss: 0.0502 - binary_crossentropy: 0.0190 - dice_coef: 0.9912 - jacard_coef: 0.9827 - binary_accuracy: 0.9958 - val_loss: 0.0574 - val_binary_crossentropy: 0.0646 - val_dice_coef: 0.9811 - val_jacard_coef: 0.9630 - val_binary_accuracy: 0.9896\n",
            "Epoch 203/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0503 - binary_crossentropy: 0.0193 - dice_coef: 0.9913 - jacard_coef: 0.9829 - binary_accuracy: 0.9959\n",
            "Epoch 00203: val_dice_coef did not improve from 0.98181\n",
            "62/61 [==============================] - 53s 852ms/step - loss: 0.0503 - binary_crossentropy: 0.0193 - dice_coef: 0.9913 - jacard_coef: 0.9829 - binary_accuracy: 0.9959 - val_loss: 0.0574 - val_binary_crossentropy: 0.0645 - val_dice_coef: 0.9810 - val_jacard_coef: 0.9628 - val_binary_accuracy: 0.9895\n",
            "Epoch 204/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0491 - binary_crossentropy: 0.0113 - dice_coef: 0.9925 - jacard_coef: 0.9851 - binary_accuracy: 0.9966\n",
            "Epoch 00204: val_dice_coef did not improve from 0.98181\n",
            "62/61 [==============================] - 53s 853ms/step - loss: 0.0491 - binary_crossentropy: 0.0113 - dice_coef: 0.9925 - jacard_coef: 0.9851 - binary_accuracy: 0.9966 - val_loss: 0.0576 - val_binary_crossentropy: 0.0673 - val_dice_coef: 0.9813 - val_jacard_coef: 0.9634 - val_binary_accuracy: 0.9897\n",
            "Epoch 205/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0497 - binary_crossentropy: 0.0154 - dice_coef: 0.9918 - jacard_coef: 0.9838 - binary_accuracy: 0.9962\n",
            "Epoch 00205: val_dice_coef did not improve from 0.98181\n",
            "62/61 [==============================] - 53s 855ms/step - loss: 0.0497 - binary_crossentropy: 0.0154 - dice_coef: 0.9918 - jacard_coef: 0.9838 - binary_accuracy: 0.9962 - val_loss: 0.0568 - val_binary_crossentropy: 0.0602 - val_dice_coef: 0.9815 - val_jacard_coef: 0.9638 - val_binary_accuracy: 0.9898\n",
            "Epoch 206/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0490 - binary_crossentropy: 0.0102 - dice_coef: 0.9926 - jacard_coef: 0.9853 - binary_accuracy: 0.9966\n",
            "Epoch 00206: val_dice_coef did not improve from 0.98181\n",
            "62/61 [==============================] - 53s 852ms/step - loss: 0.0490 - binary_crossentropy: 0.0102 - dice_coef: 0.9926 - jacard_coef: 0.9853 - binary_accuracy: 0.9966 - val_loss: 0.0574 - val_binary_crossentropy: 0.0657 - val_dice_coef: 0.9810 - val_jacard_coef: 0.9628 - val_binary_accuracy: 0.9895\n",
            "Epoch 207/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0494 - binary_crossentropy: 0.0134 - dice_coef: 0.9920 - jacard_coef: 0.9842 - binary_accuracy: 0.9963\n",
            "Epoch 00207: val_dice_coef did not improve from 0.98181\n",
            "62/61 [==============================] - 53s 852ms/step - loss: 0.0494 - binary_crossentropy: 0.0134 - dice_coef: 0.9920 - jacard_coef: 0.9842 - binary_accuracy: 0.9963 - val_loss: 0.0579 - val_binary_crossentropy: 0.0699 - val_dice_coef: 0.9808 - val_jacard_coef: 0.9624 - val_binary_accuracy: 0.9894\n",
            "Epoch 208/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0499 - binary_crossentropy: 0.0162 - dice_coef: 0.9914 - jacard_coef: 0.9831 - binary_accuracy: 0.9961\n",
            "Epoch 00208: val_dice_coef did not improve from 0.98181\n",
            "62/61 [==============================] - 53s 855ms/step - loss: 0.0499 - binary_crossentropy: 0.0162 - dice_coef: 0.9914 - jacard_coef: 0.9831 - binary_accuracy: 0.9961 - val_loss: 0.0574 - val_binary_crossentropy: 0.0647 - val_dice_coef: 0.9810 - val_jacard_coef: 0.9628 - val_binary_accuracy: 0.9896\n",
            "Epoch 209/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0499 - binary_crossentropy: 0.0171 - dice_coef: 0.9914 - jacard_coef: 0.9830 - binary_accuracy: 0.9960\n",
            "Epoch 00209: val_dice_coef did not improve from 0.98181\n",
            "62/61 [==============================] - 53s 853ms/step - loss: 0.0499 - binary_crossentropy: 0.0171 - dice_coef: 0.9914 - jacard_coef: 0.9830 - binary_accuracy: 0.9960 - val_loss: 0.0573 - val_binary_crossentropy: 0.0643 - val_dice_coef: 0.9810 - val_jacard_coef: 0.9628 - val_binary_accuracy: 0.9896\n",
            "Epoch 210/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0502 - binary_crossentropy: 0.0194 - dice_coef: 0.9912 - jacard_coef: 0.9828 - binary_accuracy: 0.9959\n",
            "Epoch 00210: val_dice_coef did not improve from 0.98181\n",
            "62/61 [==============================] - 53s 852ms/step - loss: 0.0502 - binary_crossentropy: 0.0194 - dice_coef: 0.9912 - jacard_coef: 0.9828 - binary_accuracy: 0.9959 - val_loss: 0.0569 - val_binary_crossentropy: 0.0608 - val_dice_coef: 0.9811 - val_jacard_coef: 0.9630 - val_binary_accuracy: 0.9897\n",
            "Epoch 211/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0515 - binary_crossentropy: 0.0290 - dice_coef: 0.9902 - jacard_coef: 0.9810 - binary_accuracy: 0.9952\n",
            "Epoch 00211: val_dice_coef did not improve from 0.98181\n",
            "62/61 [==============================] - 53s 853ms/step - loss: 0.0515 - binary_crossentropy: 0.0290 - dice_coef: 0.9902 - jacard_coef: 0.9810 - binary_accuracy: 0.9952 - val_loss: 0.0571 - val_binary_crossentropy: 0.0613 - val_dice_coef: 0.9810 - val_jacard_coef: 0.9628 - val_binary_accuracy: 0.9895\n",
            "Epoch 212/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0497 - binary_crossentropy: 0.0150 - dice_coef: 0.9916 - jacard_coef: 0.9835 - binary_accuracy: 0.9961\n",
            "Epoch 00212: val_dice_coef did not improve from 0.98181\n",
            "62/61 [==============================] - 53s 853ms/step - loss: 0.0497 - binary_crossentropy: 0.0150 - dice_coef: 0.9916 - jacard_coef: 0.9835 - binary_accuracy: 0.9961 - val_loss: 0.0567 - val_binary_crossentropy: 0.0583 - val_dice_coef: 0.9813 - val_jacard_coef: 0.9634 - val_binary_accuracy: 0.9897\n",
            "Epoch 213/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0499 - binary_crossentropy: 0.0169 - dice_coef: 0.9917 - jacard_coef: 0.9837 - binary_accuracy: 0.9962\n",
            "Epoch 00213: val_dice_coef did not improve from 0.98181\n",
            "62/61 [==============================] - 53s 853ms/step - loss: 0.0499 - binary_crossentropy: 0.0169 - dice_coef: 0.9917 - jacard_coef: 0.9837 - binary_accuracy: 0.9962 - val_loss: 0.0565 - val_binary_crossentropy: 0.0584 - val_dice_coef: 0.9818 - val_jacard_coef: 0.9642 - val_binary_accuracy: 0.9900\n",
            "Epoch 214/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0494 - binary_crossentropy: 0.0138 - dice_coef: 0.9922 - jacard_coef: 0.9846 - binary_accuracy: 0.9964\n",
            "Epoch 00214: val_dice_coef did not improve from 0.98181\n",
            "62/61 [==============================] - 53s 853ms/step - loss: 0.0494 - binary_crossentropy: 0.0138 - dice_coef: 0.9922 - jacard_coef: 0.9846 - binary_accuracy: 0.9964 - val_loss: 0.0566 - val_binary_crossentropy: 0.0585 - val_dice_coef: 0.9816 - val_jacard_coef: 0.9640 - val_binary_accuracy: 0.9899\n",
            "Epoch 215/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0491 - binary_crossentropy: 0.0121 - dice_coef: 0.9926 - jacard_coef: 0.9853 - binary_accuracy: 0.9966\n",
            "Epoch 00215: val_dice_coef did not improve from 0.98181\n",
            "62/61 [==============================] - 53s 852ms/step - loss: 0.0491 - binary_crossentropy: 0.0121 - dice_coef: 0.9926 - jacard_coef: 0.9853 - binary_accuracy: 0.9966 - val_loss: 0.0568 - val_binary_crossentropy: 0.0609 - val_dice_coef: 0.9817 - val_jacard_coef: 0.9640 - val_binary_accuracy: 0.9899\n",
            "Epoch 216/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0514 - binary_crossentropy: 0.0274 - dice_coef: 0.9906 - jacard_coef: 0.9819 - binary_accuracy: 0.9955\n",
            "Epoch 00216: val_dice_coef improved from 0.98181 to 0.98207, saving model to net_lung_seg.hdf5\n",
            "62/61 [==============================] - 55s 882ms/step - loss: 0.0514 - binary_crossentropy: 0.0274 - dice_coef: 0.9906 - jacard_coef: 0.9819 - binary_accuracy: 0.9955 - val_loss: 0.0558 - val_binary_crossentropy: 0.0528 - val_dice_coef: 0.9821 - val_jacard_coef: 0.9648 - val_binary_accuracy: 0.9902\n",
            "Epoch 217/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0495 - binary_crossentropy: 0.0142 - dice_coef: 0.9924 - jacard_coef: 0.9850 - binary_accuracy: 0.9965\n",
            "Epoch 00217: val_dice_coef did not improve from 0.98207\n",
            "62/61 [==============================] - 53s 852ms/step - loss: 0.0495 - binary_crossentropy: 0.0142 - dice_coef: 0.9924 - jacard_coef: 0.9850 - binary_accuracy: 0.9965 - val_loss: 0.0566 - val_binary_crossentropy: 0.0590 - val_dice_coef: 0.9816 - val_jacard_coef: 0.9639 - val_binary_accuracy: 0.9899\n",
            "Epoch 218/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0498 - binary_crossentropy: 0.0165 - dice_coef: 0.9920 - jacard_coef: 0.9843 - binary_accuracy: 0.9963\n",
            "Epoch 00218: val_dice_coef did not improve from 0.98207\n",
            "62/61 [==============================] - 53s 853ms/step - loss: 0.0498 - binary_crossentropy: 0.0165 - dice_coef: 0.9920 - jacard_coef: 0.9843 - binary_accuracy: 0.9963 - val_loss: 0.0567 - val_binary_crossentropy: 0.0604 - val_dice_coef: 0.9817 - val_jacard_coef: 0.9641 - val_binary_accuracy: 0.9899\n",
            "Epoch 219/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0491 - binary_crossentropy: 0.0124 - dice_coef: 0.9928 - jacard_coef: 0.9857 - binary_accuracy: 0.9967\n",
            "Epoch 00219: val_dice_coef did not improve from 0.98207\n",
            "62/61 [==============================] - 53s 855ms/step - loss: 0.0491 - binary_crossentropy: 0.0124 - dice_coef: 0.9928 - jacard_coef: 0.9857 - binary_accuracy: 0.9967 - val_loss: 0.0571 - val_binary_crossentropy: 0.0641 - val_dice_coef: 0.9816 - val_jacard_coef: 0.9639 - val_binary_accuracy: 0.9899\n",
            "Epoch 220/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0500 - binary_crossentropy: 0.0180 - dice_coef: 0.9919 - jacard_coef: 0.9841 - binary_accuracy: 0.9962\n",
            "Epoch 00220: val_dice_coef did not improve from 0.98207\n",
            "62/61 [==============================] - 53s 853ms/step - loss: 0.0500 - binary_crossentropy: 0.0180 - dice_coef: 0.9919 - jacard_coef: 0.9841 - binary_accuracy: 0.9962 - val_loss: 0.0573 - val_binary_crossentropy: 0.0639 - val_dice_coef: 0.9814 - val_jacard_coef: 0.9635 - val_binary_accuracy: 0.9897\n",
            "Epoch 221/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0493 - binary_crossentropy: 0.0139 - dice_coef: 0.9925 - jacard_coef: 0.9852 - binary_accuracy: 0.9965\n",
            "Epoch 00221: val_dice_coef did not improve from 0.98207\n",
            "62/61 [==============================] - 53s 852ms/step - loss: 0.0493 - binary_crossentropy: 0.0139 - dice_coef: 0.9925 - jacard_coef: 0.9852 - binary_accuracy: 0.9965 - val_loss: 0.0577 - val_binary_crossentropy: 0.0692 - val_dice_coef: 0.9811 - val_jacard_coef: 0.9629 - val_binary_accuracy: 0.9896\n",
            "Epoch 222/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0507 - binary_crossentropy: 0.0231 - dice_coef: 0.9911 - jacard_coef: 0.9828 - binary_accuracy: 0.9958\n",
            "Epoch 00222: val_dice_coef did not improve from 0.98207\n",
            "62/61 [==============================] - 53s 850ms/step - loss: 0.0507 - binary_crossentropy: 0.0231 - dice_coef: 0.9911 - jacard_coef: 0.9828 - binary_accuracy: 0.9958 - val_loss: 0.0569 - val_binary_crossentropy: 0.0622 - val_dice_coef: 0.9816 - val_jacard_coef: 0.9639 - val_binary_accuracy: 0.9898\n",
            "Epoch 223/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0487 - binary_crossentropy: 0.0096 - dice_coef: 0.9932 - jacard_coef: 0.9865 - binary_accuracy: 0.9969\n",
            "Epoch 00223: val_dice_coef did not improve from 0.98207\n",
            "62/61 [==============================] - 53s 854ms/step - loss: 0.0487 - binary_crossentropy: 0.0096 - dice_coef: 0.9932 - jacard_coef: 0.9865 - binary_accuracy: 0.9969 - val_loss: 0.0577 - val_binary_crossentropy: 0.0677 - val_dice_coef: 0.9812 - val_jacard_coef: 0.9632 - val_binary_accuracy: 0.9896\n",
            "Epoch 224/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0494 - binary_crossentropy: 0.0138 - dice_coef: 0.9925 - jacard_coef: 0.9851 - binary_accuracy: 0.9965\n",
            "Epoch 00224: val_dice_coef did not improve from 0.98207\n",
            "62/61 [==============================] - 53s 851ms/step - loss: 0.0494 - binary_crossentropy: 0.0138 - dice_coef: 0.9925 - jacard_coef: 0.9851 - binary_accuracy: 0.9965 - val_loss: 0.0574 - val_binary_crossentropy: 0.0666 - val_dice_coef: 0.9814 - val_jacard_coef: 0.9635 - val_binary_accuracy: 0.9897\n",
            "Epoch 225/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0490 - binary_crossentropy: 0.0113 - dice_coef: 0.9928 - jacard_coef: 0.9857 - binary_accuracy: 0.9967\n",
            "Epoch 00225: val_dice_coef did not improve from 0.98207\n",
            "62/61 [==============================] - 53s 855ms/step - loss: 0.0490 - binary_crossentropy: 0.0113 - dice_coef: 0.9928 - jacard_coef: 0.9857 - binary_accuracy: 0.9967 - val_loss: 0.0578 - val_binary_crossentropy: 0.0690 - val_dice_coef: 0.9810 - val_jacard_coef: 0.9627 - val_binary_accuracy: 0.9895\n",
            "Epoch 226/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0493 - binary_crossentropy: 0.0133 - dice_coef: 0.9926 - jacard_coef: 0.9852 - binary_accuracy: 0.9965\n",
            "Epoch 00226: val_dice_coef did not improve from 0.98207\n",
            "62/61 [==============================] - 53s 851ms/step - loss: 0.0493 - binary_crossentropy: 0.0133 - dice_coef: 0.9926 - jacard_coef: 0.9852 - binary_accuracy: 0.9965 - val_loss: 0.0579 - val_binary_crossentropy: 0.0703 - val_dice_coef: 0.9811 - val_jacard_coef: 0.9629 - val_binary_accuracy: 0.9896\n",
            "Epoch 227/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0496 - binary_crossentropy: 0.0154 - dice_coef: 0.9919 - jacard_coef: 0.9841 - binary_accuracy: 0.9962\n",
            "Epoch 00227: val_dice_coef did not improve from 0.98207\n",
            "62/61 [==============================] - 53s 852ms/step - loss: 0.0496 - binary_crossentropy: 0.0154 - dice_coef: 0.9919 - jacard_coef: 0.9841 - binary_accuracy: 0.9962 - val_loss: 0.0575 - val_binary_crossentropy: 0.0668 - val_dice_coef: 0.9812 - val_jacard_coef: 0.9631 - val_binary_accuracy: 0.9896\n",
            "Epoch 228/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0518 - binary_crossentropy: 0.0293 - dice_coef: 0.9894 - jacard_coef: 0.9798 - binary_accuracy: 0.9951\n",
            "Epoch 00228: val_dice_coef did not improve from 0.98207\n",
            "62/61 [==============================] - 53s 853ms/step - loss: 0.0518 - binary_crossentropy: 0.0293 - dice_coef: 0.9894 - jacard_coef: 0.9798 - binary_accuracy: 0.9951 - val_loss: 0.0577 - val_binary_crossentropy: 0.0673 - val_dice_coef: 0.9810 - val_jacard_coef: 0.9628 - val_binary_accuracy: 0.9896\n",
            "Epoch 229/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0490 - binary_crossentropy: 0.0109 - dice_coef: 0.9925 - jacard_coef: 0.9851 - binary_accuracy: 0.9966\n",
            "Epoch 00229: val_dice_coef did not improve from 0.98207\n",
            "62/61 [==============================] - 53s 854ms/step - loss: 0.0490 - binary_crossentropy: 0.0109 - dice_coef: 0.9925 - jacard_coef: 0.9851 - binary_accuracy: 0.9966 - val_loss: 0.0575 - val_binary_crossentropy: 0.0653 - val_dice_coef: 0.9810 - val_jacard_coef: 0.9627 - val_binary_accuracy: 0.9895\n",
            "Epoch 230/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0514 - binary_crossentropy: 0.0257 - dice_coef: 0.9899 - jacard_coef: 0.9806 - binary_accuracy: 0.9953\n",
            "Epoch 00230: val_dice_coef did not improve from 0.98207\n",
            "62/61 [==============================] - 53s 853ms/step - loss: 0.0514 - binary_crossentropy: 0.0257 - dice_coef: 0.9899 - jacard_coef: 0.9806 - binary_accuracy: 0.9953 - val_loss: 0.0574 - val_binary_crossentropy: 0.0653 - val_dice_coef: 0.9813 - val_jacard_coef: 0.9633 - val_binary_accuracy: 0.9896\n",
            "Epoch 231/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0497 - binary_crossentropy: 0.0153 - dice_coef: 0.9918 - jacard_coef: 0.9839 - binary_accuracy: 0.9962\n",
            "Epoch 00231: val_dice_coef did not improve from 0.98207\n",
            "62/61 [==============================] - 53s 854ms/step - loss: 0.0497 - binary_crossentropy: 0.0153 - dice_coef: 0.9918 - jacard_coef: 0.9839 - binary_accuracy: 0.9962 - val_loss: 0.0570 - val_binary_crossentropy: 0.0631 - val_dice_coef: 0.9815 - val_jacard_coef: 0.9636 - val_binary_accuracy: 0.9898\n",
            "Epoch 232/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0490 - binary_crossentropy: 0.0115 - dice_coef: 0.9927 - jacard_coef: 0.9854 - binary_accuracy: 0.9967\n",
            "Epoch 00232: val_dice_coef did not improve from 0.98207\n",
            "62/61 [==============================] - 53s 852ms/step - loss: 0.0490 - binary_crossentropy: 0.0115 - dice_coef: 0.9927 - jacard_coef: 0.9854 - binary_accuracy: 0.9967 - val_loss: 0.0575 - val_binary_crossentropy: 0.0656 - val_dice_coef: 0.9810 - val_jacard_coef: 0.9627 - val_binary_accuracy: 0.9895\n",
            "Epoch 233/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0496 - binary_crossentropy: 0.0150 - dice_coef: 0.9921 - jacard_coef: 0.9844 - binary_accuracy: 0.9963\n",
            "Epoch 00233: val_dice_coef did not improve from 0.98207\n",
            "62/61 [==============================] - 53s 851ms/step - loss: 0.0496 - binary_crossentropy: 0.0150 - dice_coef: 0.9921 - jacard_coef: 0.9844 - binary_accuracy: 0.9963 - val_loss: 0.0575 - val_binary_crossentropy: 0.0671 - val_dice_coef: 0.9810 - val_jacard_coef: 0.9629 - val_binary_accuracy: 0.9896\n",
            "Epoch 234/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0494 - binary_crossentropy: 0.0143 - dice_coef: 0.9923 - jacard_coef: 0.9848 - binary_accuracy: 0.9965\n",
            "Epoch 00234: val_dice_coef did not improve from 0.98207\n",
            "62/61 [==============================] - 53s 852ms/step - loss: 0.0494 - binary_crossentropy: 0.0143 - dice_coef: 0.9923 - jacard_coef: 0.9848 - binary_accuracy: 0.9965 - val_loss: 0.0574 - val_binary_crossentropy: 0.0655 - val_dice_coef: 0.9812 - val_jacard_coef: 0.9632 - val_binary_accuracy: 0.9897\n",
            "Epoch 235/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0492 - binary_crossentropy: 0.0129 - dice_coef: 0.9927 - jacard_coef: 0.9855 - binary_accuracy: 0.9966\n",
            "Epoch 00235: val_dice_coef did not improve from 0.98207\n",
            "62/61 [==============================] - 53s 855ms/step - loss: 0.0492 - binary_crossentropy: 0.0129 - dice_coef: 0.9927 - jacard_coef: 0.9855 - binary_accuracy: 0.9966 - val_loss: 0.0575 - val_binary_crossentropy: 0.0653 - val_dice_coef: 0.9812 - val_jacard_coef: 0.9631 - val_binary_accuracy: 0.9896\n",
            "Epoch 236/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0498 - binary_crossentropy: 0.0163 - dice_coef: 0.9920 - jacard_coef: 0.9843 - binary_accuracy: 0.9964\n",
            "Epoch 00236: val_dice_coef did not improve from 0.98207\n",
            "62/61 [==============================] - 53s 853ms/step - loss: 0.0498 - binary_crossentropy: 0.0163 - dice_coef: 0.9920 - jacard_coef: 0.9843 - binary_accuracy: 0.9964 - val_loss: 0.0569 - val_binary_crossentropy: 0.0618 - val_dice_coef: 0.9816 - val_jacard_coef: 0.9640 - val_binary_accuracy: 0.9899\n",
            "Epoch 237/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0490 - binary_crossentropy: 0.0118 - dice_coef: 0.9930 - jacard_coef: 0.9860 - binary_accuracy: 0.9968\n",
            "Epoch 00237: val_dice_coef did not improve from 0.98207\n",
            "62/61 [==============================] - 53s 850ms/step - loss: 0.0490 - binary_crossentropy: 0.0118 - dice_coef: 0.9930 - jacard_coef: 0.9860 - binary_accuracy: 0.9968 - val_loss: 0.0567 - val_binary_crossentropy: 0.0613 - val_dice_coef: 0.9818 - val_jacard_coef: 0.9644 - val_binary_accuracy: 0.9899\n",
            "Epoch 238/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0486 - binary_crossentropy: 0.0091 - dice_coef: 0.9935 - jacard_coef: 0.9872 - binary_accuracy: 0.9971\n",
            "Epoch 00238: val_dice_coef did not improve from 0.98207\n",
            "62/61 [==============================] - 53s 852ms/step - loss: 0.0486 - binary_crossentropy: 0.0091 - dice_coef: 0.9935 - jacard_coef: 0.9872 - binary_accuracy: 0.9971 - val_loss: 0.0571 - val_binary_crossentropy: 0.0643 - val_dice_coef: 0.9816 - val_jacard_coef: 0.9640 - val_binary_accuracy: 0.9899\n",
            "Epoch 239/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0488 - binary_crossentropy: 0.0101 - dice_coef: 0.9933 - jacard_coef: 0.9867 - binary_accuracy: 0.9970\n",
            "Epoch 00239: val_dice_coef did not improve from 0.98207\n",
            "62/61 [==============================] - 53s 851ms/step - loss: 0.0488 - binary_crossentropy: 0.0101 - dice_coef: 0.9933 - jacard_coef: 0.9867 - binary_accuracy: 0.9970 - val_loss: 0.0572 - val_binary_crossentropy: 0.0654 - val_dice_coef: 0.9816 - val_jacard_coef: 0.9639 - val_binary_accuracy: 0.9898\n",
            "Epoch 240/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0494 - binary_crossentropy: 0.0151 - dice_coef: 0.9926 - jacard_coef: 0.9854 - binary_accuracy: 0.9966\n",
            "Epoch 00240: val_dice_coef improved from 0.98207 to 0.98226, saving model to net_lung_seg.hdf5\n",
            "62/61 [==============================] - 55s 881ms/step - loss: 0.0494 - binary_crossentropy: 0.0151 - dice_coef: 0.9926 - jacard_coef: 0.9854 - binary_accuracy: 0.9966 - val_loss: 0.0563 - val_binary_crossentropy: 0.0585 - val_dice_coef: 0.9823 - val_jacard_coef: 0.9652 - val_binary_accuracy: 0.9902\n",
            "Epoch 241/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0494 - binary_crossentropy: 0.0147 - dice_coef: 0.9927 - jacard_coef: 0.9856 - binary_accuracy: 0.9966\n",
            "Epoch 00241: val_dice_coef did not improve from 0.98226\n",
            "62/61 [==============================] - 53s 856ms/step - loss: 0.0494 - binary_crossentropy: 0.0147 - dice_coef: 0.9927 - jacard_coef: 0.9856 - binary_accuracy: 0.9966 - val_loss: 0.0571 - val_binary_crossentropy: 0.0644 - val_dice_coef: 0.9816 - val_jacard_coef: 0.9639 - val_binary_accuracy: 0.9898\n",
            "Epoch 242/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0500 - binary_crossentropy: 0.0186 - dice_coef: 0.9917 - jacard_coef: 0.9838 - binary_accuracy: 0.9962\n",
            "Epoch 00242: val_dice_coef did not improve from 0.98226\n",
            "62/61 [==============================] - 53s 850ms/step - loss: 0.0500 - binary_crossentropy: 0.0186 - dice_coef: 0.9917 - jacard_coef: 0.9838 - binary_accuracy: 0.9962 - val_loss: 0.0570 - val_binary_crossentropy: 0.0619 - val_dice_coef: 0.9815 - val_jacard_coef: 0.9637 - val_binary_accuracy: 0.9898\n",
            "Epoch 243/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0498 - binary_crossentropy: 0.0173 - dice_coef: 0.9920 - jacard_coef: 0.9842 - binary_accuracy: 0.9963\n",
            "Epoch 00243: val_dice_coef did not improve from 0.98226\n",
            "62/61 [==============================] - 53s 853ms/step - loss: 0.0498 - binary_crossentropy: 0.0173 - dice_coef: 0.9920 - jacard_coef: 0.9842 - binary_accuracy: 0.9963 - val_loss: 0.0573 - val_binary_crossentropy: 0.0654 - val_dice_coef: 0.9812 - val_jacard_coef: 0.9632 - val_binary_accuracy: 0.9896\n",
            "Epoch 244/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0488 - binary_crossentropy: 0.0108 - dice_coef: 0.9930 - jacard_coef: 0.9862 - binary_accuracy: 0.9968\n",
            "Epoch 00244: val_dice_coef did not improve from 0.98226\n",
            "62/61 [==============================] - 53s 851ms/step - loss: 0.0488 - binary_crossentropy: 0.0108 - dice_coef: 0.9930 - jacard_coef: 0.9862 - binary_accuracy: 0.9968 - val_loss: 0.0572 - val_binary_crossentropy: 0.0645 - val_dice_coef: 0.9815 - val_jacard_coef: 0.9637 - val_binary_accuracy: 0.9898\n",
            "Epoch 245/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0495 - binary_crossentropy: 0.0155 - dice_coef: 0.9922 - jacard_coef: 0.9846 - binary_accuracy: 0.9964\n",
            "Epoch 00245: val_dice_coef did not improve from 0.98226\n",
            "62/61 [==============================] - 53s 852ms/step - loss: 0.0495 - binary_crossentropy: 0.0155 - dice_coef: 0.9922 - jacard_coef: 0.9846 - binary_accuracy: 0.9964 - val_loss: 0.0562 - val_binary_crossentropy: 0.0565 - val_dice_coef: 0.9823 - val_jacard_coef: 0.9652 - val_binary_accuracy: 0.9902\n",
            "Epoch 246/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0503 - binary_crossentropy: 0.0199 - dice_coef: 0.9915 - jacard_coef: 0.9834 - binary_accuracy: 0.9960\n",
            "Epoch 00246: val_dice_coef did not improve from 0.98226\n",
            "62/61 [==============================] - 53s 854ms/step - loss: 0.0503 - binary_crossentropy: 0.0199 - dice_coef: 0.9915 - jacard_coef: 0.9834 - binary_accuracy: 0.9960 - val_loss: 0.0579 - val_binary_crossentropy: 0.0677 - val_dice_coef: 0.9801 - val_jacard_coef: 0.9611 - val_binary_accuracy: 0.9890\n",
            "Epoch 247/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0491 - binary_crossentropy: 0.0117 - dice_coef: 0.9926 - jacard_coef: 0.9854 - binary_accuracy: 0.9966\n",
            "Epoch 00247: val_dice_coef did not improve from 0.98226\n",
            "62/61 [==============================] - 53s 852ms/step - loss: 0.0491 - binary_crossentropy: 0.0117 - dice_coef: 0.9926 - jacard_coef: 0.9854 - binary_accuracy: 0.9966 - val_loss: 0.0581 - val_binary_crossentropy: 0.0693 - val_dice_coef: 0.9809 - val_jacard_coef: 0.9625 - val_binary_accuracy: 0.9894\n",
            "Epoch 248/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0495 - binary_crossentropy: 0.0146 - dice_coef: 0.9921 - jacard_coef: 0.9844 - binary_accuracy: 0.9964\n",
            "Epoch 00248: val_dice_coef did not improve from 0.98226\n",
            "62/61 [==============================] - 53s 852ms/step - loss: 0.0495 - binary_crossentropy: 0.0146 - dice_coef: 0.9921 - jacard_coef: 0.9844 - binary_accuracy: 0.9964 - val_loss: 0.0577 - val_binary_crossentropy: 0.0687 - val_dice_coef: 0.9813 - val_jacard_coef: 0.9633 - val_binary_accuracy: 0.9897\n",
            "Epoch 249/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0505 - binary_crossentropy: 0.0213 - dice_coef: 0.9912 - jacard_coef: 0.9828 - binary_accuracy: 0.9958\n",
            "Epoch 00249: val_dice_coef did not improve from 0.98226\n",
            "62/61 [==============================] - 53s 851ms/step - loss: 0.0505 - binary_crossentropy: 0.0213 - dice_coef: 0.9912 - jacard_coef: 0.9828 - binary_accuracy: 0.9958 - val_loss: 0.0569 - val_binary_crossentropy: 0.0602 - val_dice_coef: 0.9811 - val_jacard_coef: 0.9629 - val_binary_accuracy: 0.9896\n",
            "Epoch 250/250\n",
            "62/61 [==============================] - ETA: 0s - loss: 0.0492 - binary_crossentropy: 0.0118 - dice_coef: 0.9925 - jacard_coef: 0.9852 - binary_accuracy: 0.9966\n",
            "Epoch 00250: val_dice_coef did not improve from 0.98226\n",
            "62/61 [==============================] - 53s 852ms/step - loss: 0.0492 - binary_crossentropy: 0.0118 - dice_coef: 0.9925 - jacard_coef: 0.9852 - binary_accuracy: 0.9966 - val_loss: 0.0571 - val_binary_crossentropy: 0.0644 - val_dice_coef: 0.9815 - val_jacard_coef: 0.9637 - val_binary_accuracy: 0.9898\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95g92shmc9Az",
        "outputId": "c1dba73f-dfbd-41b3-a379-e8750a752ac5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!cp -av /content/net_lung_seg.hdf5 \"/content/gdrive/My Drive/Colab Notebooks/unetplusplus/net_lung_seg.hdf5\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'/content/net_lung_seg.hdf5' -> '/content/gdrive/My Drive/Colab Notebooks/unetplusplus/net_lung_seg.hdf5'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzUy26eWdF7a",
        "outputId": "614895ac-82bf-4fca-fcf9-cddb8f0d96ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "!cp -avr /content/logs \"/content/gdrive/My Drive/Colab Notebooks/unetplusplus/logs\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'/content/logs/history_plotter/20200926-090303/train/events.out.tfevents.1601110984.18aefa419a69.99.20824.v2' -> '/content/gdrive/My Drive/Colab Notebooks/unetplusplus/logs/logs/history_plotter/20200926-090303/train/events.out.tfevents.1601110984.18aefa419a69.99.20824.v2'\n",
            "'/content/logs/history_plotter/20200926-090303/train/plugins/profile/2020_09_26_09_04_00/18aefa419a69.trace.json.gz' -> '/content/gdrive/My Drive/Colab Notebooks/unetplusplus/logs/logs/history_plotter/20200926-090303/train/plugins/profile/2020_09_26_09_04_00/18aefa419a69.trace.json.gz'\n",
            "'/content/logs/history_plotter/20200926-090303/train/plugins/profile/2020_09_26_09_04_00/18aefa419a69.memory_profile.json.gz' -> '/content/gdrive/My Drive/Colab Notebooks/unetplusplus/logs/logs/history_plotter/20200926-090303/train/plugins/profile/2020_09_26_09_04_00/18aefa419a69.memory_profile.json.gz'\n",
            "'/content/logs/history_plotter/20200926-090303/train/plugins/profile/2020_09_26_09_04_00/18aefa419a69.xplane.pb' -> '/content/gdrive/My Drive/Colab Notebooks/unetplusplus/logs/logs/history_plotter/20200926-090303/train/plugins/profile/2020_09_26_09_04_00/18aefa419a69.xplane.pb'\n",
            "'/content/logs/history_plotter/20200926-090303/train/plugins/profile/2020_09_26_09_04_00/18aefa419a69.overview_page.pb' -> '/content/gdrive/My Drive/Colab Notebooks/unetplusplus/logs/logs/history_plotter/20200926-090303/train/plugins/profile/2020_09_26_09_04_00/18aefa419a69.overview_page.pb'\n",
            "'/content/logs/history_plotter/20200926-090303/train/plugins/profile/2020_09_26_09_04_00/18aefa419a69.input_pipeline.pb' -> '/content/gdrive/My Drive/Colab Notebooks/unetplusplus/logs/logs/history_plotter/20200926-090303/train/plugins/profile/2020_09_26_09_04_00/18aefa419a69.input_pipeline.pb'\n",
            "'/content/logs/history_plotter/20200926-090303/train/plugins/profile/2020_09_26_09_04_00/18aefa419a69.tensorflow_stats.pb' -> '/content/gdrive/My Drive/Colab Notebooks/unetplusplus/logs/logs/history_plotter/20200926-090303/train/plugins/profile/2020_09_26_09_04_00/18aefa419a69.tensorflow_stats.pb'\n",
            "'/content/logs/history_plotter/20200926-090303/train/plugins/profile/2020_09_26_09_04_00/18aefa419a69.kernel_stats.pb' -> '/content/gdrive/My Drive/Colab Notebooks/unetplusplus/logs/logs/history_plotter/20200926-090303/train/plugins/profile/2020_09_26_09_04_00/18aefa419a69.kernel_stats.pb'\n",
            "'/content/logs/history_plotter/20200926-090303/train/events.out.tfevents.1601111040.18aefa419a69.profile-empty' -> '/content/gdrive/My Drive/Colab Notebooks/unetplusplus/logs/logs/history_plotter/20200926-090303/train/events.out.tfevents.1601111040.18aefa419a69.profile-empty'\n",
            "'/content/logs/history_plotter/20200926-090303/validation/events.out.tfevents.1601111093.18aefa419a69.99.82370.v2' -> '/content/gdrive/My Drive/Colab Notebooks/unetplusplus/logs/logs/history_plotter/20200926-090303/validation/events.out.tfevents.1601111093.18aefa419a69.99.82370.v2'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rb5sNuy5dHjc",
        "outputId": "57a96b7e-e3a1-4969-ead2-2e4c03d1101d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# Summarize CLR policy\n",
        "plt.xlabel('Training Iterations')\n",
        "plt.ylabel('Learning Rate')\n",
        "plt.title(\"CLR Policy\")\n",
        "plt.plot(h['iterations'], h['lr'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ8AAAEWCAYAAAC5XZqEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOy9e7xsWVXf+x312FX7nL336ab7AE13YzfSSBrjKy0+ojdRRBpFG28wNvF6UVE+SUDj46OB3IQk3JArSQx+NJCIQiTE0M0HfByxlRi46sVIw0HQ0EjLoVH6weP061Sdc3btXY95/1hrVq2qvR5zzTnmfpyzfp/P+Zzaq1aNmrXWmnPM8Ru/OaYYY2jQoEGDBg32E62DbkCDBg0aNLj80DifBg0aNGiw72icT4MGDRo02Hc0zqdBgwYNGuw7GufToEGDBg32HY3zadCgQYMG+47G+TRocMQhIr8vIj+Uvv5eEfnvB92mBg2q0DifBg0qICJ/T0ROi8h5EfmsiPyOiHxD+t6/EJH/WvC5vxSR7fRznxORXxGRjZLv+X0RGaXnPywivyYi19RpqzHmV40x31rvFzZosP9onE+DBiUQkZ8Afg7418CTgKcCbwRuczTxHcaYDeArgK8EXlVx/ivS858BXAG83qfdDRocdjTOp0GDAojICeA1wMuNMb9mjLlgjBkbY37LGPNTdWwZYz4HvIfECbmc/yjwLuBL07Z8vYh8SETOpf9/fUGbv19E3p/5+1ki8nsi8qiIfF5E/omIPFlELorIVZnzvkpEzopIt87vatDAF43zadCgGF8H9IFfDzUkItcBzwfOOJ5/NfB3gI+IyBOA3wZ+HrgK+PfAb2edR4GNTeB/AL8LPAV4OvDe1BH+PvB3M6d/H3CHMWZc42c1aOCNxvk0aFCMq4CHjTGTABu/ISJD4H7gC8A/rzj/50XkceBPgc8CPwF8O/BJY8zbjDETY8zbgU8A31Fh6wXA54wxP2uMGRljhsaYu9P33gr8HwAi0gZeDLzN4/c1aOCFxvk0aFCMR4CrRaQTYOOFxphN4G8DzwSurjj/R40xVxhjrjXGfK8x5ixJ1PJXK+f9FXBtha3rgU8VvPebwM0iciPwXOCcMeaDFfYaNFBD43waNCjGHwM7wAtDDRlj/gD4FeDfeXz8IeCLVo49FXiw4nP3A08raM8IeAdJ9PN9NFFPg31G43waNCiAMeYc8GrgDSLyQhE5JiJdEXm+iPybzKktEeln/vUKTP4c8FwR+fKaTbkLeEYq+e6IyPcANwPvrvjcu4FrROTHRKQnIpsi8jWZ9/8L8P3Ad9I4nwb7jMb5NGhQAmPMz5LkXf4pcJYkmngF8BuZ014MbGf+5VJdKYX2X0gcWp02PEKSv/lJEirwp4EXGGMervjckIRS+w7gc8AngW/KvP9HwAz4E2PMKq3XoEFUSLOZXIMGly9E5H3AfzPG/PJBt6XB5YXG+TRocJlCRL4a+D3g+jRKatBg39DQbg0aXIYQkbeSrAH6scbxNDgINJFPgwYNGjTYdzSRT4MGDRo02HeELJ478rj66qvNDTfccNDNaNCgQYMjhQ9/+MMPG2NOhti4rJ3PDTfcwOnTpw+6GQ0aNGhwpCAiwdL8hnZr0KBBgwb7jsb5NGjQoEGDfUfjfBo0aNCgwb6jcT4NGjRo0GDf0TifBg0aNGiw74jqfETkVhG5V0TOiMgrc97vicid6ft3i8gNmfdelR6/V0Selzn+FhH5goh8bMXWE9Ltgj+Z/n9lzN/WoEGDBg38Ec35pLsjvoFk6+CbgReLyM0rp70UeMwY83Tg9cDr0s/eDNwOPAu4FXhjag+SPVFuzfnKV5JsEXwT8N707wYNGjRocAgRM/J5NnDGGHOfMWYXuAO4beWc20i28wV4J/AcEZH0+B3GmB1jzKdJ9r1/NoAx5g+BR3O+L2vrrShsAKaFT35+yAfueySa/Qcf3+Z9n/h8NPuPX9zlt/70oWj2dyZT3vGh+4lV6skYwztO38/OZBrFPsBv/elDPH5xN5r9933i8zz4+HY0+x+47xH+4vPxSrx97MFzfOQzj0Wzf9/Z8/zRmdIdJoLw+cGI/37P56LZH47G/MZHqvYG9Md4OuPOD32G6ezwlFOL6XyuJdn7xOIB9m77Oz/HGDMBzgFXOX52FU8yxnw2ff054El5J4nIy0TktIicPnv2rMvvCMZzX/+H3P6mD0Sz/8I3/BE/+Cunow3eP3bnR/mRt3+E+x+9GMX+L7z3DD/9rj/jdz8Wp3O/557P89Pv/DN+/r2fjGL//kcv8iNv/wg/esdHo9g3xvCDv3Ka7/yF90exD3D7mz7At77+D6PZf8EvvJ/veuP/jGb/m3/2D/jeX747mv0X/9IHeNnbPsx4Ooti///69Y/xY3d+lHseOhfF/lve/2n+8bv+F+/88P3VJ+8TLknBgUlG4dyR2BjzJmPMLcaYW06eDKoOcWhwdrgDwPY4zsz+M49cjGr/84MRAI9vj6PYP7e9m37PThT79rp85pELUeyPxsmA98iFeJFVg3Lcdza5t8PRJIr9+x9L+9hunD5mx4hHL8TpYz6I6XweBK7P/H0de/ecn58jIh3gBMlOjS6fXcXnReSa1NY1wBe8Wx4JsSuID7bjdAyL8ztx7R9VxL4ug1HcAeNSqmy/O4kTmVgMIk2QLHYjRVaHETGdz4eAm0TkRhFZIxEQnFo55xTwkvT1i4D3pVHLKeD2VA13I3AT8MGK78vaegnwmwq/QRUXI81qLIaRB6lYsz6LWaRBMHZ/jn1dYt/X2M/lfuKo94HY9g8TojmfNIfzCuA9wJ8D7zDG3CMirxGR70xPezNwlYicAX6CVKFmjLkHeAfwceB3gZcbY6YAIvJ24I+BLxGRB0TkpamtnwGeKyKfBL4l/ftQIfYMNrr9yLO+85E63vmdo31dzkWOaPczshpFom4tBpEH76Pex2JHhnUQtaq1MeYu4K6VY6/OvB4B313w2dcCr805/uKC8x8BnhPS3hjIdrzhaMI1J+J9V7SOJ8l/sWZlVoETy761O4uk9LH2E6FmDPv7N5s3xqj/jguZyGo4mtDvtkvODkP8axXHvr3isfrAxdTpx74+dXBJCg4OE3YyM43Ys5po9tMxO9aszzrNaPbT6xLLOdt2x8qdRJ/NZ54bK26IZT/GPc5OKmLnPWPZn8XuY/M+0DifywaxO152wIs1SI1nyYAUy7nZ6xLP/v44t0mkyCp7XWI4uOx1iXGNluxHuMfDjODjqFLbF9LfEMu5zftAZOdcB43ziYysQ4gRUmdnqrFCatvu2LRYPPvjyPb35/pAHLn7cOkZjeAcIveBbJtjtD+7MDPWBG/xDMXqw2kfiJz/rIPG+URG7Fnfsn39jmGMiR6yx7dvZ31xI7fhaBw/Molwj7PXJYa4IXb0n70mMa5PVggTPfqP3ceayOfywXLHi9uxY8yaLuxO53x0rJn9IHJkknUOUeyn92BmlpPr2vYhzm8YRI58BkuRSYQ+EDnyid3+8XQ2l7vH6wNxIysfNM4nMrIPUxw+fZL7WgvDyJHbbGbmizRjzSrnlMbOJIribRh5Zhz/GYo7Qdrf6xPXucW4/ucj319Y9OPY4pU6aJxPZESnTGLTettxO8b53QlmrvSJNOvbtmq05PvU7e9rwj5G9BzXOcSn3faxDxxB6nx3MpvnhgfbcahhHzTOJzLsrOwpJ/pRk7nXRLOf2EzaH29WfM2JPud3JupVd2czw/ndCU850V/6Pk0k67fi2rftjzF4D0fj6O3vd1tccawbVXDwlBP9qNH/NZH7QLwxYtH+ycxEkdP7oHE+kTHYHtNpCSe34nQMOxO79or1qJTDtVeuR50VX3vFOqBf5WC4k0RW1165vvR9mhhsj+ftj2bftj/KPZ7wxM0enZZEi9w2+122+t1IkUM6eF+xHpXavjaW/e1MHxtN1COTbPuTvw9H3qdxPpExGI3ZWu+y1e9EDdmvi+YcFg/uhd0pE+VCabbN110Zp2OsOjftazSZzriwO804hzj3OLZz21rvsrUeyTlsT9jqd9ha70SbgB1ba3Pl8bWoE6RofWy0eEanM6Neay/r3ODwiA4a5xMZw9GEzX6HrX43Gu3WbQsnN3tRKQ374GpXcLZtjjV4r9rXvkb2eljnEIuWuXqjx1q7Fe0eb/Y7bPY70dRom/0um714fSBm+4eZyOp8BNHKIPIzOlyJfGLXCnRF43wiY7A9ZqvfjTrr20opje3xVH2zqyylkXyf7m9YzPqO7Y999chq9fro2rcy3CQy6USjlewzFM2+bX8k0U3c9o85vtbmymNrqZxe+RndjvyMrkwgG9rtMsFwNGFrPW7kYykT+7cmBqMxvU6Lkxu9+d+asO29LhIlsNd+HOd2crNHr6Mfmdgc2NY8eo4T+VjnEM1+5Ojf9oEYkUn2+tjv07U/QQSecoUVfWj3AUsbHpt/32FA43wiYzAas9nrstnvMBrP2Jko87kZygT0Z96D7UlCmfS78+/TtZ8qla6Ik1DfY1/7+qTXI7kH+jPvhf3kGdJu/85kymg8Y7PXYbMXL+djn6FYopiE2u5EkdMn7e/E6wOjMRtrHU6kE0j16H97mXaLXeDYFY3ziYzBdhr5xIpMMrQbxOkYSfutc9OPHPrdFldvrKX24wzeVx1fY73bjka7zanVSAPHXBAQKTKMS+stnqEYcvo9fSDCM7RsX/8eZ9mLGH1YhKhyeh80zicyhjbZ2o8Xsm+td6La38x0vBi02Fa/y0YvXvsBNiIlpO31OLHejRL5WPtb0dpvnU8ys9e2PxpP2Z3M2MpEz+py+ozgwP6tbX9rPduH9e/xEnsR4/r0Ohxba9Ntx5HT+6BxPhFhZbixZ2WbvcysSZ12W/D1yffpRz6b/Q6ddovjazEik3Ha6VpRIgd7PSztE+P6JPbjrJOx9jZ7if2Lu7qileFSzsoOrnq/wRizWM4Qqw9YWi9iZBJ1jNhOJsAikkyQGtrt0oeV4WZptxi0T1T7acfeiJRTsrNKSKgf7Vml7dhAutYqTuSz0evEaf/28jMUm3YD3cjEtjfrHM4pPkOj8Yzx1KxQz7Go7UjUc9qH+902a51WlAnSvI9FkqP7oHE+EWEf0li023g6Y3s8jU/r9Tu0W8JGT//BtbMyIE2ox6FkEvtxnMPxtTaddiuKc1sSHPQS0cruRC8yWRVMZI9pYJiJDGM8o8Ol9uvTYsaYDK0XiXreWfSBGM7BRm5AFGrYF43ziYj5rC9LWynO+rKUxsZaB5FYtFsmcogxK0s7Rox1GjZyA9LIQb9jL2aVcWg9EdjsZUUret9hnxdbhSM5phj5WPuRRDF5kZVmH9geT5nMDFvrXdY6LfrdVoTIaqUPxOzDkeT0PmicT0TkdYwYs76t9S6tNDLR7Bg7kyk7k1lUWmyYGbxjJdQXHbsTp/39xfVJKgjryemHozEbvQ6tlkRZZ7KUk4ng3JZovb5+Hxhk2h8nslqoGUE/ek4iq0wfWNcXfVhREsRxbr5onE9ELGi3DsfX2rREedaXofVAf+adpUzs/5qz4mSX1AUtFkUQsETrdRls6xZuzLY/xuCXzIrT9vfiRA4icHwtq7bSj0w2+1m5vn7kttnv0m231OX0C/uLCYxmH7CbNS7Zj5j33Ixg3xeN84mIBe0WR2mSpfUgHbwjUSb2f80Hd2cyY3c6W7Kvz3dnZn3rHXanM3aUcyZZ2g2UabEMX7+glXTv8aaNrCIk7LPPkJXT6zq3pK0nMvdY9fpk2AX7fwznttTHFMcIu1ljltZraLfLAHtDdl1aaZFszdqPG/noUibLztOu4NeKTCylkY18st+rgWVBg/46jeHKrNUe07M/WYqcQT8v2W4Jx1JRxvG1duQ+0GW4o+/clhP2+rTeZqQxwm7WOL/H6/pyel80zicibCfe6MdJqGdluAv7R2nWt8gH2P8nM8O2Us4kK8OFhZPTnhlncz6Jfd1rtIjc4tBu1u5GBOdpIzcRAWx0HuEZiiSn3xuZdBjGYC/W41DPC0HJ8gRJe6GvDxrnExF2ZXG7ZTueriBgr3PQjXz2duwkZNeKTIajvZRDclznGuV17Oz3hsLKcLPOP7EfybnFyCllBBntlrDZ036GFu0HfdpnMBrTbQv9bjKUaYti5oKGJecQ17lpyulX2ZdYZbh80DifiMjy9UCEnE8iw91Yi6Nkya6hsP9rbna1l9LQTUivUjJbyjP7i7tTpjOzRJkk9uPQescjyOmzggzQF5Vk2z+3r3p9Fqv3E/vatNiyc9Bv/15aL/u9ocgKMrLfE2Nri7ponE9E2B0iLdRnfdsLGW5iv8NQsaR8Hu2WPR5sfzuu/XPzyG05MtEavAerkZsy7bYqw22lkYl2zsHO6iEC7TNaiXwiULdbGeemvWPwYHvCWrtFr5NGVn1dOX0ee5Ec14r+90ZucDh2M22cT0Sszvq0qwbbopwWm/0uRnGzq+FoQkvg+Fob0KeV8gQZoNfx9kQ+ymuthisd28rptexbGW7UwXvVOSivY1l1bjFEN5sr10ebGt5az+SslKnP1chHWzFZRG03tNsljtWOvdnX3exqldZTnzVtr1IaurTYYIXW049MlmW42rTYKqUxl9Or21+lbnXu76oM136XupR7xblpU8+rzk1TTj/IqAEhTvTf67TodZIJ3lyRqXQPVp+hWJWzfdA4n4jIFs0E5ptdDXf0HqxVWs8eV7GfQ8kkx/VmZVaGm9jXnVWuJnPXu206LVHMKS3TeqBbvmSVkrHfpXX9rQx3yf66vlR5OXJLaEOtyCRP0GCP69nP0nr61O3y9dedIK1KuWNV/vZBVOcjIreKyL0ickZEXpnzfk9E7kzfv1tEbsi896r0+L0i8rwqmyLyzSLyJyLyMRF5q4h0OGDsiUzUQ+rVWas2rTSer6pP7Gs7h8myDFeZEljteElkou8clhL2iruBrlIy9ru0nfMeQYDSrHuaRlar7Z8qyunzBA2gS92uCjLs92pgsKf9yoKDUbJZ41qas9rspaKVSznyEZE28Abg+cDNwItF5OaV014KPGaMeTrweuB16WdvBm4HngXcCrxRRNpFNkWkBbwVuN0Y86XAXwEvifXbXDCX4fZzZjVaIfWeZK4yLba9EvnEmPVl2t/rtFhrt1SvT1aGC7o5k9U1FPa1uv3VyEHx/u6xn+Z8NCITu5YkPzqP1QeUabHI0f/eyE15jNheHoNaLWFjTb/GoQ9iRj7PBs4YY+4zxuwCdwC3rZxzG4nTAHgn8BxJpsG3AXcYY3aMMZ8GzqT2imxeBewaY/4itfV7wN+J+NsqYWW4eYO3auSznp2VpfaVaJNBwaxPb1a53LEXkYkerZfNWYGu4nBR1DKOonFYMHirJ6NXaJ+ZScQOoVitYAG6VRom0xkXd6d7ckqJfb3IZyti5LMauR1f66SiFaV7vLNM64Fd6HsJRz7AtcD9mb8fSI/lnmOMmQDnSBxJ0WeLjj8MdETklvT4i4Dr8xolIi8TkdMicvrs2bMeP8sNuZSMYu2s2cyWjlmWmYLerGk1ctPe7CqpK5bTMRRpvezAB4sSPir2R2PW2i363XbGvh7ttirIAF05/eo6q+S1XnSb1wc0I4dVtSFk+4BedJhHncfK+WhXp19tP+iX4fLFJSE4MAlHcDvwehH5IDAEcqduxpg3GWNuMcbccvLkyWhtyqU0FGmxC7uTPTJczYHD2sl2bLBqpTiRT2Jfr2OsduzEvh7tltt+TcFBTk5maz2R059XkNOvynCzrzV+w2r5p8S+3gRpdZ1V8l16zs1u1pi1f2ytTbslihOw5Qke2MhEL7rdY1+5zJcvYjqfB1mOPq5Lj+WekwoETgCPlHy20KYx5o+NMd9ojHk28IfAX3CAWK0OkLzWo93yZn12sysNNd1sZji/uywzhQjOYcW+ZuSwSmkk9nWdQ177hzsTpgqRyXA0od9dyHAT+3q0z+oi36x9nchkr3PQLO6aL8jQuz55tKe2aCVxDqvPqGL0v0LNg80bXtq024eAm0TkRhFZI4lMTq2cc4qFMOBFwPvSKOYUcHuqhrsRuAn4YJlNEXli+n8P+MfAf4r42yqRJ5PVzJnkURqgt45iuJPKcFc7hiotNt7bfsX6d3nOQXNWuapUgsX10ijcuJpzS+xr0mJ7B29NKW5uTkxxLVqe89SU0+dFnqDXx0bj5c0aF/Z1RSt7J2C6cnpfRJMjG2MmIvIK4D1AG3iLMeYeEXkNcNoYcwp4M/A2ETkDPEriTEjPewfwcWACvNwYMwXIs5l+5U+JyAtIHOp/NMa8L9Zvc0HeGpBuu8WxtbZK5JBH64HezD6vYyffpxP5TKYzLuxO99BWmz29hHpeZLXV73Jhd8pkOqPTDpt7DfNovQztc+JYN+9jzsjLWWlWaRiOxqx323Qz10FzBX+uGlAx+s+j3URkXuUghn3Q62N5YwQk9/iBx7aD7ecpbu33HYbIJ+paGGPMXcBdK8denXk9Ar674LOvBV7rYjM9/lPATwU2WQ2rq98ttNZR5NF6oCclLuwY/S4PPR7eMc7vLK/BmdtXpASKaDf7/VccWwuyP9gec82J/tKxLUXaKi/y0awykZ+M1qfF7CZyoCunz4vc7N+xaD3Qy5msln+y0BLF2M0a88YIK6fPKkH3G5eE4OAwoqhjaD24ebTe3L6iUmkvbaVDiy0it73XZ3scvtnVOJXhFkYmSoNfXmQFSpFDHl+v6BzyBBmqOaXRmOPpJnIWSWSi4xyKo3OlPlBkX2mCtFr0c25fa4woaP9mX09OH4LG+UTCYDROBQDtpeNalEBRZKJNCeTlHFQpk0iD3/lC56+bUC92bkr2o9Jue2m9frdNr9PSa//6XupRq0pDXmQFeorDPMEB2PbHi3y21nVqQA5K2As4+BI7jfOJhDwJJehRAkW0nhbtlsfXJ9+XbHa1MwmbNeWtYUm+T6djFPP1OpFDUlZ/xmYvn9bTig6j0m45tF7yHVrP0F5aD2zOQan9mc0aLTZ7uuxCPnuhGf3vzcloyOnL+kC/2+KiUvV7XzTOJxJsKfZV6NFik6WaTcv24yVbtWbeq9spzO0r0VarW3TP7SuVOMqrDgD6CfXVZ6jbbrHebavlNPIiEzVqNUfwkdjXc26F7dfoA9vjpc0as/bPK8jpV3fandtXikzylmMAfNtffzKf+L+fz9OfuBlkPxSN84mE1VLsFnq0WNGsNSkpH7rZ1ZzSKEjYhzuHYiURhEcmhYIMJedQlNPb6Os4t9F4yu5kVhg9a6nR8iITrbVWeYKPxL5mH8hvv47znyxt1pi1D+Fy+jLBQfK+Th9btX+QIoMsGucTCaul2C3srC+0cGOeDNfah/DBe7A95tjasgwX9GZlhcnWyLTbImEfx3laOX2488zn60EncjDGFEcmfcXIJy8yURTF5Ld/IaePY19ngjTYXt6scW4/ch84LGicTyTklbWA5EEYT03wZlfFHVtn1lQ0a9Wj3ZKOsZosVpv1VUQmoTPjomQ06Igyimi9xH545LAzmTGemnxqeF0roV6c99QSBOQ/ows5faj9IsEE6ETnq4VvQY96LqLdDgsa5xMJq6XYLbQSxkW0nl5kku88tWixwfZkjwwXdCO3rD2Lti3cGEiLFSWj7bFw+/nOMzkWHjkUUTKgswjRGFNI61k5/W6kCZjWbqCF7VfKG1aOEQp9oN0S1lcUt4cFjfOJhLzSLqA3uA4LaT0dtVUZZQIaydB8+xtrOptdDUYTRNijRgOd8iWlkYnCbqBFtJ61r3F9Evv5ziE08tkeT5nMTOH1AYW8WxH1rDV4F0RuWmutKscIBcHBVr9zaHI8q2icTwTsTJKaTUWzYtAZXMtmfRq0Uln7w2mx/I43Lymv4Nw21vYmi0EnIV20SDaxHx45lNF6GiXxi9ZZWfs7kzDRSpGa0drPnuODpHRMsVQcdGixIsVq8n4calu1j+Xc38OCxvlEQFU+AHRosSJKI7EfTjnkDRx2sysN2i2v/aCzwrtIhgs6UtzBKJHhHl/Lvwfhs+5iWk9DTr+IrOLk9YqKcibfGe4cLuxOky1FcnNWSrRYYWSiRZ3n29eS0xfRhocFjfOJgLJZ34n18FlNlQw3sa+RU9r74LZaorJCPW+HRQuNhHSRc4aUVgqkxYajCZs5MlzQWWFfTruFy+nLnlENOXpVZJVtg5f90pxVePtnM8NwJ5/WsyIZjXuc137QeYaKBB+HBY3ziYCyWZ8GJVAmw9XY7MpSGmXOITzhXRL5KGx7UKQ2BCVBQMnAYQUBIXL64WhCuyUcW9ubLNZ4hoq25EiOhVPDZYIJjZyGi/MMaf+F3WRLkbzr02m3OK4kpy9SomlUmSibgB0GNM4nAspmfRq0WJl9EQlWK43GqQy3aFam1DHK7GtUOCjq2BrrZMr49K1+l8nMMBr7q7nswJGXLNbYDTRvl9G5fQVBQJVgAnScZ177Fwt9Q+yXy5RDJ0jTeWRV9AxpTJCayOeyQ1EpdoB+t0W3LUEdu2zWl3xvWEK9qDqARWj5lfk+I0UdW0ONtlNCaaTOLSQyGeQU5ZzbnysOw+5x4cCk4ByGozGdAhmuxgSpbI2JBu1WVB0AEjn9Zi+MtsrbhTWLUGp4saVIsXPTWCvWCA4uM5TN+pJteMNm3mW0HoQ7h7LIKvnesFnfxd0p05kp4bs11rEUO4fNfofpzHAxoKR8Fe1mzwmzX+ycIZQWK46sNNaZlK2un8vpg65PMfUM4QV8rf2yCYxGHy7tYwH3127W2NBulxnK1G4QHlJXOode2OB9rqJjh9Ji1ZFbJ6ikfFXOSoP2qYrcEvth97iMloTwnEnV9Qmj3SastVv0OnuHmLmcPuIEKXQCU1TV3SLYuVVEVqGVv21k1dBulxkGo3FuzSaLcFqsKmTXoRyKZ/Y6Ha9MjZZsduX3G6wMt8i+itqqVNCg49yK268jhS6yf3ytncjpg2i34sgKwiOHqj4QSotZNWRZdK4zASu+xyHU8CJyayKfywqWkinseKG0WAmtZ4+HOYekbSdKkq0hkUkV5bAVKEd3uT7Z8+piNjOcL5Dhgo6cfrBdFrlp0PNpCxgAACAASURBVGLFOSVLDYdJrYsjK7CRSdj16XVa9Dr5E7xwWqw6+teJrIrv8e505l0DsioyPAxonE8ElM1aIbx8yWA0LpThQvhOkWVrKIDgza5cZn3gP7iWyYghfBHl+VSGW6Z2g3C1VZFzWO+26bRCRSvFkRvoTJCK7i+EV2ko2gjPIjQyqeoDNrLyjkyq2AulPtDQbpcZyigZCF9nYp1bWWR1fmfiXVK+KicTOrhWOodAtVVVNd/QhHqV4CPUeU7TyKrIfhKZBOYNS9ZZQXjesKj0jUXobqBFRTktQqnh4U7+Zo0WW+uJnH7bc6Gvi5oO/PvAJUG7icgzROS9IvKx9O8vE5F/Gr9pRxdVHUNDKVM6a03f8y0pPxiN6baFfreo4wV2jMo1FGFVGmLTblXOeSGn94ysKgQr9r2wnEm5DDc0b1jZB9bDEuoufSAsZ+LWx2I5h1BRjO07J4447fZLwKuAMYAx5s+A22M26qijTIYLyYN1MWCzqzKlFYQn1Iv2GbEILV9S5RxCIweXZHRiPzCnVNCxk4W+/pHDgjKpom792m9luFWDa7Bzq3QOcQQZkDi3EDl9mRoQwstYDUfJZo2rW4pYhBYvHVRMkA4DXJzPMWPMB1eOhe8EdQmjqqZSqHMYjMZs9sqdG8A538GvZI0MZJ2Df/vX2i36BfuMhK7gr0q29rtt1jqtAD69mtLYDNgNtIqWnNsPjNzK2x+aUK/Ke3YYhohWKiI3jbxhuXMLt1/unMOqNNjPbRxl2g14WES+GDAAIvIi4LNRW3XEMSgoxW4RnEwsKR0DCjmNymRuWMeojtx0Iqsq0Yd/Tqk6mRuyQr2s9M3cfkBkUrUOzX637+RoPJ2xPS6PrDb73SDRStUEKZwWq87bhtmvitzCo/+NXod2TuHbwwIXt/hy4E3AM0XkQeDTwPdGbdURxmyeLI4X+bgkc8Psx3cOZe1f67Tod1vekcNwNCmV4UI6847o3MIik2rnFrKOpWqdVfJel+HOhOnM1B7AXCKrrJzehxqqovXCabEJ1z/hWOH7oRPIsqruoMSOHOKoB9wiH2OM+RbgJPBMY8w3OH7ussRwJ5XhusxqvHMC5R32RKh911lfiHOr6BghOQGXTbQ2A3YDXQyu1QlvH7jw9SEr+F1kuPb++IhWqnJi2e/2+Q12s8YqQQYE0mIVkWFyXpzIzcrpQyYwhznfA25O5F0AxpgLxphheuyd8Zp0tOFEyQTkTKwMN67goJwS6LZbHFtrx3UOAVLior2IsgiKfEZj1tO8UbH9EFqsvLSLtX/BU7TiROsFTGCq1IAQVqXBKbIKjhzKJ3ihopsq9kJEgtYqVVHzhwGFrRORZwLPAk6IyP+eeWsL6Mdu2FGFS8cOycmcd5h1282uYiVDk+8PcA7bY645Uf4IhUiJqyI3SAaPhx7f9rRf7dzCrk/yOXsfi+xDEplccWytnv0akY/PPXCh9ULyhlVqyeS7/Z2n3ayxrP29Tou1ditoglTlHELWKg1GY560dbiH6bJf/yXAC4ArgO/IHB8CPxyzUUcZrslo8Ox4DjLc+WZXHh1jPJ1xcXdaGZmEJryrnVvXX603mlSubwhZwV/F1yf2u2yPp4ynM7oFctoiDEZjjpfIcK19SBxVXefjEpmE5A1daLcQNVrVOrHEvj8t5lKaZr7Q16P9xhjnCVKIqOemJx7uyKfw6TbG/KYx5geAFxhjfiDz70eNMf/TxbiI3Coi94rIGRF5Zc77PRG5M33/bhG5IfPeq9Lj94rI86psishzRORPROSjIvJ+EXm64zVQxaBGZOLVsR1rNvmqrc47UBr2/ZBkaLVz6zAM4Lur2x+mRqvKWYVQny77sIREzy4y3JDIwUlNF3h9oLyPhcjpq8o/WfjSYqPxjEnJliIWsfvYQcNlSvYREXm5iLxRRN5i/1V9SETawBuA5wM3Ay8WkZtXTnsp8Jgx5unA64HXpZ+9mWQh67OAW4E3iki7wuZ/BL7XGPMVwH8DDqQKQ1UpdlhsduU3cLg5B9/IxLUmlC8ttjuZMRrP2CyhlBb2Q5K51c5tNJ6x61G4sUqKntj3zwm40HohaqvBaFwpww0p7uqqpgNf2s1tAaWvnN6F1kve91M0lu3Cumzfr4/ZzRovBbXb24AnA88D/gC4joR6q8KzgTPGmPuMMbvAHcBtK+fcBrw1ff1O4DmSLKu/DbjDGLNjjPk0cCa1V2bTkOSjAE4ADzm0UR0uszLwnzW5OgffWVMd5xYya3USHATlrKqdW7Y9dVC1+j1r32vwc8i5hTgHV7WhbUtdDLbHiCSbxhXByumHPmo6B+cGdq1SHFov+X6/6LmqaKmF71oru1njpaB2e7ox5p8BF4wxbwW+Hfgah89dC9yf+fuB9FjuOcaYCXAOuKrks2U2fwi4S0QeAL4P+Jm8RonIy0TktIicPnv2rMPPqAeX1e/2/VhKIvCPTGo5B69Zn7tzS6KkeuVRbLLYnbbymxm73N/Evt89do58PBP2VQOfpeT8nGeywLFVsT7IN6fh/oz6Rc/uE0i/vOHAkdbzrTLhUiHjMMDF+dhf/7iIfClJVPHEeE3yxo8D32aMuQ74z8C/zzvJGPMmY8wtxphbTp48qd4IW7OpKsnsTYs50HqJfT+1VV3arW7hRhdBhrWfnF/vNzjz9Z6Dt6U0XCifpD1+g4eL4CM51zPyqXh+QuT0LpEb+E+QBtuT0s0a5/Z9J0i1aL0Q2q3avo+cvqqq+2GBi/N5k4hcSZJDOQV8nDQ3U4EHgeszf1+XHss9R0Q6JI7tkZLP5h4XkZPAlxtj7k6P3wl8vUMb1eHC14N/SG0/UybDhQBKoEZkMp6a2ptdLaTo1Xx60p56v6EO7ZmcX+8e7Exm7E5n1c4/oPK3i3PbmCfsIzoHzwmSCy0J/tRwVeFbC1/Rjcs6Kwhpv6ugwW+hr2vO6qBR6XyMMb9sjHnMGPOHxpinGWOeCPyOg+0PATeJyI0iskYiIDi1cs4p4CXp6xcB7zPJVPoUcHuqhrsRuAn4YInNx0jWIz0jtfVc4M8d2qgO1469GSAIqJLhwoISqBuZuMhkIVvbqt5vcObrPSMTd77ez7m58vW+UmIrw626Pu2WsNHzj25dJki+a5Vc2g8hkYPbAsotz+KudrPG9YLCtwv7iZy+rmjF1TksRBk1nY9jHztolLZORL6OJKfyh8aYL4jIlwGvBL6R5QhkD4wxExF5BfAeoA28xRhzj4i8BjhtjDkFvBl4m4icAR4l3aohPe8dJFHWBHi5MWaatmmPzfT4DwPvEpEZiTP6wfqXIxyuKhNvWqxke+UsNvvdeUn54xVR0pJ9x8gqW77kiTUWs9XJKSXn+836XNVo3s6tiq/vdRCpT4ttj6dMZsbpHm95ijJcI5Ot9S7DHT/ncO0V65XnbfY7fObRi/Xtb5dXdbfwdm6plL4qssrWj7tqo+du3zU6947+3diFg0ZZhYN/S7LI9KPAPxaR95Ak9f8fHAd2Y8xdwF0rx16deT0Cvrvgs68FXutiMz3+68Cvu7QrJgajMU84Xr3oz9JixpjKhzwLd+e2oJXqOJ/haMymQzVc34S9s5rOszaXqyDD27k55qxaLWFjrX7OwaV0jIUPtVpHhrvZ7/DI+d1a9sHWFdusPM+fFnOLfDb7HXYmM3Ym09Iis3vtVwsyYJm6reN8hqNJ6WaNFr7Rs0vh28OAstZ9O/CVxphRmvO5H/hSY8xf7kvLjigG22NuuOp45Xlb6x1mBi7sTiujjCX7zsncxazpyRWlbJbsbzvOij0jh+GoWoabte/tHCoGp+NrHVoSMqt0yevVl6PX4euT3UDr2a8jw93qd/nLhy/Usg/u0bn3OpzRmKeWVJye2884h96Gu/Nxp/X8ncOWU87KL294FDaSg/KczyiNTDDGPAZ8snE81agfmdQf/FxpNz/7bnz9Cc91JoPRhE0HGa5vTslVcNBqSRo5xHMOPmuVBjUok61+fVrMVWmVnFM/Z2K3FKmiJSG5PrvT+nL6pI+5T5DqKyZd87Z+fSD2GDEYjdN1VO4O9yBQdgWeJiJZgcCN2b+NMd8Zr1lHE8YY57IW2WTiNSfcv2MwGvO0kw6Rlec6jTqCCXt+LfsOa0wAjq21abfEw76bDBf81irVWUPhk3Ookyze7Hf45Bfi0J7JOUn761DDF3YnzIzj9clQq3UGyiSycrs+9vw6GGxPuOFq98jK5x7XYhc8qG0X53/QKGvhajWCn43ZkEsBO5MZ46kjpZGhxerApSAhhDiHSWXFacjSbvUjH5eOZws3+tBuLjJc8JMS16PdOjz0+KiW/Xq0m0/7a9jvd5nMDKPxjHUHZw7uasPE/mKC9MTqFBGQbCkyrNiscW7fM2/oPgHz78Muzn8jIPo/7JQblDgfY8wf7GdDLgXUSfT50GLzBY6OAx/UnzUNd8Z8yXr1SNDvtui0xIsScJ2V+UQOrtcHLC1Wn3brOMhwE/tdBiOXSlQL1HFu1jnXiUzq0G7ZwdXV+dR1btnPuMCueXGl9RL79WkxVzWgr32X7Q6snN6L2j7kSjdodiRVRS0+3YMWszLcOny3D+Xg0rHtZlc+kYNr2Q+fhbiukWFi38+5bTrIcIF0w7o4ajp7jpXTu6KOms6n/t2C1qsT/btfI9d1aODXBybTGed33HIyG2upnN6HdnN9Rj3yhsMaE7yDRON8FOFaHQDCOrbLg9vvtllrt2oNfklk5ZaTSdrh6RxcI5NefedWZ+96n+KodUrVWynxbOa+0HewPWGt3aJXsktq1j7Um3nXovXS63iuxgTJtfwT+EX/LvtZWfhcn0VkVX19Wnahr0dOxvkZ9ZCj15mAHSQa56OIukooqDfrWyi5XB/cerOmC7tTZsa9JpRP4cNasz4PKbFLaRoLLzWaI19v7Sdy+nr32DWy8sk51Jkg+eQNrfquXnRe5/q4O4fja+3acvo6kaFtRx374+mM7XH1Zo0WPlUmXLaRPwyobKGI/BbJdgVZnANOA79o5dgNFg/uCYfBu9dp0+u0ag3edWg9qO8c6taEqivFrSPDBb9FlK5rTCC5jud3JsxmplL6bVHHuWWlvq7RpKsgI2u/7jPkKsP1kdMvovMaarRa0b97H0hEK/X6wLka9qG+c3Ct62ax1e/yuUG9IdZlM8LDAJfI5z7gPPBL6b8ByX4+z0j/bpCibinzuhumuZZ2mduvSYstZn3ug1+tZPHuBGPcO/aWR0n8OptobfU7GJO0yxX1IjePyKGOIMOLdqvvPOsM3q7rrGAhp6/zDNWOTGrmDetEVon9en2gzvVZ2Hdv/85kymg8OxI5H5cWfr0x5qszf/+WiHzIGPPVInJPrIYdRdTJyUB92se1bplFXUGAa3UAi7qzvrplP7bWO5zfmTCdmcpyP7CQ4foMrq6fqcPX+6itXNdBZe3Xvcd1Ik+o2f7RhH63xZpDzkpEatc4rCPIgPp5w7pFObf6XR58fNvdvmNVd4u6Y0TdCeRBwiXy2RCRp9o/0tcb6Z/1Cz9dwhiOEhluVc0mi7pS4jprKKD+Israzq0m3113Vmnbcd5x8DvvMSuGujmHGrSeFy3mLhX3i0zcZbj9botuu95C37rJ7rrV3e292qhxj30mSCec73HNPubh3Kyc3gVHZS8fcIt8fhJ4v4h8ChDgRuAfishxFltgN2ChhHJdc1F3EWWdNRT2PD/KwX1mfDHd7KpqiwfwcW6Lmf2JY9Wf8cmJgbvaajKdcWF3WjvyqUu7uVRsXrZfb3B1vb8+OZM6tCf40GJumzVabPa73F+jcnZ9Ws+PdqvDjtSpTj/vY47P0EGi8tcYY+4SkZuAZ6aH7s2IDH4uWsuOIJJkdJ2OVz9kd5XhWvt+tJu74ACS332lQyXvurOyujmTupRM3fIldWS4EJCTcbw+/W6btU6rtnNz2e7Aom7esI4UPbFfN/qvF1nVnYDZa+la7Her32FYQ7SyoN3q9wEX53NUtlMAd6n13wCeBXw58HdF5P+M16Sjizp8PfhEJskaGefIqtdhNJ45b3blIzPNfq4Ktfn6mgtxayuJ5s7T0bl58PXJ59zsz2W4UQdXd+cGPhMY95wb+ET/9SOrutTwRq/jFMlDElmZGnL62qIk3z52KdBuIvI24ItJ9vWxS6kN8F8itutIonbHrs0Xu0t2YXkhq8t+I4PtMb1Oy3nvk7q0Um3BQc11JnVkuEk76uVM6vL1czm948BR1/mDxzNUc4JUN2843B5z/ZV1Iqv60XmdWf1mv56cvs46Lliu0uByXQejCSLJxNAFdScwdantg4TLFbgFuNnU3Y/5MsRwNOaJmxvVJ6bYWu/W2uyqDl8PyzkBJ+dTo7oBZCgBx47hI+XOfq4KdRZQZs9zdQ51IzeolxOo6zwBNmvI9XcmU3Ym9WS4W/0uXxjsOJ/v4xzqOc8JV21UU7wWVk4/3Jk4iQjq0nrZCYwLnTnYHrOxVr2liEVd6rlu9H+QcIktPwY8OXZDLgXUkeFCfSlu3cVjdQs31o3cfAbv9TRP4YKFGs2149VzDt12i/Vu24N2q3eN6tOGde5xx7n9PvmA2ssBatJuW+sdLqSiFRfUrdhctw/UKUy7bN/9Hte9/nXsD0bjdEuRw+98XFp4NfBxEfkgMJ8CNfv57IVPMhSSwfVqp8hkUmtX0kVk4vjg1pTJ1qXF6vL1Nunr3PFq7FVjUUeKW9e52XPrCibq0W5dHnIUrfjReu45pdF4yu5kVts+JGKOK45VRzT1c1aZvOGV1ecPRmOeuFmnj9WkxWrUHoT6cnqbs3KNrA4SLlfhX8RuxKWAyXTGxd1pTdqqZuRQew1FzZyMh1rPtsvNfr3IrdNucXytXWvwPrbWdk4WQ13n4BGZrHfnJVsq7XvQbnVKHNUtn2TbcnF3yng6q5Q311VLwrKopMr5GGO8RD3ZtlVhsD3h6SfrRLb185J+fbjGGHEElG7gJrVu9vVxgM/irrrrTOorferaH3NdjWSxT2RSt+BhnW0PfDbRqqO2su1wXeBo7T/guM7EJzKpU/+urtIq25bhaMITKuT0PvmGOjmN0XjGZOa2WaNF3SoNdaq6w+K31qHdnnKFe2RVV05fN297kCicyojI+9P/hyIyyPwbishg/5p4NODH17vTYj4y3LpS5brb77ZbwmbPPScQ3zl4Orcazn+j13Eq9TO3X6M+nU/ksNV3l9P7TJDq5Ex8Iqs60bkXLVmDFjPGeOQ960f/dZ1DshbKXXRzFMQGUOJ8jDHfkP6/aYzZyvzbNMZs7V8TjwZCOoZLx/ZJFtvNrupEPnWdQ53Ch3UqNs/t16DFhjv1KYc6OY06ddHm9musM7Ey3I0ayeI60a0v7ZZ8tvoahTk3F/s+ztn9+myPp0xrRlZJhfAWw50aggOPZ6iOYvKo0G5O5LiItEXkKSLyVPsvdsOOGrxksjX44rprZCDZ7GrTcbOr0TiV4dZ8cOusA7F71dRBLedWM3IDn/bXd267kxmjcfVuo4Ptce1kcZ2cgB+t5z5B8qH1TtTIG57brk/rbdS4PnV2Yc3CtUrDbGa8tjvYrBE916XmDxIui0x/BPjnwOcBG9sb4MsituvIoe4aE8hsduUwq/RZY5K0x61j+AxMtj0uzjNJFteT4dr2fOrseadzB6MxN159vJZ9S7sZYyorR9QpfTO3n8kJVO2hU1ctmdh3H7x9ZLh1EvZ1q7pDPefp49y67RbH1trO1wfqVwdwlaNf2J0wMz59zH2C5PMMHRRcrsI/Ar7EGPNI7MYcZfg4B1u4sQ7t5pfTqEFpeDgHl82udiYzdqf1ZLi2PXVkpj4Dx3hq2JnMnJzDk7bck8WJ/cXgfXKzXE7vM2utk1APiqycaLf60flCtOLeB1w2a8zCNW9Yd68dC9fo3CcvbM93kdPX3azxoOFCu91PsnNpgxL4FvRzlcr60HrgPiuru12DhWvC3ieZDouBo6rAhpXhxowcfPl6+9kq+PD1C7m+Y/tr268R+YzGtFvCsTW38kyQkdO7RP8eOSt7fr3Irf4EoF5kFWeMqLtZ40HD5SrfB/y+iPw2y4tM/320Vh1BzGW4jjWbLFx3A/V+cPtulbN9a0K5Vj327dhb610mM8P2eMqxErpoezxlMjNes1ZInO8TK2Q0ddcpQV1abFKr4nTWvuszVDuy7SWiFdecyVbfvfCthWsJIh/abWG/BrVd+x67yel9FkEn9h2vj6dzPii4RD6fAX4PWAM2M/8aZDAYjdmsKcMF9/Ir/rSbG1/sSwnYWV9VZOKbs3JVQ/luouUq9TXGRKfF6myhvbDvTov5SNFbLWFjzU1t5SPIAPfIZDia0G27b9ZoUTf6jyXXD6G2R+OkBmQZfJ3bQaG0lSLSBp5hjPnefWrPkYUPpQHJg/gZp1nTuLYM19qPtYYCksF+ZuDC7rQ06gt2Dtvl+Rb/yM0tMrm4W1+GC/VoMR/a7fhaJxGtON7j659wrJZ9sAt9XSKH+jk3cJ+A2eoGtSOrfpe/fPiCk317fh04t9+7jy0mML2NYkrTR4p+kCidQhhjpsAXiYh7GdnLFHVLsVu4UwITNj1qNm31O/OS8mXwfXBdaR9vvt4x57AofVPvHpxwzMmE0J5Q7dx8k8WtlhWtuEXPPpSMa+Tgs04M0j6wEyfnlth3FRxM0nU77jkrSOX002o5vXde2DF69in/dJBwiV/vA/5IRP6ZiPyE/ediXERuFZF7ReSMiLwy5/2eiNyZvn+3iNyQee9V6fF7ReR5VTZF5P8TkY+m/x4Skd9waaMWfCWOrutMfMtmbK0nm12dr9jsarA9SWW49TreYoW3Gy3mk1OC6pyDv6DBzbn50p7H1tq0W1I5cCxkuLGfIY/B2znn4LfGZKtG5OAzq9/sL+T0lfY9J5D286X2PdbqZc+vusc+asODhIvz+RTw7vRc55xPStm9AXg+cDPwYhG5eeW0lwKPGWOeDrweeF362ZuB20l2T70VeGO60LXQpjHmG40xX2GM+Qrgj4Ffc/htavBd3LXV7zLcmTCtiEySNSZ+A1Py+arIwZPScKSV/NdQuEUOi8iqPi2ZfL7KOftFbomcvjpy8FUb2jZV2Z9HVj7UsGPlb/8JmKsazd95jqeG0bi8BJGPWjKx75Z3G4wmtTZrnNuv6dyOCu3mUlj0X3rafjZwxhhzH4CI3AHcBnw8c85tLKpmvxP4D5KMfrcBdxhjdoBPi8iZ1B5VNkVkC/hm4Ac82+2FwWjMM55UX4dhO9P5is2ufKoDQL2EvR9f7067tVvCel1Kw7Hyt69got9t0WlJdfsDZpUukYnvGpO5/arrs5PKcL3a32UwGlaeN6y5066FpcWqFvoOR5Pa66xguUrDeklkHzKBtPbL4FPdANz39PEVTBwUKiMfETkpIv9WRO4SkffZfw62ryVZI2TxQHos9xxjzIRkPdFVJZ91sflC4L3GmNzipyLyMhE5LSKnz5496/Az3ODPRzvO7L35evfIYbMXb9Znr49Psjj5vKtzqB+ZuKiVfPl6cKsf51MdYG7fofK3r9Iq+Ux1zmQ6j6z8nNt0Zri4W6Hm8p2AOecNw5xDJTXsTUu69eHhKNmssWrri8MCl1b+KvAJ4EbgXwJ/CXwoYptC8WLg7UVvGmPeZIy5xRhzy8mTJ1W+0GefEQv3yGTsR8k4JtR9Ix/Xwpa+HbvXabHWbjk5Nx8ZLrgNriFrKFxosaEnLWntOzs3z3s8rMiZnA9IdteKzkNosVj26/SBIPvV99jn/h4UXHrqVcaYNwNjY8wfGGN+kITWqsKDwPWZv69Lj+WeIyId4ATwSMlnS22KyNUk9NxvO7RPDRd2p8yM78DhmDPx5qNrzPo8KZ/k89Ud22fWl0Qm1etM7PWpG1mB2wr1EErDpbyLb+Rm7bs6N1/7Vk5fhBBa0iVvOE43a/QVHIBj9B8UmVTTYj7tn9eArLrHO0dnLx9wcz72F39WRL5dRL4SeILD5z4E3CQiN6ZS7duBUyvnnAJekr5+EfA+k0yvTgG3p2q4G4GbgA862HwR8G5jTHWxMUWEdGwX2m02Mww9azY5Cw48I7dep02v03Ky7ysBdanqOwio5utSvmQwGnvJcBP7Ds7NswKEtV8lpw+R4brQPucCkt0uzsFXbQgLOb3LPQ6j3Sqcg6dzszUgXZ6ho1LXDdzK6/wrETkB/CTwC8AW8ONVHzLGTETkFcB7gDbwFmPMPSLyGuC0MeYU8Gbgbamg4FESZ0J63jtIhAQT4OXpmiPybGa+9nbgZxx+kypC+HqXZOKFgJpNrivsfWk3+x0uHftpV2942Xep6uubzAXY7HU5OyyvnO1TkXtu30UQEDKB6XfmcvqiNi6UUP6iksFozFPIL//jK/hIPlPdB0JyVi6imGTbi5nX4L2Q08fJ24J79Fy12+xhgova7d3py3PAN9Uxboy5C7hr5dirM69HwHcXfPa1wGtdbGbe+9t12qeFUL4eymdNIZSP3eyqzP40jax8Q3aXDdNC9hlxqfztS5mAm5TYp/TN3H4/iUymM1NYfmkwmtDvtljr+OSsFpFD0eAWFp1XO4cwNaBDHwgoHeNCi4Vcn7mcvpJ2C3uGXPrYF11Vb0uRg4SL2u0ZIvJeEflY+veXicg/jd+0o4NQvh4qOnZgwcCqhPQiWezfMVwS9r6RiRst5j+rdFlEORhN2PRuf/K58xX32Lv9Ts5BY/Aucw7Je2XLBQrtO9BivouIIZHTd9vlkUnIOiuofoZG4ym7Hps1zu279IFtf+d2EHCZZv0S8CrS3I8x5s9I6bEGCUL4+o7DZle+1QEsqqTEIR07aVc5LTaZzriwO/WPTBycg29pF0iu64XdKZNp8SLEkI7tkhMIjQyh2jn4ynBdJkghORkX5xZCu81zJqXXP51Aeiw3gGrnMAyc4FXlfIwx3lVQDgouT+IxY8wHV75wQQAAIABJREFUV45VL3e+jBASskN1SB3C1yftKqcEFhWnfWmr8vaf3wmrOeVEaXiuoQC3yCHEublRqwGR4dx++eDnPat3WCdj36u7pQhAv9tO5PSRaDeoLuGzkKL75w1Lnb/CGFH2fO5MZoyn5pKTWj8sIl9MsnU2IvIi4LNRW3XEELqyuKrwoS26GItWCkkWL+zH69hb/S7b4ynjgshkPJ2xPfaT4Vr7UE1b+Q/e1Qtxg2jDufOscG4Bzh+q1WgbvQ4dzwWOVX0gNDqv2jMoJG9rP+cSGYbYd5qgXmKRz8uBXwSeKSIPAj8G/P2orTpiGIzG9DxluFBd2yp01leltgqtCVWlRgtJRmc/V9S5wykNF1rMn9JwqdLgK8MFd6myr30rp6/KS4aUdamilQajCSLJ5nZ+9iv6QGBkUt2Hw5zDZr9cTn/USuuAg/MxxtxnjPkW4CTwTGPMNwDfFb1lRwgJ5eM/46imBAJD9op1JuGRW5edSfFmV74byWXtQ/HgqnF9yuzvTKbeMlxwo8VCaDeXhb4h9sEtbxgy695ymCBtrNXfUmRhv6IPBORtnewH026JnH64k3+NQiPDg4BzjGyMuWCMsdUFnbZUuFww8Cx9Y1ElJR7u+MtwYUGLFZVHCUnmQnVkEs7Xl+ccQuquZdtVNPiFCj5caKuQRbLddov1brucdvNcRGxRlXcLiazAhRbzqw5gUbVOZjhKNms8XnOzRout9U6paCWYdquInn2ruh8kfCvQ+U0/LlH41oSyqFLKhMhwIel4u9MZO5P8jmEHlY1Q51AwuNoO4yPDBQfnFkjruTu3OLThXIYb+gxVOIeQgalSFBMYWVUpJn2LilpUt99vs0YL69jPF0UmwdF5ed4wNG97EPB1PuWbz1xmCOW7rSCgODIJm/VVqZWGozHH1vyr4VapxUJ3WKyixUIjt6rCjaF8fafd4vhaO1rkZttWtBuoleGG025xnVsstSEk7b9YEpkEXx+HvKTPZo0L+xWRz6VEu4nIUEQGOf+GwFP2sY2HHuGzvvLNrsJnfeWzplC+vmqFuu0w3pFVpXMIi0ysPLjYuYXRbvazlQNHUMK+OPKxMtwwQUB5cddQWq8ypxRYsdmFGg5tPyxq3O2xn44RPoVvIdvHqqjhS4B2M8ZsGmO2cv5tGmOOzi/cBwTP+iqq+obSblW0UsgamSX7Rc5tO5HhFpWWqUKVGi00mdtuCZu9Yimr7y6sWZTRYhoy2bLBW8V+v1vY/iSyCnQOvQ6j8YzdImo4cAFlZR8IKH0DDs9oKDuyXj5BGmyP6Xhs1niQOBq7Dh1yhOdkykPqcNqtghLYCefrE/txOvbGWgeRko4XKMOF8oS0xuBdJsUNzSlZ+1U5sVBaqaj92+Mp05kJdp5Q0QcUnEMZLRZKe1bajzhGhEZWB4HG+QRiZzJlJ6BmEyzolnMltFjoGgoomzWFK5WgnHYLmbW2WsJGr1iUESrDhXI5ugalUbZhXWjkZu2XOefEftg9Tio/75XTL9SM4ROYvHs8m5ngZ8hFrq8T/Rc7h1DaM7FT7NyOEuUGjfMJhsrAVDHrCynnD9WzstCcj93sqoxPDy37UaZWCs25Wftl16cVIMOFKlosXKmUSJXz5fQ6tFtx5KBCS5bM7C/sTrw3a1y1XziBCRY0VOeUQux30xqQZVLro6R0g8b5BEOzY+d1jNF4yu50psMXl9J6/varNrvS2GHRDq659hVmfWW7gdrSMSGRVRmtt6gNGDYzLpLTh1aASOwXO4fQ2oaQjUz2XiMNGXFZTmY2M5z33KzRYi5aKYn+QydIZaKSJvK5DKFDyRSH7Bp8/Xo32ewqz74xJlipBOVrlTR2WCxbB6Ix66tK2GtEVoPtfDn9YDSm3RKOecpwrX2I9wyVbXsQWh0Ayp2DCi1ZQrudD9is0WIupy+kzsOdQ2X030Q+lxd0OnYxLaYxaxWRwpzDaDxjEpgshsVapTxo0WJlfHc4rVeek9FwbpOZYTsnZ2KT6SHJ4kXercw5KKjFojm3sshKQZDRS0Qr5X1MIzrf2/7pPLKKF/1rUNv7jcb5BELjwe11ks2ucmd9StVqi9RWGnx9Yj+fEjDGqFACWyXrTDScw2ZpZKJD60FBzkQh8iyLHIajRIbb7/p397Lt2DUEDYsSRPnXB8L6QKslbKzlU6uL6gNxqNv5Zo0atFskUc9BoHE+gdB4cJPIJD9nErrDokWyzqSs42lEJnvtX9wNl+FCuRotVKmU2O8wM3BhN0/NpRO5WVt77KtEbuWRSagMtyxvqOEc5nL6Utot9B7nr1UKreo+t1+wFkqt/QVjhN2ssaHdLjNolbUoSkhrJHOhWM01UKD1oHidiQZfD0n78krKz5PFwde/nPbRinzyaLHhaOy9g6ZFqRotUEoP1ddnre2/pQgkkclmr6gP6EUOZbSehnPLK3EUWtXdoniMOHrVDaBxPsEIrdlkUZTw1uDroThkV3MOBZGVBl8PSfuSyGS581kZrsasEgpoH6Wcj7W1x76GFL3EfmhdNFjI6Quvj0K+oUgxqUWLFUXnms4hP7LSmeDZMWKVGtZyzvuNxvkEwvL1oSuLiyKT0B0Wq+0nx04o2D+/uzcy0cpZFamt9JLF+VUatCKrMlpMwzmUreXSoPVEpHCCFLp636KoeOlwNKHXadHrhE7w4kZWRaKboRI7spXWgFyV02vUBjwINM4nEBodG4qlxFaGG1qzqShnoidoyN/sSo3SKKB99GjP/MhhLsNVEExAsXMIjTz73RadAjm9Bq0HxbSPRs4Nikv4aKgloUR0oxVZpcsNViOT0KruFkX7QmmxF/uNxvkEQqtjF1IC2+EyXEge3LzNrvRot/yZvbpzWKE1Qjeqsyiq/K0XueU7t7kMN2JkoiXDLRbFKDqH3AmSzgLKoh2DB6Mx613/LUUsNvtdpjPDxRXRip5zy3+GQqu6HxQa5xMIrY5dJjjQ6Nh28Fzd7Go4mtBth8lwE/v5M3t12m1lcArdy8eiKKGu1bHncvqVwe+80qwYSiITpQWIRXlDPdotdvvz983SWCcGxdSnVvRfJFrRylntNxrnEwitjmE3uxrviUx0Zn1F6yg0c1aQMytT63hpx94pohzidGwttaGV0xfRhjoz+72Rw2Q64+LuVIWSKVRMqtFuRYIApcinQE4ful2DRdFaq8Eo2ayxExhZFeUNj+IuptA4n2AMFfh6KI8ctJwb5DsHjURlGe221gmT4UIZLaaTLO532/Q6rZz263XsvIT6OaU1JomNvSWOtNSGiY24tFuRnH6osM4qsV/wjCqUf4KSPqDUh08UiG7s9/lu1nhQaJxPIJIFiDoyU9hL+2gVDCyKTLRovaIV/KH7sCzsF10fvchhM6eEj679vetMNNdobPb2RlYau7DO7efQesk2C7OgvZQstta7GJOIPLIYKNF6RVUatKoDFE0gtWi9sjEiZLPGg0LjfAIwmxnO7ypFPgVVfTX5+lz7ipQJ5CVDddqfRE+tHL5bR4YLNnLY2/7kPSVRSZEgQylnkvf8JPZ17vFwZ8I0E5loyYihXM2lE5kU0WLhUnooVkxq0XpFa9G0rs9+o3E+ARju6MhwITtr2jur0egYJwoKN2oli4sin8FowqbS4re8wVsrcrP289oPSjmZElrshJJz2yuY0KT1UtFK5jeo0no5kcloPGU3cLPGvfZzniFV5xYn+u93E9FK3j0+agtMIbLzEZFbReReETkjIq/Meb8nInem798tIjdk3ntVevxeEXlelU1J8FoR+QsR+XMR+dGYvw20Z317Z02T6YzzO8qCgxyljIb9TrrZVa5zUJqV5dE+WjJcaz+v/RoyXMinxbRkuImN7h45vabzzEuozwUTKuuI9uZMVGnJnOg/2VJEK29bnPfUsD/fNysSNb/fiOZ8RKQNvAF4PnAz8GIRuXnltJcCjxljng68Hnhd+tmbgduBZwG3Am8UkXaFze8HrgeeaYz5a8AdsX6bhVbZDMhKiRcdw8qiNSKT+WZXuclWxcgkEu0G+SWINPcxybWvWKq+jBbbUMmZ7I0+VWm9nAmSluAjsbF3gqRLS+5t/85kxu50pnKPe50Wa+1Wfh/QeoZy1iodxb18IG7k82zgjDHmPmPMLokzuG3lnNuAt6av3wk8RxLN723AHcaYHWPMp4Ezqb0ym/8AeI0xZgZgjPlCxN8G6HaMvMhHc9bXabfYWCncOJ7O2B5P1UL2vMhEc1aWt6ePFl+f2M9pv8IurBab/S7b42U5/XA04biCDNfatzaz9kHL+ex1bpqCjDxaTJPWy6OGNasDJAt9l58hu6WIlnPYzKFWm8hnL64F7s/8/UB6LPccY8wEOAdcVfLZMptfDHyPiJwWkd8RkZvyGiUiL0vPOX327FmvH2ahqiTq2ZLyiwdXU4YLexcJalfDLYxMNJ3bKi2mJJiAAkGAkgw3sZ8z+Cny9Vt5tJiiDDdPSqxVwQLyBQdaW34A9Dp75fSa7AXsrdKwPZ4ymRm1CUxe3lCzj+0nLiXBQQ8YGWNuAX4JeEveScaYNxljbjHG3HLy5MmgL1wkc8Mf3FZL0sgkp2Mr0mLDnIFJz/7yrM/KcNUG732g3XYmM3Ymi0WImh27aPDWbL+1mbW/qSTDXdBuWeepN3jnRW7qfWBlrZWm84S9fUC79M1qH9aOrPYTMZ3PgyQ5GIvr0mO554hIBzgBPFLy2TKbDwC/lr7+deDLgn9BBWI4hyyfqx2ZrJZ81y7Fvjrr06oOsLCfN+vTy8nk0TJai4gT+/m0mOb9BfbcY237y7TYGBE4vhb+HQs5fRzaDYqjf9XIZ7S3D+jRbst92G7W2NBuy/gQcJOI3CgiayQCglMr55wCXpK+fhHwPpMUXjoF3J6q4W4EbgI+WGHzN4BvSl//LeAvIv2uOeyDq7WyeLVj2IFcQ4YLeyMHzdIuif3OyqxSf9aXRFNJZDKX4So6f9hL+2jTbqv3QFMqvse+Iq2X59wGowmbvQ4tpQWOqxMwTdptYT9i9L+yr5V6H+vn9+GjSLtFc5fGmImIvAJ4D9AG3mKMuUdEXgOcNsacAt4MvE1EzgCPkjgT0vPeAXwcmAAvN8ZMAfJspl/5M8CvisiPA+eBH4r12ywG20nNJg0ZLiQPUG6yVZEWO/OFvclibVrPGIOIROjYi8ih322rz1pX1WLGmCi02+o9fvpJPVrS2rTQpPU67RbH19p7qGHNgW91N1CtzRqz9vOk3LHWig207ac1ICfTGZ12S22zyYNA1FjNGHMXcNfKsVdnXo+A7y747GuB17rYTI8/Dnx7YJNrQZtr3ep3eOjx0fzvuQw3EiWgtR1B1v54ahiNZ6yvtdEUZMBy5HBys6e+j8mq4nBnMmM81aM0ciOHbT01XZ6cfjia8OStvop9yH+GNPeRWaWV7BqZ0MK3WfsPPHZxyb49rmU/j73QXOsGyX298viaqtpwv3EpCQ72HVoLNC32hNTbujWbrAzUlpRXT7aulC9Z2NejHGDRoTUFH8v2J8v2IwkCkshKL2fVbgmbvU40Wg/2rlXSLu2ytw/orZGZ219x/h2FzRqz9kfjGbvpbqOahWmzdvb2saMX+TTOJwDaHXt1ncwwgnPLbnY1GE0QQaUoJOwtfKgtOFilxbRpydWEumZ1AICNtWU5/fbYJotjPkO6a0A2+3tpMc32J9Tzcvu12YVV2nOzH75Z49z+en4f0M67rfaBJvK5zKDdsW3OJxuZaHa8VVppsD1mY00zWZxci3PzyEFfSQR7Z316zi3urNLK6ReRmz5fn81pJKVjdJ+h1RX22pHJaokjdXZhRU4fYwKZ2F30gW5b6HX08sKJ3ZXo/wjmfBrnEwD9jt1d2uxKqxT73H5O5KCdLE7sLgbvlpIMF/bSYtoy3ONrbVqysBujY2dppaEyLWnt2/Zf2J0yM8r21/dKibWvT5YajhH5WLtx7O+NfLYUc1ara620o/P9RON8AqDtHFZXeGsVJFzYX5k1qdN6y7M+u8+IVmS1hxZTluHOCzdu24FDN3KDZVpMO3Kz9ledWyxabzYzDHf0KkBY+7vTGTs2Z6IoyEjs740cdGnJZVGJ1i6se+xnJngamzUeBBrn4wkrw9XmuyFLi+l27NV1JjEiN2t3bl8xsjq21qbdkqWOpynDheW1SjGSuVlaTJuWnNsfRaT1UudsTLKXlTH61weyE6Q40X/2HmvTntYu6PeBvbTb0axuAI3z8cZonMhwdXMyq5RAnAd3mXbTTUZn7WvtQGkhIkvlSyxtqEVpwPK2B9qChsTW3sgnlmglBq232e8ymSVy+ljXB5JnZzoznN/RfYb2imK0nVs+7aYFK6dfHiOOHuUGjfPxRgx9fTZysDLcOJRAHFrPbnaVjUy0uegsLaZNmcCylNjKcPtdvW6SzfnE4OuzOZMYtF5WTq+5F9HcfkZUcj7S9YFlOb02LblkX7kPr8rpB8pqw/1E43w8EYuSgWRWY2s2RaHFMgl1TconiUy6SzkZ7fUHy7SYPuWw7BzG6pHVMu0WQdCw3pnL6aPQepkJkuYuqXP7GVFMnD62yBtOpjMu7E51I5NUTj+MRG3Dshxduw/vJxrn44nF4rE4yUTt6gAA/W57vtnVLKU0tGdN2RXqMfYZWabF4kRWWVpP336H8zuTJFk/mrDW1k0WZ+XosQQHif1JlDUmWUHAonBvBPuj8XyzRs32z+X0kZ+hhSjmaG4kB43z8Ya20iqxtaDFtKsDWFha6cLuRF2Gm9hfiRzUZ31ZWixC5LPeWYpMYkRWiZx+kkZWytc/QytFofUyCXXtqu5ZWwmtp59TsnL6wfZEdRfWLKwoQ3uzxiX7GdqtyflcZrAd+4Tije912vS7LYajiXrRTwtLi8VIFi/sT+aRVYyOt5TMjWD//O4iMonh/IH0Hsdxnon9xDn0lGW4i3Usi8gnFu2mXR0A7G6j3fn1Ad3ICuwELHN9IuQllwQHTeRzeSGWc7CFG7WLfi7sJ5RAjGT03P72eCHDjSE4GMVJ5ib2OxgDw53kGm329O8vLBL2MWjDhX19WnUrG51HEBysd1M5/fY42gLKfekDS4KMOGPEzmTKaDw7kgtMoXE+3lg4B/3OnVAmcQoG2oS39g6Lc/tz5xkpcltPcia7k5m6DDexn02oR4h8lmixGJHbQm0VhdZbod3Wu3pbisBCTh/1GervQx9Yos7jjBExIs/9RON8PDEYjem2dWW4kIl8Is76hplktH7k1lmiZGLN7D93Ltl6ItbgbWmfGLPixP44UjJ6sc5Eu+gnQK+TyOntPY4x67aij3jPUIe41PZyH4gR/Q8jSd33E43z8YQdmDRluLDgi6PO+pYoB/2Z8cXdKY9e2J3/rWo/be8Djyd7sqi3P73ej13cVZfhwkrkEEHQkFWjxZDhWjm9ndnHmHVb0cdglGzW2FGMrCATncfKe653o9JuW+sdZiYzAWtyPpcXtEvfWGzNI5NJlJpNNtkaK2S31+TBx7fTv+MM3g8+Ftm+bb86JbMiOFC+/v1um16nNafF4jiHRWQSpw9055FJjIF10X7dzRrn9lM5/Tnl/aYW9pNr8sD8GW2cz2WFGEorsCv4J+qbdM3t9zqMxjMeHu6k3xeH9rHOIQZlAvDA3PnEsb9ofxzBwcPnd9keT9X2Ulr9DpsTiPIMZXIyMVbXL+zHovU685yP5maNC/tdjIGH0sgk1jMUq4/tFxrn44kYSiuwK/jjUDKJfTuzH9HrtOh19COrxH6cWZm9JvtmX/keJ9Fsi4cizlqjP0Nz2k0/clvYjyPIsPaHOxMe396NE7mtLyYwmps17rEfiV3YLzTOxxMxO/buZMbD53fYjDQwATz4+MVIkdtq5KDb8U5Ept02VtofK7pd2I8T+TxyfoedySzaPV7QYjEG7wU1HCtyA/js46Nozg2SPqa5pYjFauTT0G6XGWIpfbI5kzi0W8oXP7Ydqf2Wj76oLsOFDO0WSXDQbbc4ttaOZh+Sezy3r7yOyNq3s+JY9/jcdpx1RJC0+UIqWolh3w7WDzx+MZpaD5I+FmeCuugD2luK7Cca5+OJGKVjYDmhHpd2i2V/ETnEmNXbkvIx+e6tbGQS6R7EnLUu2Y90jx8+v8PudBblHts2P3QuzjO01Y/dxxYTyDjU/KL9MRS3+4XG+XhgMp1xcVe/ZhMsBtOZiTOwWpsmmv3kmiTt178+nXaL42ttZoYoMlxIrsss2cU5yuC0mdZ3s9+lja1M+2Pd44X9eH3ARHqGtqL3saTNSYWPozdG7Bca5+OBWIvfYPlhjTUrjml/s5eUlAf9ZL2FbXesRGv2umjLcGH5usTMOcSz38l9rWY/+4xGjP5XX6vZX7q/+ten10nk9Ml3Hc18DzTOxwsxqvlaLHe8yANfhPbbkvIQLxFq2x2rmq+9RpsRZLiwD/f4yA/eWfuRJ3iRItuY9iEzATuiFa2hcT5eiBn5ZG3GoByOr+1DZJK2O9YOi/YaxbNv2x/n+li7Isn9iGV/9bWe/bjOM3YfiH19rJw+lv2s3aO6iyk0zscLMXZwtIg962u1hLU0TxIrMrEdIz7tFsv+/kRua+2Wugw3ax/2g3bTt38icmS4GZn2BNjo2cgkcvTfOJ/LCzFpt2MZ2WQMGW4WRz3yiec840Y+sbc9zrY7hgw3e19jRyYx7nFWpBLrHtuviOUcFpFPQ7tdVohVcRpYkk3GXjwWyzms2WRotJxMbOeQ2NdeozS3H/m+Zu3HkOFm72tMOT3Ed9SxI4fYtNtRXWAKjfPxQkzaLYtYg/c85xM5WRl/1hcrmbvIyUSxn7Y7tv1YyD7368qFb2E5MtnP36IJQeLaTx+e2M45Jhrn44HhaBKlZtMqYg2uJuIajSxizfrs4NSNkC+B5XUacewv1rHEtB8LGxmRROwFjkf1GTWYqPYtmpxPAUTkVhG5V0TOiMgrc97vicid6ft3i8gNmfdelR6/V0SeV2VTRH5FRD4tIh9N/31FrN81GI3ZWNOv2bSKo045HNWOEX3A2EfaLQZiP/dZaG/WuIqj3gd6ka9PTETrZSLSBt4APBd4APiQiJwyxnw8c9pLgceMMU8XkduB1wHfIyI3A7cDzwKeAvwPEXlG+pkymz9ljHlnrN9kkWyvHH9gjSHDzSI27RZjjcwSIs26O2m7Y03qs1LrGDiqtb7yED+y2j/xRwwc1dI6EDfyeTZwxhhznzFmF7gDuG3lnNuAt6av3wk8R5KreRtwhzFmxxjzaeBMas/FZnQku5jG51pjzTCt4zweiTY83ksGv1jOx86G7SpvbXRaid31bqxkcVw14FEekPYb2ps1Wth7G8v+sdRuZx+jUG3EHEGvBe7P/P0A8DVF5xhjJiJyDrgqPf6Blc9em74us/laEXk18F7glcaYndVGicjLgJcBPPWpT635kxJ8+fVX8LSTG16fdcG7/sHX84nPDaLZf/sPfy3vuedz0SiBf/XCv84Xn9zga592VRT73//1N/DYhV1+4G/eEMX+s298Av/wb38x3x/J/kavw0/f+iV8681PimIf4F9/11/nS54c7xn9D3/vK5eWBWjjbS99Ng+f39N91XDqFX+Tj3zm8Wj23/ySW/jNjz7ENSf6Uez/k2/7azxhY43nRnyGYkNMpKyniLwIuNUY80Pp398HfI0x5hWZcz6WnvNA+venSJzJvwA+YIz5r+nxNwO/k34s16aIXAN8DlgD3gR8yhjzmrI23nLLLeb06dNaP7lBgwYNLguIyIeNMbeE2IhJuz0IXJ/5+7r0WO45ItIBTgCPlHy20KYx5rMmwQ7wn0kougYNGjRocAgR0/l8CLhJRG4UkTUSAcGplXNOAS9JX78IeJ9JQrFTwO2pGu5G4Cbgg2U208iHNGf0QuBjEX9bgwYNGjQIQLScT5rDeQXwHqANvMUYc4+IvAY4bYw5BbwZeJuInAEeJXEmpOe9A/g4MAFeboyZAuTZTL/yV0XkJCDAR4G/H+u3NWjQoEGDMETL+RwFNDmfBg0aNKiPw57zadCgQYMGDXLROJ8GDRo0aLDvaJxPgwYNGjTYdzTOp0GDBg0a7Dsua8GBiJwF/srz41cDDys2RxOHuW1wuNvXtM0Ph7ltcLjbdxTb9kXGmJMhhi9r5xMCETkdqvaIhcPcNjjc7Wva5ofD3DY43O27XNvW0G4NGjRo0GDf0TifBg0aNGiw72icjz/edNANKMFhbhsc7vY1bfPDYW4bHO72XZZta3I+DRo0aNBg39FEPg0aNGjQYN/ROJ8GDRo0aLDvaJyPB0TkVhG5V0TOiMgr9+H7rheR/1dEPi4i94jIP0qPP0FEfk9EPpn+f2V6XETk59P2/ZmIfFXG1kvS8z8pIi8p+k7PdrZF5CMi8u707xtF5O60HXem22CQbpVxZ3r8bhG5IWPjVenxe0XkeUrtukJE3ikinxCRPxeRrzss105Efjy9px8TkbeLSP8gr5uIvEVEvpBu9GiPqV0rEfkbIvK/0s/8vIj7nt8Fbfu36X39MxH5dRG5ouqaFPXfouvu27bMez8pIkZErj6I61bWPhH5kfT63SMi/yZzPP61M8Y0/2r8I9nK4VPA00h2Tf1T4ObI33kN8FXp603gL4CbgX9Dsl04wCuB16Wvv41k51cBvha4Oz3+BOC+9P8r09dXKrbzJ4D/Brw7/fsdwO3p6/8E/IP09T8E/lP6+nbgzvT1zen17AE3pte5rdCutwI/lL5eA644DNeOZGv4TwPrmev1/Qd53YD/Dfgq4GOZY2rXimRfrq9NP/M7wPMD2/atQCd9/bpM23KvCSX9t+i6+7YtPX49yRYwfwVcfRDXreTafRPwP4Be+vcT9/PaRRswL9V/wNcB78n8/SrgVfvcht8EngvcC1yTHrsGuDd9/YvAizPn35u+/2LgFzPHl84LbNN1wHuBbwbenXaShzPABvmfAAAHQ0lEQVQDw/y6pZ3x69LXnfQ8Wb2W2fMC2nWCZICXleMHfu1InM/96WDTSa/b8w76ugE3rAxSKtcqfe8TmeNL5/m0beW97wJ+NX2de00o6L9lz2tI24B3Al8O/CUL57Pv163gvr4D+Jac8/bl2jW0W33YAcPigfTYviClWr4SuBt4kjHms+lbnwOelL4uamPMtv8c8NPALP37KuBxY8wk57vm7UjfP5eeH6N9NwJngf8sCSX4yyJynENw7YwxDwL/DvgM8FmS6/BhDsd1y0LrWl2bvo7Vzh8kiQp82lb2vHpBRG4DHjTG/OnKW4fluj0D+MaULvsDEflqz/Z5XbvG+RwhiMgG8C7gx4wxg+x7JplyHIhuXkReAHzBGPPh/7+9cw2xqori+O8fGpHllCWkSIjRUwqtoUQthjCIKXrQhyAJrSiiSBDqS0JNJj2s6EGlfavMjB4SPSCCSpiymsxGS0mddD6MlpUfojEVm1Yf9rrOmevMvTPXe8+17vrBgX3O2Wfvtde9+66799pn7XrUX4ZRpOmGZWY2HdhLmjo6RL10576Ta0kGciIwBrgybzlGQj2/Z6WQtIi06/HKessCIOl44H7ggXrLUoJRpFH3DOA+4M2R+pKOhDA+I2cnaR63wCS/VlMkjSYZnpVmttov75Y0we9PAH4tI2OtZJ8FXCOpG3iDNPX2LHCSpMJW7dm6Dsnh95uAPTWSrwfoMbOv/fxtkjE6GnQ3B9hhZr+Z2UFgNUmXR4PeslRLVzs9XVU5Jc0HrgbmunGsRLY9DK33SjiD9Kdig/eLScB6SadVIFtN9EbqG6st0UGatTi1Avkq091I5w0b/SD9W9hO+mIVnG5Ta1yngFeBZ4quP8FAR/BST1/FQIdmh18fR/J/nOzHDmBclWVtoX/BwVsMdELe5em7Geg4f9PTUxno6NxOdRYctANne7rN9VZ33QGXAJuA472+V4B76q03DvcNVE1XHO44bz1C2a4ENgPji/INqhNK9N+h9F6pbEX3uun3+eSutyF0dyew2NNnkabUlJfuqvoj2SgHabXKVtLKj0U51DebNNWxEej0o5U01/oJsI20aqXwRRXwgsv3PdCcKetWoMuPW2ogawv9xmeKd5ou/3IWVtUc5+ddfn9K5vlFLvcWRriip4RM04B1rr93vWMfFboDHgJ+BH4AVniHr5vegFUk/9NB0j/j26qpK6DZ2/oT8DxFC0EqkK2L9KNZ6BfLy+mEIfrvUHqvVLai+930G59c9VZCd8cCr3m564HL89RdhNcJgiAIcid8PkEQBEHuhPEJgiAIcieMTxAEQZA7YXyCIAiC3AnjEwRBEOROGJ/gf4+kUyR1+vGLpJ2Z85LRdyU1S3puGHWsrZKsLeqPCt4iaWY1yvXyJku6KXM+rLYFQS0YVT5LEPy3MbM9pHd9kNQG9JrZk4X7kkZZf1yq4mfXkd4RKldH1YxEhhagFxi2YSvVFtJLhjeRIo8Pu21BUAti5BM0JJJelrRc0tfAUkkXS/rSg4+ulXS258uORNp8X5Q1krZLWpAprzeTf4369w9aWYiXJanVr33re7J8UEK+yaQ30Bf6CO1SSeMlvSPpGz9mZeRaIekLYIWPcNolrfejYBgfIwWS7FTaRyjbtnGS3lXaX+YrSReUarOkMZI+lLRBaS+iG6v36QSNQIx8gkZmEjDTzPokjQUuNbO/Jc0BHgFuGOSZc0j7oJwIbJG0zFJctizTSSFKdgFfALMkrSOFyL/MzHZIWlVKMDPrlrSczChN0uvA02b2uaTTSaHuz/VHzgNmm9k+D2p5hZntl3Qm6e32ZlJonHvN7GovryVT5UPAd2Z2naTLSeGcpg3VZlJYm11mdpWX1VSqPUFQTBifoJF5y8z6PN0EvOI/1gaMHuKZD83sAHBA0q+k7QV6ivJ0mFkPgKRO0nRXL7DdzHZ4nlXAHSOUdw5wXibw8FiPdA7wnpnt8/Ro4HlJ04A+UtyucszGja2Zfep+srF+b7A2fw88JelxUjil9hG2JWhwwvgEjczeTPph4DMzu96nvNYM8cyBTLqPwfvQcPJUwjHADDPbn73oxijbloXAbtImZscAA/JXwGHtMbOtSts/twJLJH1iZouPsJ6ggQifTxAkmugPAz+/BuVvAaa4YQMYjo/kT9JUV4GPSVGvAfCRzWA0AT+b2T/AzaSIxIOVl6UdmOvltgC/W9GeUVkkTQT+MrPXSFGvLyzXmCDIEsYnCBJLgUclfUcNZgR8Suwu4CNJ35IMwR9lHnsfuL6w4ABYADT7ooDNpAUJg/EiME/SBpK/pjAq2gj0+SKBhUXPtAEXSdpIWpgwr4xs5wMdPq34ILCkTP4gGEBEtQ6CnJB0gpn1+uq3F4BtZvZ0veUKgnoQI58gyI/bfaSwiTQ19lKd5QmCuhEjnyAIgiB3YuQTBEEQ5E4YnyAIgiB3wvgEQRAEuRPGJwiCIMidMD5BEARB7vwLjOV0M3vBboMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkLKVV_bjfO9",
        "outputId": "90d3859c-4915-430b-969e-c9db3e5fc655",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# Summarize history for PCL Loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('PCL Loss Progress')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'validation'], loc='best')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StPQEuMyjLWv",
        "outputId": "944e3d09-e032-4d7f-e32e-972ca4b78eeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# Summarize history for dice_coef\n",
        "plt.plot(history.history['dice_coef'])\n",
        "plt.plot(history.history['val_dice_coef'])\n",
        "plt.title('Dice Similarity Coefficient Progress')\n",
        "plt.ylabel('Dice Similarity Coefficient')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'validation'], loc='best')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeXxcVd348c93JpOt2Zeu6U5LW6C0UAqICChL2QVRwA14VJQfCuL24IOPAoqiIgrPoyBoFVdEFIVHFhEKlaXQlKV032mTLkmTZs9MZvn+/jg36TRNptM2k2kz3/frlVcy527n3pu533vOufccUVWMMcaY3nzpzoAxxphDkwUIY4wxfbIAYYwxpk8WIIwxxvTJAoQxxpg+WYAwxhjTJwsQGUJE7heR/x7kbbaJyKQDXHa5iJzu/X2riPzuIPIx6Pt+IMT5lYjsEpHXvbTrRGSHdyzLkzmmIjLOm88/ODk3Q5UFiCFARDaJSKeItIpIk4i8IiKfE5Ge86uqn1PVbw/wdktEZL6IbPe2vUZEbo7bZoGqbjiQdavqUar6wkDkM37fReR0Eak5mPWJyFQR+bOI7BSRZhFZKiJfGoAL8nuBs4AqVZ0rIgHgbuBs71g2JHNMVXWzN1/0IPODiLwgIp9OMH2CiKgXkNq8/8Wb+5vfHF4sQAwdF6pqITAeuBP4T+CXKd7mj4ECYDpQDFwErEvxNvfLQN9Fi8hk4DVgC3CMqhYDHwbmAIUHufrxwCZVbfc+jwBygeUHud7BUKKqBcCVwDdFZF7vGUQkayA3aCWkQaCq9nOY/wCbgDN7pc0FYsDR3udfA9+Jm34x8BbQAqwH5nnpxbjAsg2oBb4D+PvZ7jLggwnypcARcdv/GfAU0Aa8DIwEfgLsAlYBs/vaJ+BW4Hdx0/4MbAeagYXAUXHTfg3cBzwJtANndu87MAzo9I5Lm/czGugAyuPWcRxQDwT62KffAf/Yx/m4CHdRbwJeAKbHTRsN/MVb/0bgBi/9U0AQiHr5+qOXf/U+P9/HMc0DfgS86x2Ll7y0Cd58Wfs6p8DV3nJ3eedhI3CuN+0OLz9BLw//28e+7rEtL20x8BXgdKAGd7OyHfgtkOOd863ez0+AnLhlv+blcyvwafb+H+p9bvs8nnHfgWrc//gO4G4vPdc7jw3eOVoMjEj39/hQ/LESxBClqq/jvpyn9p4mInOB3wBfBUqA9+EuyOC+hBHgCGA2cDbui9qXRcAdInKNiExJIlsfAb4BVAAh4FXgDe/zo7jqlGQ8BUwBhnvL/77X9I/iLm6FuIsfAOruzM8FtqqrgilQ1a24i/hH4pb/BPCwqob72PaZXl77JCJTcRf3LwKVuIvZEyKS7VX5PQG8DYwBPgB8UUTOUdVfAp8DXvXydSVwlLfaElV9fx+buws4HngPUIa7uMb6mO/XJD6nJwKrcefhB8AvRURU9Rbg38DnvTx9vr/99vZdROQUL99veskjvbyNB64FbgFOAmYBx+Iu4t/wlp8HfAl3jI/ABZje4s/tK/RzPL157wHuUdUiYDLwiJd+FS5ojgXKcce9M9G+ZSoLEEPbVtyXs7dPAfNV9VlVjalqraquEpERwHnAF1W1XVXrcNVIV/Sz/i/gLs6fB1aIyDoROTdBfh5T1SWqGgQeA4Kq+ht1deV/wl289klV56tqq6qGcKWLY0WkOG6Wv6vqy96+BZNY5UPAx6Gn2uJK3N1uX8pxd7j9uRxXwnjWCzB34e7q3wOcAFSq6u2q2qWuLeFB+j++/fKCzX8AN3rnL6qqr3jHJH6+ZM7pu6r6oHceHgJG4aq39sdOoBH4BXCzqj7npceAb6lqSFU7gY8Bt6tqnarWA7fhAjK4IP0rVV2uqh24c9tbz7kFjiHx8QwDR4hIhaq2qeqiuPRyXMkk6v1Ptuzn/maEAa0TNIecMbgvbW9jcXe2vY0HAsA2EelO8+Hq2/fifeG/C3xXRIqAm4E/i8g4Ve1ruzvi/u7s43NB/7vieBfwO3D1/pXsvmOuwFWz0F9+E/g7cL+ITASOBJq9ElhfGnAX0P6MxlX5AKCqMRHZgjsXYWC0iDTFze/H3aXvrwpcVcn6fcyXzDndHpffDm++fZ6L3vlR1Ugf6fW9gvQex8f7e3TctOq4aX2dx/i08SQ+np8CbgdWichG4DZV/T9c8B8LPCwiJbjqplv6KTFmNAsQQ5SInIC7KL3Ux+QtuCJ3X+kh+v+y90tVW0Tku8DXgYn0HZgGwkdx7Sdn4qrFinF15xI3T6IuiveapqpBEXkEV4qYRv+lB4B/AR8CftXP9K24O1vAVbvgLka1uGO7UVWTqY7bl524toHJuCqW/hzwOfUcbHfPvZffiruwdze8j/PSwJXMquLmHbuP9W0hwfFU1bXAlV5p61LgUREp96oabwNuE5EJuJul1aT+oY7DjlUxDTEiUiQiFwAP4xp23+ljtl8C14jIB0TEJyJjRGSaqm4D/gn8yFuPT0Qmi8hp/Wzrv0XkBK9+PRe4EdfotzpFuweu7jmEu5PPx5Vg9scOoLxXlRS4NpmrcQ3MiQLEt4D3iMgPRWQkgIgcISK/8+5GHwHO945tAPiyl99XgNeBVhH5TxHJExG/iBztBfP94lWxzAfuFpHR3rpOFpGcXvPt1zntww7ggN5l6ccfgW+ISKWIVADfxN3Bgzt214jIdBHJB/b17krC4ykiHxeRSu9YdZcyYiJyhogc45VGW3Alu77abjKeBYih4wkRacXdVd2Ca/C9pq8ZveqTa3B10c3Ai7i7OoBPAtnACtyd+aP0X6WiuDvpnbi7wLOA81W1bQD2pz+/wVVL1Hp5XJR49j2p6ircRWqDuHdGRnvpL+MuEm+o6rsJll8PnIx7eme5iDTjnqKpBlpVdTWuJPI/uONyIe4R5C6vjv8CXAPtRm/6L3CloAPxFeAd3FM4jcD36fs7vT/ntLd7gMvEvbx37wHmM953cMdqKS7vb3hpqOpTwL3AAtzj0t3nNrT3aiCJ4zkPd47avP24wqsWHYk7Bi3AStz/f6KbgowlqjZgkDEAIvI88AdV/UW682JARKbjHqXOOcDqMXOQrARhDD1tNsfhnqYyaSIil4hIjoiU4kpET1hwSB8LECbjichDuMbnL6pqa7rzk+E+C9Thns6KAtelNzuZzaqYjDHG9MlKEMYYY/o0ZN6DqKio0AkTJqQ7G8YYc1hZsmTJTlWt7GvakAkQEyZMoLq6et8zGmOM6SEi/T7WbVVMxhhj+pSyACFuIJk6EVnWz3QRkXu9Dt6WishxcdOuEpG13s9VqcqjMcaY/qWyBPFr3JuM/TkX12XzFFw3wPcBiEgZrjuDE3FdAX/LeybaGGPMIEpZgFDVhSTusO1i4DfqLAJKRGQUcA7wrKo2quou4FkSBxpjjDEpkM42iDHs2XVvjZfWX/peRORaEakWker6+vqUZdQYYzLRYd1IraoPqOocVZ1TWdnnU1rGGGMOUDoDRC179vde5aX1l26MMWYQpTNAPA580nua6STcKF7bgGeAs0Wk1GucPttLM8aYtFFVendNVNvUycptLagqrcHwXtP3tT6AYDjKcyt38L/Pr+VPizdT29RJLLbntmqbOgmGo/2up6MrNf0ZpuxFORH5I27Q8QoRqcE9mRQAUNX7caM4nYfr970Db+wCVW0UkW/j+rgHN35tqkYnM+aw0dAWomxYNiJCKOIuFjlZ/gNal6oSU/D73EB8zR1h6tuClA3LoSAni9qmTiaU5/NuQwcFuVlUFOSgqsQNW9qntlCE1mCYUcV5hCJRfrdoM9NHFjJ7XCkL19bzxuZdTK4o4LyZo9ja1MniTY1MH1XE+LJ8Xlq3k5L8bE6cWEZOlo91dW0s3rSL046s5M3Nu3huZR3TRhZSWZjDmTNGUJQbAGBHS5D7X1zPiRPLeHldA12RGCdNLuOYMSVsbmznvhfWU5CTRSSmrNnRykmTyjltaiVVpfnkZ/upKs2jICeLp5Ztp641xLq6Vt7e0ozfJ3zp7Kk8uHADAb+PDTvbaOmM8N4jKlhf38ZZM0bw+9c209jeRX62n46uKHkBP8ePL+Vzp00mEotx73NrueeK2by0bie/enkjrcEIRwwvYEtjB7VNnUwfVUTtrk4a2rv2OpZjy/K46NjRrNzWyvOr6ijMyeLcY0aiCgtW1zNjdBEXHDOKf7yzDb9P+OVVc/Z5fvbXkOmsb86cOWpvUpveguEomxraEYSdbSHaQxGK8wIcNaaYYdn+A/pC1bUEqfcu1nf/cw1XzB1H+bBsltY2U1GQzavrG5g+qohQJMqmnR1kZ/n48Jwqhhfm7pW3ml2dTKoYxvyXN9LY3sVnT5sMCt9/ZhX5AT/bWtxwzkdUFnDPc2v5+Enj2FDfzivrG8jP9vPxk8YzpiSPJ9/ZRm7Az1Gji9jc2EFbKEJ7KEJbKEpxXhZFuQHe3NKET2BUcR5bmzppDUaYWVVMVzTG21uaiHmXgryAn85wlKkjClhX10ZpfjYnTirjXyvrGF2cSziqvGdyOR89cRybGzv4+1tbWVbbzFkzRvDyup1sbwly05lT+csbNazZ4caOysnyEYrE8AnEFCZVDGN7S5COrr3vivMCfsoLsqnZ1QlAaX6Aps4ww7KzaAu5O+WS/ABXnDCOM46s5PtPr+KNzW7AuOwsH7lZPlqCu++ox5Tk9fw9a2wJizY07HFBzsnyMa4sn7V1Lq9FuVnMrCphxbYWGtu7KM0PMKIol4oCFzyr321kRFEuy7e2MKIoh8+cOonNjR2MLM6lriXEsyt20NAeYlh2Fg3tXRTnBWjuDHNsVTFVpfm829jOuLJ8Rhbl8cbmXZQPy+YTJ4/nhAllbGsO8vyqHbSFoixcU89bW5qoLMzhihPGsrUpyNPLthGOKmfOGM6y2hY2N3YwLNvPV885kk+ePAGfb///n0VkiarO6XOaBQiTLsFwlMferGVTQzuzx5Yw7+hRvLWliSyfEI0pmxs7aGgLUZwfYMaoYjbubGdEUQ6zx5XSFYmxvTnI6BL3Rd3eEuSUIyp4+PXN7OroYvHGXWxsaKe5I0xXtO/RJHMDPj4yZyzXvm8SVaX5tATD/GLhBv721lZGl+TyiZMmcP7MUWza2c69z61lfPkwFm9q5OX1O1GFLJ8QiSml+QEiMaU1uHcxXwRU3UXowU/OoaMrwts1zSytaWLRhkaiMaWqNK/nYliUm0XZMHdx9IlQmJtFMBylvSvKhPJ8NjV0kJPl4zOnTmJjQzv/WLoNgPHl+USiyvaWIGNL8yjKC5Cf7acgJ4u61hCN7V3MnVhGlk/Y0thJWUE2pfkBVmxtIcvn48RJZT13tnWtIUaX5PH3t7Yye5y7oNbs6uSSWWNo64qAwrMrdvQc1zEleUwfVci/VtZRlJvF6JI8Vm1vZVxZPrecP511dW3Ut4Y4a8YITphQxqsbGrjx4TcZXpjDjy+fxZbGTtbXtzF3YhltoQgvrKpja3OQ902tZMrwAr78yNuMLcvj19fMJRSJsb6+jZ8tWMeC1fVEvaj248uPpSQ/mxmjiqgoyGHlthbW7GilMDfAqVMqyA3sLmnFYsqq7a00tnfRForwr5U7eGntTr5+3jROnVJJaX4AEWFdXSsPLNzA/zv9CCZUDNvjvKoqL6yuZ+rIwj0CEEB9a4iL/vcl6ltDfPWcI7nrn6u5+j0T+Pq50/f7Ah6KRPcoJXZ2RemKxijOCxCLKUs272JcWT4jinITrCUxCxBmwEWiMfw+SXgHHospr25ooCsaY1d7F1ubOnltYyOvb2wkHI313LEG/EI4qtx87jTufGpVwu2KwEkTy6l+t5FwVBlemMPOthAxhcKcLFq9O8wZo4qYWVXsLhqji/CLUDYsm8LcLOpbQ6za3sq6ujb+9lYt0Zhy9JgidrZ2saM1yHuPqKC2qZMN9e3MGV/Khp3ttIcihCIxhhfm8NETxzGiKJelNc2cNWM4N/3pbYrzAtx56TG0BMOcPKmCtXWtFORmMbmygJpdnVz3uyWsrWsjGlMCfmFcWT5nzRjJ8MIc5r+8kfdPG85H5ozl5ws38Or6nfzgspmcckQFWT4fW5s6eXndTi47voq/vlHLjNFFHD3GjarZGgzT1BFmTEkeIhCJKQH/wDYtBsNR2kIRKgp2D3dds6uDVdtaKcoLMGd8KT6f8PaWJkrzsykryOa1DQ28b2plv3lpCYbJyfIlVUUWjsbwi+x1cd3V3sVbNU3kB/ycOKn84HZygNXs6mBHS4jjx5cSDEf3CFCHGgsQ5oCoKu1dUYZl+6l+dxfzX9rI+vo2JlcW8OyKHRw/vpTx5fk0d4Z5z+QKPnbiOP65YgcPvbKJUcW5jCrJ474X1u+xzvHl+Zxx5HAKc7Pw+4STJ5Vz9JhiTr/rBepbQ4wpyeOW86cT8PsYW5ZHRUEOje1dLK1pZlRxLo+/tZWX1u3krBkjmFw5jAWr6xlXls+o4lyeXr6dr587nbkTy5Lex5pdHfztzVpeWd9AJKr81/nTmTW2hEg0xs8XbuCfy7eTl+3nu5ccQ1FegMLcrL0uanUtQfKy/RR6deJ92dES5KY/vcVpUyv59KmTeur+jUk3CxAmKarKwrU7+efy7Szb2sLG+jZaghGGZftp74pSnBdg2shCVm5r4QPTR7BwTT3haIzSYdm829DRUwUyujiXrc2u7vyDs0bziZMnUDYsm1HFuf3eST1SvYWvPbqUn3/ieM45auRg7rYxGS1RgBgy3X1nopZgmLqWIJMrC1izo41vPb6Mzq4orcEITZ1hzjhyOFNHFLCjJURVaR4fOq6K4vy973I37mznxdV1/OOdbSzetIuCnCxmVhVz8awxjCrJpXaXe9ri0uPGkJ+9+1+mu/7X7xN+t+hdbn9iBZ993yS+Nm8aD/57A8+t3MG3P3h0wjvrbh+ZM5bTj6zcqyH3gISD4A9AtAtatkLxWMjKhlgUNOamHYxICDqbIL8MWrdD4UjoaoOORiga7bZZOAqy8938Xe3QuBGGzwBfktU/oTbIHubq1CJdEOmErDyIBCGQD/79+OoGm2H9Amivh6o5UDndrWfXRmjZ5o5TLOKOTywM4odhlVAwHMomQk5h4vVHI1DzOpROhPxyWPMUvPsKjD7O5b9oDAyfDnml7jO4hplu8dWU8ekdjbBrkztfkRC01EKoBUonQPkUd9y7G3nqV0GWVwUW6YJoyO2TLwBtddC82R230cfBsAq3z13t7rxFI4BC3Uq3nnCn22ZXG+x61523rGzwZUFemTs2hSO9beZCbrHLR8VUt82QN2ptdgH4/O5/pGWrOw4l49y5DAehqxW2L3P7GAlCTpGbf9O/oWAkjD3RrbtgODS9C6v+AaNmwbw7oXUb1K+EwDBo3eqOwTGXJf8/kSQrQRxuwkEI5LJ2RytXzX+d1uZGpuc2ktfVQE3eNEaPHkNOlp/8bD8vr9nOsOA2WvylNEWyGVmUy2PXv4dRxXmoKs8s38F9L6xjac0uTvKtpKoowJlHjebMEa34G9dDNAxlk+Ddl91FomyS+2ctGQ8vfM9dJMsmwrQLYNbHCCu765zrV8PaZ92XMCvHfbHbd0Igz33JVj7hvlThTrfukrHQ7L0P6ctyX+L8crdcOAgT3+cuvsFm9+XOLXHbDuTDW7+HmsVuvUWj4O2H3YUhFoFwO/hz4OgPwfrn3MWicKS7WIXaYNRMdwGIhqB+DbTXuW1Fw24fUJhyDkw9GxbdB5techeGWFyDdGCY+4JrrydyxAf+7N0X3vIpcMQHoKPB/ZROhPLJ7rjGIu4C1bgR2ra7C/roWW49W9/ce73ZhS7YBIbB5DNcnltq3YW5ZRuUT3LHO78MNr/m9utA5Ra7cz7jInjPDe44tG5z+9W0Gba/4y5SiMubRt05jCXxbL4/210Yu9pdQAy1umOelQeh5sTLlk2GKWfDztWw/vkD3794WbkuH9Gw+78tHuvOC7hzmMw+7a/8Cvd/HGqGrg6oOgFaatyxjVc6wQWTwtHe8Y4z4hi47qUD2rxVMR0qVGHnGneh8Plgx3JY/STMvMJdIHvpisS4/5klTKhfwIYWgaYt3BD7La8Nez8/bzqBz2Q/zSm6++Kh4kdO+0844dPw7x+h1fORSCeKECyexM+b5vJM2cf49TUncMtf3yF/zd8oLCrm3Ik+3rvy23tuPLsAEHeXU1TlLqDtcf1dFVXBmOPcPjSud3c2ZRNh+FGw7S13t0P8XaLPXfC72iHcAeNOdheGQC60N7h/+JJx7u41FnZ3XcFmNw8KDev6P67ig7EnQcdO2LnWXchyS9xFavRs2PwqvP1HGDPHXUyba6Fzl9t27RJ3l+jLgvIjILfIBRtfwN0RRkPunIGbZ9LpMHKmCzIdjS5g1q92y5WM80oUo9zvSNAtL3437Z0/w7a33T4VjnR38MH4i6C4IBjIh8nvd3fiWbkuuGUPc4EyK8ddREMt7gLdXg/rnnPnCaByGhRXQeMGd6fbVufWecZ/uTxsed0FoaxsF6CKq9w6fQF399p9YW+vd/vQuN793r4MNr8CxePc3Xj33XHJOBfgpl24+054zPFwxJnQsNatt3GDW09nk7eb4vZVxP0vBFu8/etw6xVxF8qySe6iGIu441A0yk3ftckF6TVPu+AnPjj9P93+Im7fsnLdcY+GoGCEu9B37nLBLNjk9jmQ79bnD7hjWXmk256vVzWo6u6SSqjVK5FscfPHIu5GIxZ2/3uBPO+7g1c6Cbv/h8IRLt9t9W6eQK7bfsVUdzPUm6pbtnOXu2EoHO3me/EHsOEFmHa+u4EIB6Gg0pUKs7L7/44kYAEiXZprYPEv3T/r+PfA0j/Bm791AeHCe+CB09w/OuJO9rEfhdkfg+xhdLQ18c591zCrbSE5svuuZTmTOYIt5NCF+nORU26AEUe5O+I3HoJlf3F3X9EQHPMRmHCKK94u+yvhlh0c1X4/InCH/IzL/AtRfw6SX+4udOd+3/1TFo9xFw9Vd+EuHO2+ILEo1K1wF9WjL3V3lqrwxm+ger774u3aBMOGu/048XPuSxsJujz5fK7439noLpD7o2G9W09usSsRdDS4C2yozR27iiluvmik7+qX7otrX09dRcPuHHQvF2p1X97uC8XWN13Am/FBGHn0/uW7t+6LTfffHY3uApqV7S5OucX7v85oxN1F55a4c5cqi+6Dp2+G93wBzvp238dysMWiXgDJ2fe8pk8WIAZbsAWe+S9X1aEx99N9Nz35/a44PGw4tNfxyvRvEGqu4+TwInLrl7LaP4VPRr/Ff/ie4LOxP7Fy3JVMOevT+HauxrdzDZxxi6vD3LzIXRTLJu3ebiwKT33NVS2c/nUYPm33tH/fDc/dxosfepPv/v0Nnol8ygWkNU+7C/YVf3B3JQers8m7K7PmrSGprd7dyR4KwcEMCGukTrVo2FVTlIxzd4LPf9vVi5/waXe3JX5XTVE4kljFNFY//xCFS+5jSWwqN745Hb/vKKKx0znPt4j/zf4ffp9/F6M717Br3DlM/4/73TbGxp2/rGyYes7e+fD54fwf9Z3HknEAnDYixPs+lAN/AuZcAzM/DGuegannDsyxyCsZmPWYQ1OB9ZqcSSxAHKwdK+DX57m6whOvg9kfh8W/gDmfgvN+uHu+4jG8ur6B//7dQtbVVZIXuI15R4/k+fcfQUFuFg+/voWZVScgbUdwxL9uBeki//xbBy6fxV4bR9MWZMvrrnFw1LGuaD75/QO3HWPMkGEB4mCouiodgImnufaF2iWuLviM/0JVeWDhBlZtb6W+NcRL63Yyvjyfn1w+i3lHj9zjnYAbPuDVoXMVHHule+qkuGrg8trdCN68xTVUjppl9bbGmIQsQByMtc+6Z5bPu8s9ufHgGVDzOrHzf8zq5ixeqt7I955aRUVBNkW5AW78wBQ+e9qkPd4l6FNW9sAGB3BPcviyXIPo1jdh7mcGdv3GmCHHAsTB2Piie6Lm+Kvdo3Lj30tnRysffnkSy7b/G4DTj6xk/lUnHFAviwPK53cv6qx43D3hNPbE9ObHGHPIswBxMLa/AyNm9LyZ2/7hh7n4py/THIlwxyVHU5KXzRnTKtMfHLqVjHMlHn+Oex/AGGMSsABxoFRdgPAeDX2nppnvP72K9U1R/nTt3P3qMG7QdDdUH/GBfXefYIzJeBYgDlTrNvf+wMiZbNrZzofuf4WcLB+3XnjUoRkcYHdD9fQL05sPY8xhwQLEgdr+jvs98mhu/78VZPt9/OtLpx3UwB0pN+5k153EkQP0zoMxZkizAHEgFnzX9aEEvNA0nOdXreaW86Yf2sEBXLvDF5akOxfGmMOEBYj91dEIC38IGiM2fAbf+ucWjhhewNWnTEh3zowxZkBZgNhfa54GjVF36V/42svwbkMHv/vUiQM+zKMxxqRbSq9qIjJPRFaLyDoRubmP6eNF5DkRWSoiL4hIVdy0qIi85f08nsp87pdV/yBaMJqL/w+W7Ijyw8tm8t4pfXTXa4wxh7mUlSBExA/8FDgLqAEWi8jjqroibra7gN+o6kMi8n7ge8AnvGmdqjorVfk7IOEguu45ns76AK2hKH/67EkcNfoAumc2xpjDQCpLEHOBdaq6QVW7gIeBi3vNMwPoHgpqQR/TDy3t9Uikk4Wto7jl/OkWHIwxQ1oqA8QYYEvc5xovLd7bwKXe35cAhSJS7n3OFZFqEVkkIh/sawMicq03T3V9fX1fswwsb6zZWHYhl8xO4cAsxhhzCEh3y+pXgNNE5E3gNKAW6B7Yd7w3iMVHgZ+IyOTeC6vqA6o6R1XnVFamvp/65qadABw/dfwePbEaY8xQlMoAUQvED7Rc5aX1UNWtqnqpqs4GbvHSmrzftd7vDcALwOwU5jUpqza5gcKPmzouzTkxxpjUS2WAWAxMEZGJIpINXAHs8TSSiFSISHcevg7M99JLRSSnex7gFCC+cTst1tduA2By1ag058QYY1IvZQFCVSPA54FngJXAI6q6XERuF5GLvNlOB1aLyBpgBHCHlz4dqBaRt3GN13f2evopLWq21wHgz7PGaWPM0JfSF+VU9UngyV5p34z7+1Hg0T6WewU4JpV5219bGjsIt1AoUVUAACAASURBVDdBAOsJ1RiTEdLdSH3YeGX9TgqkE0UgMCzd2THGmJSzAJGkl9c1MDy7y5UefHbYjDFDn13pkqCqvLJ+J5MKo0hOUbqzY4wxg8I660vClup/cGPwV4ypAKLW/mCMyQz7LEGIyI3JpA1pr/2cT2T9i+HSBLlWgjDGZIZkqpiu6iPt6gHOx6ErGqaysRqA7MY19gSTMSZj9FvFJCJX4rq5mNiru+1CoDHVGTtk1L5BXqzD/R1qsQBhjMkYidogXgG2ARXAj+LSW4GlqczUoaR99XPs8VCrNVIbYzJEvwFCVd8F3gVOHrzsHHqC619ma2wMU3xeN1JWgjDGZIhkGqkvFZG1ItIsIi0i0ioiLYORuUNBuLWBGq1Ehw13CVaCMMZkiGQaqX8AXKSqxapapKqFqpoxV0kNtSG5hUixN/6DPcVkjMkQyQSIHaq6MuU5OURlRdsJ5BVCkRcgrIrJGJMhknlRrlpE/gT8DQh1J6rqX1OWq0NENKbkxTrJzi+C4hKXaAHCGJMhkgkQRUAHcHZcmgJDPkDsaO5kJEFyhxXHlSCsiskYkxn2GSBU9ZrByMihqLaugdGiDCsshhJvcLxcGwvCGJMZknmKaaqIPCciy7zPM0XkG6nPWvptb2gAoKi4FKaeCxf8BEbNSnOujDFmcCTTSP0gbjjQMICqLsUNHzrk1e90AaK4pBQCuTDnGuvq2xiTMZK52uWr6uu90iKpyMyhZtcuFyACudYwbYzJPMkEiJ0iMhnXMI2IXIbrgmPIa25pdn/kFKQ3I8YYkwbJPMV0PfAAME1EaoGNwMdTmqtDRHvzLvdHtgUIY0zm2WcJQlU3qOqZQCUwTVXfq6qbklm5iMwTkdUisk5Ebu5j+nivAXypiLwgIlVx067yuvhYKyJ9dTmeUpFojFBnq/tgAcIYk4ESdff9cVX9nYh8qVc6AKp6d6IVi4gf+ClwFlADLBaRx1V1RdxsdwG/UdWHROT9wPeAT4hIGfAtYA6uamuJt+yu/d7DA1TXGiKfTvfBqpiMMRkoUQmiu5frwn5+9mUusM4rgXQBDwMX95pnBvC89/eCuOnnAM+qaqMXFJ4F5iWxzQGzvSVIAUH3IXtY4pmNMWYIStTd98+937cd4LrHAFviPtcAJ/aa523gUuAe4BKgUETK+1l2TO8NiMi1wLUA48aNO8Bs9m1Hc5D8ngBhJQhjTOZJ5kW5h0SkJO5zqYjMH6DtfwU4TUTeBE4DaoFosgur6gOqOkdV51RWVg5QlpztLUEKJIj6c8AfGNB1G2PM4SCZx1xnqmpT9wevymd2EsvVAmPjPld5aT1UdauqXqqqs4FbvLSmZJZNte3NQQp9QWt/MMZkrGQChE9ESrs/eA3IyTweuxiYIiITRSQb9/Z1/NjWiEiFiHTn4etAd8nkGeBsr7RSiuso8JkktjlgtrcEKQ+EEateMsZkqGQu9D8CXhWRPwMCXAbcsa+FVDUiIp/HXdj9wHxVXS4itwPVqvo4cDrwPRFRYCHunQtUtVFEvo0LMgC3q2rj/u3awdneHKQsK2TtD8aYjJVMb66/EZFq4P1e0qW9HlVNtOyTwJO90r4Z9/ejwKP9LDuf3SWKQbejJUiRv8uqmIwxGSvRexBFqtriVSltB/4QN61ssO/oB5Oqsq05SGFxELJHpDs7xhiTFolKEH8ALgCW4PXD5BHv86QU5iutmjvDhCIx96KcVTEZYzJUogBxp/d7uqoGByMzh4odLW5k1ZxYpw0xaozJWImeYrrH+/3KYGTkUNLY3gVAINphb1EbYzJWohJEWEQeAKpE5N7eE1X1htRlK72aO7sAJSvcblVMxpiMlShAXACciesXacngZOfQ0NQRJpcuRCOQW5Tu7BhjTFokChBfVdX/FJFxqvrQoOXoENDcGaaIDvchtzi9mTHGmDRJ1AZxnri+vTNi/Ol4TZ1hSn3dXX1bCcIYk5kSlSCeBnYBBSLSwu7HWwVQVR2yV87mzjCj80Ku28Dckn3Ob4wxQ1G/JQhV/aqqlgD/UNUiVS2M/z2IeRx0zR1hhme7J5msDcIYk6mSGXL0Ym9o0DMBRCRPRIb0ywHNnWGGB7xXP6wNwhiToZIZD+IzuP6Sfu4lVQF/S2Wm0q2ps4uKLC9AWBuEMSZDJdPd9/XAKUALgKquBYanMlPp1tQRpqw7QFgVkzEmQyUTIELemNIAiEgWe/bNNOQ0d4YpkU7wZUEgP93ZMcaYtEgmQLwoIv8F5InIWcCfgSdSm630icaU1mCEQulw1Usi6c6SMcakRTIB4magHngH+CxufIdvpDJT6dTSGQagkHZroDbGZLRkBgyKichDwKte0mpVHbJVTE1egMjXDmt/MMZktH0GCBE5HXgI2IR7SW6siFylqgtTm7X0aOpwzS150VbItxKEMSZzJTsm9dmquhpARKYCfwSOT2XG0qXZK0HkRNohZ3Sac2OMMemTTBtEoDs4AKjqGiCQuiylV3eAyAq3WBuEMSajJRMgqkXkFyJyuvfzC6A6mZWLyDwRWS0i60Tk5j6mjxORBSLypogsFZHzvPQJItIpIm95P/fv324duKYOFyD84VYLEMaYjJZMFdN1uJflugcIWgjct6+FRMQP/BQ4C6gBFovI46q6Im62bwCPqOp9IjID94TUBG/aelWdldReDKD61hABn+LrarO3qI0xGa3fACEilUCld0G/2/tBRI4CinCPviYyF1inqhu85R4GLgbiA4R66wIoBrYewD4MqLrWIOPyIxDBShDGmIyWqIrpf4CKPtLL2D1edSJjgC1xn2u8tHi3Ah8XkRpc6eELcdMmelVPL4rIqX1tQESuFZFqEamur99XvEpOfWuICQWumskeczXGZLJEAeKIvh5lVdV/AzMHaPtXAr9W1SrgPOC3IuIDtgHjVHU28CXgDyKy19VaVR9Q1TmqOqeysnJAMlTfFmJMXsR9sComY0wGSxQgEnXpncxTTLXA2LjPVV5avE8BjwCo6qtALlChqiFVbfDSlwDrgalJbPOg1bWEGJHnfQjkJZzXGGOGskQBYl33U0XxRORcYEMS614MTBGRiSKSjRu69PFe82wGPuCtdzouQNSLSKXXyI2ITAKmJLnNgxKNKQ3tXZTnegn+Ifs0rzHG7FOip5i+CPxDRD4CLPHS5gAnAxfsa8WqGhGRzwPPAH5gvqouF5HbgWpVfRz4MvCgiNyEa7C+WlVVRN4H3C4iYSAGfE5VGw9wH5PW2N5FNKaUdxcc/Dmp3qQxxhyy+g0QqrpWRI4BPgoc7SW/CHxWVYPJrFxVn8Q1PsenfTPu7xW4sSZ6L/cX4C/JbGMg1beGACjN8bqaysoe7CwYY8whI+F7EKoaAn41SHlJu7pWF/d6AoTfAoQxJnMl8yZ1xuguQRR3xwWrYjLGZDALEHHqvABRFIi5BKtiMsZksH0GCBG50Hs3Ycirbw1RmJNFNt6LclbFZIzJYMlc+C8H1orID0RkWqozlE6N7V2UF2RDtDtAWBWTMSZzJTOi3Me9t5ivBH4tIopruP6jqramOoODaWrjAo6PbYTIFJdgVUzGmAyWVNWRqrYAjwIPA6OAS4A3ROQLCRc8zMxufYHzQ09B1LVFWBWTMSaTJdMGcbGIPAa8gOtiY66qngsci3vRbciQaMi1P0StDcIYY5IZD+JS4Me9O+5T1Q4R+VRqspUevlgX2YQgEnLBQSTdWTLGmLRJpoppe+/gICLfB1DV51KSqzTxxboIxLog2mWlB2NMxksmQJzVR9q5A52RQ4E/FsZPFMIdFiCMMRkv0Yhy1wH/D5gsIkvjJhUCL6c6Y4MtEo2RpWEQINgCWfaIqzEmsyVqg/gD8BTwPeDmuPTWwehZdbC1h6K7X5ALtVhX38aYjJcoQKiqbhKR63tPEJGyoRYk2roiZOONJBdssZfkjDEZb18liAtwY0EorvKlmwKTUpivQdceipAvcSUIq2IyxmS4RONBXCAiApymqpsHMU9p0RqMUNJTgmiGwlHpzZAxxqRZwqeYVFWBfwxSXtKqPRTZ3QYRbLGnmIwxGS+Zx1zfEJETUp6TNHMBwitBhNutHyZjTMZL5k3qE4GPici7QDuuLUJVdWZKczbI2uJLEGCN1MaYjJdMgDgn5bk4BLQHQ2RJbHeCVTEZYzJcMt19vwsgIsOB3JTnKE2CnZ17JlgVkzEmwyXTm+tFIrIW2Ai8CGzCvUC3TyIyT0RWi8g6Ebm5j+njRGSBiLwpIktF5Ly4aV/3llstIikvxXQGewUIq2IyxmS4ZBqpvw2cBKxR1YnAB4BF+1pIRPzAT3H9Ns0ArhSRGb1m+wbwiKrOBq4AfuYtO8P7fBQwD/iZt76U6dorQNib1MaYzJZMgAiragPgExGfqi4A5iSx3FxgnapuUNUu3GBDF/eaR4Ei7+9iYKv398XAw6oaUtWNwDpvfSnTFepdxWQlCGNMZkumkbpJRAqAhcDvRaQO9zTTvowBtsR9rsE9ERXvVuCf3sh0w4Az45aNL6XUeGl7EJFrgWsBxo0bl0SW+heyKiZjjNlDMiWIi4FO4CbgaWA9cOEAbf9K4NeqWgWcB/xWRJIaBhVAVR9Q1TmqOqeysvKgMhLuCu6ZYFVMxpgMl8xTTPGlhYf2Y921wNi4z1VeWrxP4doYUNVXRSQXqEhy2QEVCfUKEFbFZIzJcP3erYtIq4i09PHTKiItSax7MTBFRCaKSDau0fnxXvNsxjV6IyLTcY/R1nvzXSEiOSIyEZgCvL7/u5e8vUsQ9pirMSazJeqsr/BgVqyqERH5PPAM4Afmq+pyEbkdqFbVx4EvAw+KyE24Buurvf6flovII8AKIAJcr6rRg8nPPkVDe362AGGMyXCJRpQrUtUWESnra3oy40Go6pPAk73Svhn39wrglH6WvQO4Y1/bGCj+WHjPBKtiMsZkOBsPwuPXrl4JVoIwxmS2hONBeL8nDl520ieruwSRXQBdbRYgjDEZL5n3IBCRmcCE+PlV9a8pylNa+NULELnFLkBYFZMxJsPtM0CIyHxgJrAc6O7uVIEhFSCytMtVouUUAbVWgjDGZLxkShAnqWrvPpSGnJ4AkVvsEixAGGMyXDJvLb/aRyd7Q05WTxWT1zWUdfdtjMlwyZQgfoMLEtuBEEN0RLms+DYIsL6YjDEZL5kA8UvgE8A77G6DGFJiMd09HnWO936gVTEZYzJcMgGi3nvreciKxJRswkQlgD8rzyVaFZMxJsMlEyDeFJE/AE/gqpiAofWYa9QrQUR92fgD3qiqVsVkjMlwyQSIPFxgODsubUg95hqJxVwJwheArO4AYd19G2MyWzLdfV8zGBlJp+4SRMyXvTtA2ItyxpgMl6izvq+p6g9E5H9wJYY9qOoNKc3ZIIrElGwJuwAxrBJ8AdflhjHGZLBEJYiV3u/qwchIOkW9RuqYLxuO/hCMOQ7yStKdLWOMSatEnfU94f3uGUVOREqBJm/MhiGjp4rJn+2eXqo8Mt1ZMsaYtEs0otw3RWSa93eOiDyPG496h4icOVgZHAzRmJLTXYIwxhgDJO5q43Jgtff3Vbg3qCuB04Dvpjhfg8q1QURQeznOGGN6JAoQXXFVSecAD6tqVFVXkmQ34YeLqPeYqwUIY4zZLVGACInI0SJSCZwB/DNuWn5qszW4Il4bhFoVkzHG9EhUErgReBRXrfRjVd0IICLnAW8OQt4GTSSqXgnC3n0wxphuiZ5ieg2Y1kf6k8CTyaxcROYB9wB+4Beqemev6T/GlU7AlUqGq2qJNy2K6yAQYLOqXpTMNg9E91NMav0vGWNMj5S1JYiIH/gpcBZQAywWkcdVdUX3PKp6U9z8XwBmx62iU1VnpSp/8bpflLMShDHG7JbMgEEHai6wTlU3qGoX8DBwcYL5rwT+mML89Ku7BGFdfBtjzG6pDBBjgC1xn2u8tL2IyHhgIvB8XHKuiFSLyCIR+WA/y13rzVNdX19/wBnt7qzPAoQxxuy2zwAhIvki8t8i8qD3eYqIXDDA+bgCeFRVo3Fp41V1DvBR4CciMrn3Qqr6gKrOUdU5lZWVB7xx96JcxDroM8aYOMmUIH6F6+77ZO9zLfCdJJarBcbGfa7y0vpyBb2ql1S11vu9AXiBPdsnBlQkGiNHwhYgjDEmTjIBYrKq/gAIA6hqB+6t6n1ZDEwRkYkiko0LAnuNTOd151EKvBqXVioiOd7fFcApwIreyw4UjXS57VoVkzHG9EjmKaYuEcnD6/Lbq+oJJV4EVDUiIp8HnsE95jpfVZeLyO1Addwwplfg3tKO7wBwOvBzEYnhgtid8U8/DbRYxNsdK0EYY0yPZALEt4CngbEi8nvc3fzVyay8r3cmVPWbvT7f2sdyrwDHJLONgdBTgrAAYYwxPZIZUe5ZEXkDOAlXtXSjqu5Mec4GkXolCAsQxhizWzJPMV0CRFT1H6r6f0Ckv8dOD1caCQIWIIwxJl4yjdTfUtXm7g+q2oSrdhoyNOyVIAIWIIwxplsyAaKveYZUd99EXRuEzwKEMcb0SCZAVIvI3SIy2fu5G1iS6owNpu42CJ9VMRljTI9kAsQXgC7gT95PCLg+lZkabBLpLkHkpjknxhhz6EjmKaZ24OZByEvaaNRKEMYY01u/AUJEfqKqXxSRJ/BekouXyvEZBpt0BwhrgzDGmB6JShC/9X7fNRgZSSeJhgHwWxWTMcb0SDSi3BLv94veuNSo6oH3qX0IsxKEMcbsLWEjtYjcKiI7gdXAGhGpF5FvJlrmsOQFCL8FCGOM6dFvgBCRL+H6XTpBVctUtRQ4EThFRG7qb7nDkUTtKSZjjOktUQniE8CVqrqxO8Ebm+HjwCdTnbHB1B0gbEQ5Y4zZLVGACPTVKZ/XDhFIXZYGny/mBQh7zNUYY3okChBdBzjtsLO7BGEBwhhjuiV6zPVYEWnpI12AIVVZ74t2EUXw+4dWF1PGGHMwEj3m6h/MjKSTL9ZFmAAZs8PGGJOEZPpiGvJ8sS66hlazijHGHDQLEOwuQRhjjNnNAgTgj4UJiwUIY4yJl9IAISLzRGS1iKwTkb16hBWRH4vIW97PGhFpipt2lYis9X6uSmU+/VaCMMaYvaTssR0R8QM/Bc4CaoDFIvK4qq7onkdVb4qb/wvAbO/vMtywpnNwPcku8ZbdlYq8+mNhIlaCMOaQEg6HqampIRgMpjsrQ0Jubi5VVVUEAslf61L5XOdcYJ339jUi8jBwMbCin/mvZPdY1+cAz6pqo7fss8A84I+pyKhfu6yKyZhDTE1NDYWFhUyYMAERSXd2DmuqSkNDAzU1NUycODHp5VJZxTQG2BL3ucZL24uIjAcmAs/vz7Iicq2IVItIdX39gXc06491WQnCmENMMBikvLzcgsMAEBHKy8v3uzR2qDRSXwE8qqrR/VlIVR9Q1TmqOqeysvKAN+5Xq2Iy5lBkwWHgHMixTGWAqAXGxn2u8tL6cgV7Vh/tz7IHLcsChDHG7CWVAWIxMEVEJopINi4IPN57JhGZBpQCr8YlPwOcLSKlIlIKnO2lpURWrIuoWE+uxpjdmpqa+NnPfrbfy5133nk0NTXte8bDQMoChKpGgM/jLuwrgUdUdbmI3C4i8eNZXwE8rKoat2wj8G1ckFkM3N7dYJ0KVoIwxvTWX4CIRCIJl3vyyScpKSlJVbYGVUp7p1PVJ4Ene6V9s9fnW/tZdj4wP2WZi5OlYaI+K0EYc6i67YnlrNjaV9+hB27G6CK+deFR/U6/+eabWb9+PbNmzSIQCJCbm0tpaSmrVq1izZo1fPCDH2TLli0Eg0FuvPFGrr32WgAmTJhAdXU1bW1tnHvuubz3ve/llVdeYcyYMfz9738nLy9vQPcjlQ6VRuq0CmAlCGPMnu68804mT57MW2+9xQ9/+EPeeOMN7rnnHtasWQPA/PnzWbJkCdXV1dx77700NDTstY61a9dy/fXXs3z5ckpKSvjLX/4y2LtxUKx/a6wEYcyhLtGd/mCZO3fuHu8Q3HvvvTz22GMAbNmyhbVr11JeXr7HMhMnTmTWrFkAHH/88WzatGnQ8jsQLEAAAQ0T9VkJwhjTv2HDhvX8/cILL/Cvf/2LV199lfz8fE4//fQ+3zHIydk9CJnf76ezs3NQ8jpQrIoJV8UUsxKEMSZOYWEhra2tfU5rbm6mtLSU/Px8Vq1axaJFiwY5d4PDShCxGFlELUAYY/ZQXl7OKaecwtFHH01eXh4jRozomTZv3jzuv/9+pk+fzpFHHslJJ52UxpymjgWIaAjAAoQxZi9/+MMf+kzPycnhqaee6nNadztDRUUFy5Yt60n/yle+MuD5SzWrYoq4AGGN1MYYsycLENEuANRvAcIYY+JZgBhWySn+3/NG+QXpzokxxhxSLECI0K7ZSFbOvuc1xpgMYgECiEYVv88OhTHGxLOrIhCJKVl+63feGGPiWYAAojHFZwOTGGMOQkFBAQBbt27lsssu63Oe008/nerq6oTr+clPfkJHR0fP53R2H24BAojEYmT5LEAYYw7e6NGjefTRRw94+d4BIp3dh2f8i3KqSkzBbwHCmEPXUzfD9ncGdp0jj4Fz7+x38s0338zYsWO5/vrrAbj11lvJyspiwYIF7Nq1i3A4zHe+8x0uvvjiPZbbtGkTF1xwAcuWLaOzs5NrrrmGt99+m2nTpu3RF9N1113H4sWL6ezs5LLLLuO2227j3nvvZevWrZxxxhlUVFSwYMGCnu7DKyoquPvuu5k/342C8OlPf5ovfvGLbNq0KWXdimd8CSIac+MUWQnCGBPv8ssv55FHHun5/Mgjj3DVVVfx2GOP8cYbb7BgwQK+/OUvEzfW2V7uu+8+8vPzWblyJbfddhtLlizpmXbHHXdQXV3N0qVLefHFF1m6dCk33HADo0ePZsGCBSxYsGCPdS1ZsoRf/epXvPbaayxatIgHH3yQN998E0hdt+IZX4KIeAHCb43Uxhy6Etzpp8rs2bOpq6tj69at1NfXU1paysiRI7nppptYuHAhPp+P2tpaduzYwciRI/tcx8KFC7nhhhsAmDlzJjNnzuyZ9sgjj/DAAw8QiUTYtm0bK1as2GN6by+99BKXXHJJT6+yl156Kf/+97+56KKLUtateMYHCCtBGGP68+EPf5hHH32U7du3c/nll/P73/+e+vp6lixZQiAQYMKECX12870vGzdu5K677mLx4sWUlpZy9dVXH9B6uqWqW/GMr2LqKUHYexDGmF4uv/xyHn74YR599FE+/OEP09zczPDhwwkEAixYsIB333034fLve9/7ejr8W7ZsGUuXLgWgpaWFYcOGUVxczI4dO/bo+K+/bsZPPfVU/va3v9HR0UF7ezuPPfYYp5566gDu7d6sBGElCGNMP4466ihaW1sZM2YMo0aN4mMf+xgXXnghxxxzDHPmzGHatGkJl7/uuuu45pprmD59OtOnT+f4448H4Nhjj2X27NlMmzaNsWPHcsopp/Qsc+211zJv3ryetohuxx13HFdffTVz584FXCP17NmzUzpKnSRqYDmczJkzR/f1fHFfmjvD/Ndf3+EjJ4zltKmVKciZMeZArFy5kunTp6c7G0NKX8dURJao6py+5k9pvYqIzBOR1SKyTkRu7meej4jIChFZLiJ/iEuPishb3s/jqcpjcV6An37sOAsOxhjTS8qqmETED/wUOAuoARaLyOOquiJuninA14FTVHWXiAyPW0Wnqs5KVf6MMcYklsoSxFxgnapuUNUu4GHg4l7zfAb4qaruAlDVuhTmxxhzmBkqVeCHggM5lqkMEGOALXGfa7y0eFOBqSLysogsEpF5cdNyRaTaS/9gXxsQkWu9earr6+sHNvfGmLTKzc2loaHBgsQAUFUaGhrIzc3dr+XS/RRTFjAFOB2oAhaKyDGq2gSMV9VaEZkEPC8i76jq+viFVfUB4AFwjdSDm3VjTCpVVVVRU1OD3fwNjNzcXKqqqvZrmVQGiFpgbNznKi8tXg3wmqqGgY0isgYXMBarai2Aqm4QkReA2cB6jDEZIRAIMHHixHRnI6OlsoppMTBFRCaKSDZwBdD7aaS/4UoPiEgFrsppg4iUikhOXPopwAqMMcYMmpSVIFQ1IiKfB54B/MB8VV0uIrcD1ar6uDftbBFZAUSBr6pqg4i8B/i5iMRwQezO+KefjDHGpF7GvyhnjDGZLNGLckMmQIhIPZC4Y5TEKoCdA5Sdw4Xtc2awfc4MB7rP41W1zzeFh0yAOFgiUt1fFB2qbJ8zg+1zZkjFPlsXpsYYY/pkAcIYY0yfLEDs9kC6M5AGts+ZwfY5Mwz4PlsbhDHGmD5ZCcIYY0yfLEAYY4zpU8YHiGQGNRoKRGSTiLzjDcBU7aWVicizIrLW+12a7nweLBGZLyJ1IrIsLq3P/RTnXu/cLxWR49KX8wPXzz7fKiK1cYNunRc37evePq8WkXPSk+sDJyJjRWRB3EBjN3rpQ/0897ffqTvXqpqxP7guQNYDk4Bs4G1gRrrzlaJ93QRU9Er7AXCz9/fNwPfTnc8B2M/3AccBy/a1n8B5wFOAACfhOo5M+z4M0D7fCnylj3lneP/nOcBE7//fn+592M/9HQUc5/1dCKzx9muon+f+9jtl5zrTSxDJDGo0lF0MPOT9/RDQ57gbhxNVXQg09krubz8vBn6jziKgRERGDU5OB04/+9yfi4GHVTWkqhuBdbjvwWFDVbep6hve363AStxYM0P9PPe33/056HOd6QEimUGNhgoF/ikiS0TkWi9thKpu+//t3UGIVVUcx/HvDxticELMQISIUXMlmYQLCXHRIph20kJFUMSVaNQmXMy2laCEJYFSEjG0KslVlBOIoDircUwihWinposUIUSmv4tzBi/TvTAv753r3Pv7wOXdd+7jcf784f3nnHvnnHx+G1jdTtcaVxVn1/N/OE+pfFWYPuxUzJJGSVsBXKFHIdPppAAAAuFJREFUeZ4XNzSU674XiD7ZFhFvAWPAIUnbixcjjUk7/8xzX+IEvgDWA5uBW8CxdrtTP0kjwHfARxHxoHity3kuibuxXPe9QCxkU6NOiKcbMP0FnCUNNe/MDbXza1f3BK+Ks7P5j4g7ETEbEf8Cp3k6tdCJmCUNkX4kJyLi+9zc+TyXxd1krvteIBayqdGSJ2m5pJfmzoF3gV9Jse7LH9sH/NBODxtXFec5YG9+ymUrcL8wRbGkzZtj30HKN6SYd0l6UdJa0g6OU4vdv2chScCXwG8RcbxwqdN5roq70Vy3fWe+7YP0hMMN0h3+8bb701CM60hPM1wFrs/FCawCJoGbwHng5bb7WkOs35KG2Y9Jc64HquIkPdVyMuf+GrCl7f7XGPM3OaaZ/EOxpvD58Rzz78BY2/3/H/FuI00fzQDT+XivB3muiruxXHupDTMzK9X3KSYzM6vgAmFmZqVcIMzMrJQLhJmZlXKBMDOzUi4QZgOQNFtYNXO6zhWAJY0WV2Q1a9sLbXfAbIn5JyI2t90Js8XgEYRZDfJ+G0fznhtTkl7P7aOSfskLqU1Kei23r5Z0VtLVfLydv2qZpNN5vf+fJA23FpT1nguE2WCG500x7Sxcux8RbwCfA5/mts+AryNiEzABnMjtJ4ALEfEmaS+H67l9A3AyIjYCfwPvNxyPWSX/J7XZACQ9jIiRkvY/gXci4o+8oNrtiFgl6R5p6YPHuf1WRLwi6S7wakQ8KnzHKPBzRGzI748AQxHxSfORmf2XRxBm9YmK80E8KpzP4vuE1iIXCLP67Cy8Xs7nl0irBAPsAS7m80ngIICkZZJWLFYnzRbKf52YDWZY0nTh/Y8RMfeo60pJM6RRwO7c9gFwRtLHwF1gf27/EDgl6QBppHCQtCKr2XPD9yDMapDvQWyJiHtt98WsLp5iMjOzUh5BmJlZKY8gzMyslAuEmZmVcoEwM7NSLhBmZlbKBcLMzEo9AWy2dnTELum/AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NVb-zp2fPrg",
        "outputId": "4072ed1c-ad2e-43cd-d904-5f9e918a7d64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# Summarize history for jacard_coef\n",
        "plt.plot(history.history['jacard_coef'])\n",
        "plt.plot(history.history['val_jacard_coef'])\n",
        "plt.title('Jaccard Similarity Coefficient Progress')\n",
        "plt.ylabel('Jaccard Similarity Coefficient')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'validation'], loc='best')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}